{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gP-x0H9Y7A5"
      },
      "source": [
        "# Baixando pendências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gYdnKS-6rH6",
        "outputId": "5cc46164-40b9-4b22-8efe-9c40a0c3e201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tsaug\n",
            "  Downloading tsaug-0.2.1-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.10/dist-packages (from tsaug) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.10/dist-packages (from tsaug) (1.11.4)\n",
            "Installing collected packages: tsaug\n",
            "Successfully installed tsaug-0.2.1\n",
            "Collecting tsai\n",
            "  Downloading tsai-0.3.8-py3-none-any.whl (324 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.2/324.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastai>=2.7.13 in /usr/local/lib/python3.10/dist-packages (from tsai) (2.7.13)\n",
            "Collecting pyts>=0.12.0 (from tsai)\n",
            "  Downloading pyts-0.13.0-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imbalanced-learn>=0.11.0 (from tsai)\n",
            "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.6/235.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.8 in /usr/local/lib/python3.10/dist-packages (from tsai) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn>=1.2 in /usr/local/lib/python3.10/dist-packages (from tsai) (1.2.2)\n",
            "Requirement already satisfied: torch<2.2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from tsai) (2.1.0+cu118)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai>=2.7.13->tsai) (23.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastai>=2.7.13->tsai) (23.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai>=2.7.13->tsai) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai>=2.7.13->tsai) (1.5.29)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.10/dist-packages (from fastai>=2.7.13->tsai) (0.16.0+cu118)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fastai>=2.7.13->tsai) (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fastai>=2.7.13->tsai) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fastai>=2.7.13->tsai) (2.31.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from fastai>=2.7.13->tsai) (6.0.1)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai>=2.7.13->tsai) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from fastai>=2.7.13->tsai) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fastai>=2.7.13->tsai) (1.11.4)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai>=2.7.13->tsai) (3.6.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn>=0.11.0->tsai) (1.23.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn>=0.11.0->tsai) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn>=0.11.0->tsai) (3.2.0)\n",
            "Requirement already satisfied: numba>=0.55.2 in /usr/local/lib/python3.10/dist-packages (from pyts>=0.12.0->tsai) (0.58.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.10->tsai) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.10->tsai) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.10->tsai) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.10->tsai) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.10->tsai) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.10->tsai) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=1.10->tsai) (2.1.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.2->pyts>=0.12.0->tsai) (0.41.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (4.66.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (1.10.13)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai>=2.7.13->tsai) (3.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fastai>=2.7.13->tsai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fastai>=2.7.13->tsai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fastai>=2.7.13->tsai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fastai>=2.7.13->tsai) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.2,>=1.10->tsai) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai>=2.7.13->tsai) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai>=2.7.13->tsai) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai>=2.7.13->tsai) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai>=2.7.13->tsai) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai>=2.7.13->tsai) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai>=2.7.13->tsai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai>=2.7.13->tsai) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.2,>=1.10->tsai) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->fastai>=2.7.13->tsai) (1.16.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai>=2.7.13->tsai) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai>=2.7.13->tsai) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<4->fastai>=2.7.13->tsai) (8.1.7)\n",
            "Installing collected packages: pyts, imbalanced-learn, tsai\n",
            "  Attempting uninstall: imbalanced-learn\n",
            "    Found existing installation: imbalanced-learn 0.10.1\n",
            "    Uninstalling imbalanced-learn-0.10.1:\n",
            "      Successfully uninstalled imbalanced-learn-0.10.1\n",
            "Successfully installed imbalanced-learn-0.11.0 pyts-0.13.0 tsai-0.3.8\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=d035a0fa98618527d6dc275a9b0473a88e79f24638a3273798835145eaaf7891\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tsaug\n",
        "!pip install tsai\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCoHsq7Z7U7Q",
        "outputId": "13a191b7-6636-4258-8c67-b745171c7cad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-12-02 11:05:12--  https://docs.google.com/uc?export=download&confirm=t&id=1uzZMimFYEEtQ2xlDjRkDNt35RV47MpRT\n",
            "Resolving docs.google.com (docs.google.com)... 209.85.147.101, 209.85.147.100, 209.85.147.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|209.85.147.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0o-ac-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/dhlre7vclevfmli8l1d6trl2gjd1n4qn/1701515100000/06233720922950061834/*/1uzZMimFYEEtQ2xlDjRkDNt35RV47MpRT?e=download&uuid=269fdbea-3a2f-4b02-9b5c-ab82dc5cbabc [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-12-02 11:05:12--  https://doc-0o-ac-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/dhlre7vclevfmli8l1d6trl2gjd1n4qn/1701515100000/06233720922950061834/*/1uzZMimFYEEtQ2xlDjRkDNt35RV47MpRT?e=download&uuid=269fdbea-3a2f-4b02-9b5c-ab82dc5cbabc\n",
            "Resolving doc-0o-ac-docs.googleusercontent.com (doc-0o-ac-docs.googleusercontent.com)... 172.217.214.132, 2607:f8b0:4001:c05::84\n",
            "Connecting to doc-0o-ac-docs.googleusercontent.com (doc-0o-ac-docs.googleusercontent.com)|172.217.214.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1033 (1.0K) [text/x-python]\n",
            "Saving to: ‘Reader.py’\n",
            "\n",
            "Reader.py           100%[===================>]   1.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-02 11:05:13 (58.7 MB/s) - ‘Reader.py’ saved [1033/1033]\n",
            "\n",
            "--2023-12-02 11:05:13--  https://docs.google.com/uc?export=download&id=1rPy1X6DmGFYIs1PQNkweWTy_pEXlgrzF\n",
            "Resolving docs.google.com (docs.google.com)... 209.85.147.101, 209.85.147.100, 209.85.147.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|209.85.147.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0g-ac-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/d5g0cckn9rqavrbnokuahhbm7hevkasn/1701515100000/06233720922950061834/*/1rPy1X6DmGFYIs1PQNkweWTy_pEXlgrzF?e=download&uuid=60b4777d-f4f2-4474-a4f5-05f228d63719 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-12-02 11:05:13--  https://doc-0g-ac-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/d5g0cckn9rqavrbnokuahhbm7hevkasn/1701515100000/06233720922950061834/*/1rPy1X6DmGFYIs1PQNkweWTy_pEXlgrzF?e=download&uuid=60b4777d-f4f2-4474-a4f5-05f228d63719\n",
            "Resolving doc-0g-ac-docs.googleusercontent.com (doc-0g-ac-docs.googleusercontent.com)... 172.217.214.132, 2607:f8b0:4001:c05::84\n",
            "Connecting to doc-0g-ac-docs.googleusercontent.com (doc-0g-ac-docs.googleusercontent.com)|172.217.214.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2960029 (2.8M) [text/csv]\n",
            "Saving to: ‘dataset.csv’\n",
            "\n",
            "dataset.csv         100%[===================>]   2.82M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-12-02 11:05:14 (226 MB/s) - ‘dataset.csv’ saved [2960029/2960029]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1uzZMimFYEEtQ2xlDjRkDNt35RV47MpRT' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1uzZMimFYEEtQ2xlDjRkDNt35RV47MpRT\" -O Reader.py && rm -rf /tmp/cookies.txt\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1rPy1X6DmGFYIs1PQNkweWTy_pEXlgrzF' -O dataset.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SphOYdDnZVeQ"
      },
      "source": [
        "# Inicializando Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAzQZYpj0Vl4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tsaug\n",
        "import gdown\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from tsai.all import *\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from Reader import Reader\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "import os\n",
        "os.environ[\"DEVICE\"] = \"cuda\"\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "869GqPRJ1QwB"
      },
      "outputs": [],
      "source": [
        "myReader = Reader()\n",
        "\n",
        "timeSeriesAux, dataframe = myReader.readFile(\"dataset.csv\")\n",
        "\n",
        "timeSeries = []\n",
        "data = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jSNYcOzFFV2"
      },
      "source": [
        "# Modelos Machine Learning Clássico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edHSfMqwyEnv"
      },
      "source": [
        "## Catch22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mEwTpEeyMlA",
        "outputId": "b5fb9933-f1cd-4eb3-a440-f87b28a79337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pycatch22\n",
            "  Downloading pycatch22-0.4.4.tar.gz (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m770.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pycatch22\n",
            "  Building wheel for pycatch22 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycatch22: filename=pycatch22-0.4.4-cp310-cp310-linux_x86_64.whl size=113407 sha256=2cf92e8d69b633bb785e15977408c6447efe4fbbe920b1453383dbbd4d7026b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/67/84/cdce1a956aa218fd5ce5b5fa6773219f42780b1fac77889c57\n",
            "Successfully built pycatch22\n",
            "Installing collected packages: pycatch22\n",
            "Successfully installed pycatch22-0.4.4\n"
          ]
        }
      ],
      "source": [
        "!pip install pycatch22\n",
        "import pycatch22 as catch22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpReAW99K7vO",
        "outputId": "17b01518-3eb0-47a0-d186-77b6d2dfe3c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['DN_HistogramMode_5',\n",
              " 'DN_HistogramMode_10',\n",
              " 'CO_f1ecac',\n",
              " 'CO_FirstMin_ac',\n",
              " 'CO_HistogramAMI_even_2_5',\n",
              " 'CO_trev_1_num',\n",
              " 'MD_hrv_classic_pnn40',\n",
              " 'SB_BinaryStats_mean_longstretch1',\n",
              " 'SB_TransitionMatrix_3ac_sumdiagcov',\n",
              " 'PD_PeriodicityWang_th0_01',\n",
              " 'CO_Embed2_Dist_tau_d_expfit_meandiff',\n",
              " 'IN_AutoMutualInfoStats_40_gaussian_fmmi',\n",
              " 'FC_LocalSimple_mean1_tauresrat',\n",
              " 'DN_OutlierInclude_p_001_mdrmd',\n",
              " 'DN_OutlierInclude_n_001_mdrmd',\n",
              " 'SP_Summaries_welch_rect_area_5_1',\n",
              " 'SB_BinaryStats_diff_longstretch0',\n",
              " 'SB_MotifThree_quantile_hh',\n",
              " 'SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1',\n",
              " 'SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1',\n",
              " 'SP_Summaries_welch_rect_centroid',\n",
              " 'FC_LocalSimple_mean3_stderr']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "catch22_output = catch22.catch22_all(timeSeriesAux[0][0,:])\n",
        "fnames22 = catch22_output['names']\n",
        "fnames22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0xK1_k6MyvXc",
        "outputId": "2ef6f8ef-5f7c-485e-c17b-ed0459e79da2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e8ceaa1d-e81b-421f-8cba-2b590634f826\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DN_HistogramMode_5</th>\n",
              "      <th>DN_HistogramMode_10</th>\n",
              "      <th>CO_f1ecac</th>\n",
              "      <th>CO_FirstMin_ac</th>\n",
              "      <th>CO_HistogramAMI_even_2_5</th>\n",
              "      <th>CO_trev_1_num</th>\n",
              "      <th>MD_hrv_classic_pnn40</th>\n",
              "      <th>SB_BinaryStats_mean_longstretch1</th>\n",
              "      <th>SB_TransitionMatrix_3ac_sumdiagcov</th>\n",
              "      <th>PD_PeriodicityWang_th0_01</th>\n",
              "      <th>...</th>\n",
              "      <th>FC_LocalSimple_mean1_tauresrat</th>\n",
              "      <th>DN_OutlierInclude_p_001_mdrmd</th>\n",
              "      <th>DN_OutlierInclude_n_001_mdrmd</th>\n",
              "      <th>SP_Summaries_welch_rect_area_5_1</th>\n",
              "      <th>SB_BinaryStats_diff_longstretch0</th>\n",
              "      <th>SB_MotifThree_quantile_hh</th>\n",
              "      <th>SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1</th>\n",
              "      <th>SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1</th>\n",
              "      <th>SP_Summaries_welch_rect_centroid</th>\n",
              "      <th>FC_LocalSimple_mean3_stderr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.280376</td>\n",
              "      <td>-0.056302</td>\n",
              "      <td>131.469534</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.092456</td>\n",
              "      <td>-0.000250</td>\n",
              "      <td>0.501669</td>\n",
              "      <td>312.0</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>33.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022321</td>\n",
              "      <td>-0.673333</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>0.994990</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.270030</td>\n",
              "      <td>0.148936</td>\n",
              "      <td>0.829787</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.135333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.021872</td>\n",
              "      <td>-0.259738</td>\n",
              "      <td>10.134138</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.687596</td>\n",
              "      <td>-0.011315</td>\n",
              "      <td>0.832036</td>\n",
              "      <td>61.0</td>\n",
              "      <td>0.046832</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>0.523333</td>\n",
              "      <td>-0.062222</td>\n",
              "      <td>0.975108</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.514048</td>\n",
              "      <td>0.212766</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.036816</td>\n",
              "      <td>0.369431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.793145</td>\n",
              "      <td>-0.586303</td>\n",
              "      <td>100.068878</td>\n",
              "      <td>226.0</td>\n",
              "      <td>1.177175</td>\n",
              "      <td>-0.000111</td>\n",
              "      <td>0.480534</td>\n",
              "      <td>224.0</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023256</td>\n",
              "      <td>-0.823333</td>\n",
              "      <td>0.408889</td>\n",
              "      <td>0.995906</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.288290</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.723404</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.113223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.011285</td>\n",
              "      <td>-0.841802</td>\n",
              "      <td>192.741838</td>\n",
              "      <td>551.0</td>\n",
              "      <td>1.058887</td>\n",
              "      <td>-0.000208</td>\n",
              "      <td>0.426029</td>\n",
              "      <td>351.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>269.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012780</td>\n",
              "      <td>-0.701667</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.994419</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.348453</td>\n",
              "      <td>0.148936</td>\n",
              "      <td>0.851064</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.088297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.178292</td>\n",
              "      <td>-0.985693</td>\n",
              "      <td>112.879316</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1.032684</td>\n",
              "      <td>-0.001036</td>\n",
              "      <td>0.550612</td>\n",
              "      <td>155.0</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>73.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.035000</td>\n",
              "      <td>-0.028889</td>\n",
              "      <td>0.542778</td>\n",
              "      <td>0.995561</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.295804</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.136545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.745921</td>\n",
              "      <td>-0.947025</td>\n",
              "      <td>164.656942</td>\n",
              "      <td>542.0</td>\n",
              "      <td>1.094689</td>\n",
              "      <td>-0.000073</td>\n",
              "      <td>0.327030</td>\n",
              "      <td>390.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003012</td>\n",
              "      <td>-0.897778</td>\n",
              "      <td>0.568333</td>\n",
              "      <td>0.993356</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.333818</td>\n",
              "      <td>0.191489</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.052032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.099931</td>\n",
              "      <td>-0.107818</td>\n",
              "      <td>6.142136</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.585723</td>\n",
              "      <td>-0.037017</td>\n",
              "      <td>0.916574</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.021122</td>\n",
              "      <td>23.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.555000</td>\n",
              "      <td>-0.321667</td>\n",
              "      <td>0.981665</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.523619</td>\n",
              "      <td>0.148936</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.257709</td>\n",
              "      <td>0.457907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-1.267461</td>\n",
              "      <td>-1.097125</td>\n",
              "      <td>198.985008</td>\n",
              "      <td>494.0</td>\n",
              "      <td>1.174630</td>\n",
              "      <td>0.000886</td>\n",
              "      <td>0.403782</td>\n",
              "      <td>435.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>120.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.019048</td>\n",
              "      <td>-0.531111</td>\n",
              "      <td>0.635556</td>\n",
              "      <td>0.996626</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.241475</td>\n",
              "      <td>0.170213</td>\n",
              "      <td>0.829787</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.097188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.013961</td>\n",
              "      <td>-0.290944</td>\n",
              "      <td>47.563888</td>\n",
              "      <td>95.0</td>\n",
              "      <td>0.852020</td>\n",
              "      <td>0.001081</td>\n",
              "      <td>0.589544</td>\n",
              "      <td>113.0</td>\n",
              "      <td>0.043333</td>\n",
              "      <td>236.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.078652</td>\n",
              "      <td>-0.600556</td>\n",
              "      <td>-0.375556</td>\n",
              "      <td>0.993662</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.443646</td>\n",
              "      <td>0.170213</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.024544</td>\n",
              "      <td>0.173754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.841052</td>\n",
              "      <td>-0.426223</td>\n",
              "      <td>5.450724</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.564257</td>\n",
              "      <td>-0.020367</td>\n",
              "      <td>0.919911</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.007334</td>\n",
              "      <td>26.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>-0.207778</td>\n",
              "      <td>0.286667</td>\n",
              "      <td>0.982178</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.542617</td>\n",
              "      <td>0.170213</td>\n",
              "      <td>0.234043</td>\n",
              "      <td>0.227029</td>\n",
              "      <td>0.467007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.141482</td>\n",
              "      <td>0.214495</td>\n",
              "      <td>9.270355</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.496756</td>\n",
              "      <td>-0.008647</td>\n",
              "      <td>0.865406</td>\n",
              "      <td>91.0</td>\n",
              "      <td>0.054422</td>\n",
              "      <td>23.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048780</td>\n",
              "      <td>0.408889</td>\n",
              "      <td>-0.183333</td>\n",
              "      <td>0.984604</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.554089</td>\n",
              "      <td>0.170213</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.055223</td>\n",
              "      <td>0.367303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.101521</td>\n",
              "      <td>0.325300</td>\n",
              "      <td>90.382463</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.891378</td>\n",
              "      <td>-0.000141</td>\n",
              "      <td>0.656285</td>\n",
              "      <td>190.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>27.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.030435</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>-0.418889</td>\n",
              "      <td>0.996696</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.337556</td>\n",
              "      <td>0.234043</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.012272</td>\n",
              "      <td>0.203264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.188243</td>\n",
              "      <td>0.440189</td>\n",
              "      <td>7.606779</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.606761</td>\n",
              "      <td>-0.057690</td>\n",
              "      <td>0.760845</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.028723</td>\n",
              "      <td>27.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.097561</td>\n",
              "      <td>-0.007778</td>\n",
              "      <td>-0.848889</td>\n",
              "      <td>0.949011</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.533941</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.128854</td>\n",
              "      <td>0.447608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-0.154923</td>\n",
              "      <td>0.598240</td>\n",
              "      <td>11.849673</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.769563</td>\n",
              "      <td>-0.003912</td>\n",
              "      <td>0.783092</td>\n",
              "      <td>193.0</td>\n",
              "      <td>0.027778</td>\n",
              "      <td>31.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.042857</td>\n",
              "      <td>-0.646667</td>\n",
              "      <td>0.562222</td>\n",
              "      <td>0.988905</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.413804</td>\n",
              "      <td>0.297872</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.042951</td>\n",
              "      <td>0.309761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.030752</td>\n",
              "      <td>0.839618</td>\n",
              "      <td>198.447773</td>\n",
              "      <td>115.0</td>\n",
              "      <td>1.093595</td>\n",
              "      <td>-0.000320</td>\n",
              "      <td>0.409344</td>\n",
              "      <td>484.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>156.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006579</td>\n",
              "      <td>0.635556</td>\n",
              "      <td>-0.573333</td>\n",
              "      <td>0.990450</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.291778</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.787234</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.130429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.067612</td>\n",
              "      <td>-0.252922</td>\n",
              "      <td>32.132787</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.783952</td>\n",
              "      <td>0.013668</td>\n",
              "      <td>0.624027</td>\n",
              "      <td>161.0</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>190.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018349</td>\n",
              "      <td>-0.932778</td>\n",
              "      <td>0.408333</td>\n",
              "      <td>0.984784</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.341768</td>\n",
              "      <td>0.702128</td>\n",
              "      <td>0.361702</td>\n",
              "      <td>0.030680</td>\n",
              "      <td>0.201063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1.121035</td>\n",
              "      <td>0.898140</td>\n",
              "      <td>140.915753</td>\n",
              "      <td>84.0</td>\n",
              "      <td>1.126440</td>\n",
              "      <td>-0.000808</td>\n",
              "      <td>0.541713</td>\n",
              "      <td>261.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>262.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020270</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>-0.808889</td>\n",
              "      <td>0.994543</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.277868</td>\n",
              "      <td>0.638298</td>\n",
              "      <td>0.574468</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.125602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-0.327961</td>\n",
              "      <td>-1.015851</td>\n",
              "      <td>170.881913</td>\n",
              "      <td>291.0</td>\n",
              "      <td>0.968521</td>\n",
              "      <td>-0.000243</td>\n",
              "      <td>0.615128</td>\n",
              "      <td>273.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>36.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002924</td>\n",
              "      <td>-0.842778</td>\n",
              "      <td>0.711667</td>\n",
              "      <td>0.990444</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.276468</td>\n",
              "      <td>0.468085</td>\n",
              "      <td>0.574468</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.120859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.083459</td>\n",
              "      <td>0.349488</td>\n",
              "      <td>93.248392</td>\n",
              "      <td>103.0</td>\n",
              "      <td>0.834031</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>0.501669</td>\n",
              "      <td>333.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002825</td>\n",
              "      <td>-0.952222</td>\n",
              "      <td>0.667778</td>\n",
              "      <td>0.988002</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.338455</td>\n",
              "      <td>0.680851</td>\n",
              "      <td>0.382979</td>\n",
              "      <td>0.012272</td>\n",
              "      <td>0.106680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.650901</td>\n",
              "      <td>0.302047</td>\n",
              "      <td>24.593907</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.458414</td>\n",
              "      <td>-0.025334</td>\n",
              "      <td>0.833148</td>\n",
              "      <td>143.0</td>\n",
              "      <td>0.041667</td>\n",
              "      <td>17.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>-0.136667</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.941775</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.542230</td>\n",
              "      <td>0.148936</td>\n",
              "      <td>0.808511</td>\n",
              "      <td>0.024544</td>\n",
              "      <td>0.443191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>-0.780709</td>\n",
              "      <td>-0.503035</td>\n",
              "      <td>77.855821</td>\n",
              "      <td>141.0</td>\n",
              "      <td>0.883222</td>\n",
              "      <td>-0.000041</td>\n",
              "      <td>0.521691</td>\n",
              "      <td>164.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>146.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.015924</td>\n",
              "      <td>-0.802222</td>\n",
              "      <td>0.926111</td>\n",
              "      <td>0.995319</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.379495</td>\n",
              "      <td>0.170213</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.012272</td>\n",
              "      <td>0.118217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>-0.732916</td>\n",
              "      <td>-0.426373</td>\n",
              "      <td>31.998246</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.499804</td>\n",
              "      <td>0.017245</td>\n",
              "      <td>0.783092</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0.036458</td>\n",
              "      <td>25.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>-0.857222</td>\n",
              "      <td>0.528889</td>\n",
              "      <td>0.942296</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.540534</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.829787</td>\n",
              "      <td>0.024544</td>\n",
              "      <td>0.429501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>-0.624249</td>\n",
              "      <td>-0.822003</td>\n",
              "      <td>144.698248</td>\n",
              "      <td>430.0</td>\n",
              "      <td>1.100407</td>\n",
              "      <td>-0.000102</td>\n",
              "      <td>0.273637</td>\n",
              "      <td>350.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003135</td>\n",
              "      <td>-0.923333</td>\n",
              "      <td>0.571111</td>\n",
              "      <td>0.993068</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.220071</td>\n",
              "      <td>0.638298</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.051919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.736538</td>\n",
              "      <td>0.442458</td>\n",
              "      <td>64.031296</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0.859116</td>\n",
              "      <td>-0.002349</td>\n",
              "      <td>0.649611</td>\n",
              "      <td>268.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>54.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022124</td>\n",
              "      <td>-0.678889</td>\n",
              "      <td>-0.456111</td>\n",
              "      <td>0.990852</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.352696</td>\n",
              "      <td>0.191489</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.018408</td>\n",
              "      <td>0.193219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.877367</td>\n",
              "      <td>0.681029</td>\n",
              "      <td>167.521161</td>\n",
              "      <td>184.0</td>\n",
              "      <td>1.008720</td>\n",
              "      <td>-0.001020</td>\n",
              "      <td>0.427141</td>\n",
              "      <td>329.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>283.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011905</td>\n",
              "      <td>-0.786667</td>\n",
              "      <td>0.672778</td>\n",
              "      <td>0.994063</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.338455</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.829787</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.128713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.517245</td>\n",
              "      <td>0.244854</td>\n",
              "      <td>161.299686</td>\n",
              "      <td>419.0</td>\n",
              "      <td>0.944489</td>\n",
              "      <td>-0.000742</td>\n",
              "      <td>0.511680</td>\n",
              "      <td>564.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>206.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022951</td>\n",
              "      <td>-0.954444</td>\n",
              "      <td>0.791111</td>\n",
              "      <td>0.991873</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.323871</td>\n",
              "      <td>0.510638</td>\n",
              "      <td>0.851064</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.110496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>-0.851754</td>\n",
              "      <td>0.064179</td>\n",
              "      <td>60.454388</td>\n",
              "      <td>89.0</td>\n",
              "      <td>0.695995</td>\n",
              "      <td>-0.001163</td>\n",
              "      <td>0.517241</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>104.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020833</td>\n",
              "      <td>-0.881111</td>\n",
              "      <td>0.836667</td>\n",
              "      <td>0.994359</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.454432</td>\n",
              "      <td>0.148936</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.012272</td>\n",
              "      <td>0.137766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.301233</td>\n",
              "      <td>-0.655935</td>\n",
              "      <td>24.592235</td>\n",
              "      <td>57.0</td>\n",
              "      <td>0.893032</td>\n",
              "      <td>-0.001710</td>\n",
              "      <td>0.589544</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>274.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024306</td>\n",
              "      <td>-0.962222</td>\n",
              "      <td>-0.843333</td>\n",
              "      <td>0.987765</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.307118</td>\n",
              "      <td>0.617021</td>\n",
              "      <td>0.468085</td>\n",
              "      <td>0.042951</td>\n",
              "      <td>0.158317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1.070393</td>\n",
              "      <td>1.215513</td>\n",
              "      <td>209.376484</td>\n",
              "      <td>561.0</td>\n",
              "      <td>1.333221</td>\n",
              "      <td>-0.000011</td>\n",
              "      <td>0.250278</td>\n",
              "      <td>429.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003165</td>\n",
              "      <td>-0.616667</td>\n",
              "      <td>0.682222</td>\n",
              "      <td>0.996022</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.211421</td>\n",
              "      <td>0.510638</td>\n",
              "      <td>0.234043</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.045121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.614849</td>\n",
              "      <td>0.329864</td>\n",
              "      <td>143.719073</td>\n",
              "      <td>442.0</td>\n",
              "      <td>0.920748</td>\n",
              "      <td>-0.000689</td>\n",
              "      <td>0.552836</td>\n",
              "      <td>382.0</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>261.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024221</td>\n",
              "      <td>-0.941111</td>\n",
              "      <td>0.817778</td>\n",
              "      <td>0.991840</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.260595</td>\n",
              "      <td>0.787234</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.106749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>-0.346140</td>\n",
              "      <td>0.675376</td>\n",
              "      <td>8.886032</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.587235</td>\n",
              "      <td>-0.010494</td>\n",
              "      <td>0.780868</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.005745</td>\n",
              "      <td>33.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>-0.815556</td>\n",
              "      <td>0.708889</td>\n",
              "      <td>0.983763</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.478811</td>\n",
              "      <td>0.276596</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.141126</td>\n",
              "      <td>0.342600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.207666</td>\n",
              "      <td>0.462467</td>\n",
              "      <td>87.093572</td>\n",
              "      <td>210.0</td>\n",
              "      <td>1.126296</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.343715</td>\n",
              "      <td>314.0</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>272.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041420</td>\n",
              "      <td>-0.933333</td>\n",
              "      <td>0.110000</td>\n",
              "      <td>0.993610</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.287702</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.851064</td>\n",
              "      <td>0.012272</td>\n",
              "      <td>0.098374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>-1.013582</td>\n",
              "      <td>-0.798812</td>\n",
              "      <td>175.278985</td>\n",
              "      <td>625.0</td>\n",
              "      <td>1.220679</td>\n",
              "      <td>-0.000038</td>\n",
              "      <td>0.397108</td>\n",
              "      <td>339.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003049</td>\n",
              "      <td>-0.880556</td>\n",
              "      <td>0.673333</td>\n",
              "      <td>0.991869</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.224287</td>\n",
              "      <td>0.255319</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.050993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>-1.113746</td>\n",
              "      <td>-0.955064</td>\n",
              "      <td>166.639758</td>\n",
              "      <td>457.0</td>\n",
              "      <td>1.277854</td>\n",
              "      <td>-0.000067</td>\n",
              "      <td>0.394883</td>\n",
              "      <td>329.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>289.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.034221</td>\n",
              "      <td>-0.388889</td>\n",
              "      <td>0.585556</td>\n",
              "      <td>0.996481</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.233710</td>\n",
              "      <td>0.170213</td>\n",
              "      <td>0.829787</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.079779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.669673</td>\n",
              "      <td>0.996980</td>\n",
              "      <td>54.211087</td>\n",
              "      <td>74.0</td>\n",
              "      <td>0.784303</td>\n",
              "      <td>-0.003990</td>\n",
              "      <td>0.619577</td>\n",
              "      <td>413.0</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>165.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>-0.186667</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.989038</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.392926</td>\n",
              "      <td>0.425532</td>\n",
              "      <td>0.148936</td>\n",
              "      <td>0.018408</td>\n",
              "      <td>0.180425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>-0.246832</td>\n",
              "      <td>0.213515</td>\n",
              "      <td>25.735393</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.339149</td>\n",
              "      <td>-0.006237</td>\n",
              "      <td>0.689655</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>69.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.069767</td>\n",
              "      <td>-0.886667</td>\n",
              "      <td>0.945556</td>\n",
              "      <td>0.987596</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.712133</td>\n",
              "      <td>0.297872</td>\n",
              "      <td>0.851064</td>\n",
              "      <td>0.036816</td>\n",
              "      <td>0.206056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>-0.183409</td>\n",
              "      <td>-0.443985</td>\n",
              "      <td>161.769855</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.953523</td>\n",
              "      <td>-0.000784</td>\n",
              "      <td>0.669633</td>\n",
              "      <td>288.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>290.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011869</td>\n",
              "      <td>-0.949444</td>\n",
              "      <td>0.774444</td>\n",
              "      <td>0.984701</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.335596</td>\n",
              "      <td>0.595745</td>\n",
              "      <td>0.851064</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.167103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>-1.006371</td>\n",
              "      <td>-0.398152</td>\n",
              "      <td>168.869551</td>\n",
              "      <td>537.0</td>\n",
              "      <td>1.031949</td>\n",
              "      <td>-0.000112</td>\n",
              "      <td>0.510567</td>\n",
              "      <td>315.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>282.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003125</td>\n",
              "      <td>-0.883333</td>\n",
              "      <td>0.683333</td>\n",
              "      <td>0.993366</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.359488</td>\n",
              "      <td>0.425532</td>\n",
              "      <td>0.255319</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.098501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.653354</td>\n",
              "      <td>0.878162</td>\n",
              "      <td>35.428951</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.743241</td>\n",
              "      <td>-0.003136</td>\n",
              "      <td>0.839822</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.054422</td>\n",
              "      <td>26.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.043103</td>\n",
              "      <td>-0.317778</td>\n",
              "      <td>0.527778</td>\n",
              "      <td>0.990303</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.418031</td>\n",
              "      <td>0.170213</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.018408</td>\n",
              "      <td>0.310670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>-0.423438</td>\n",
              "      <td>-0.147632</td>\n",
              "      <td>95.754313</td>\n",
              "      <td>178.0</td>\n",
              "      <td>0.582144</td>\n",
              "      <td>-0.000440</td>\n",
              "      <td>0.380423</td>\n",
              "      <td>146.0</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>129.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055215</td>\n",
              "      <td>-0.956667</td>\n",
              "      <td>0.212778</td>\n",
              "      <td>0.986430</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.593209</td>\n",
              "      <td>0.148936</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.012272</td>\n",
              "      <td>0.095764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.308985</td>\n",
              "      <td>0.547460</td>\n",
              "      <td>147.894380</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.873313</td>\n",
              "      <td>-0.002479</td>\n",
              "      <td>0.615128</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>22.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.015326</td>\n",
              "      <td>-0.386111</td>\n",
              "      <td>0.694444</td>\n",
              "      <td>0.990335</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.312722</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.851064</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.188269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>-0.716443</td>\n",
              "      <td>-0.415339</td>\n",
              "      <td>119.547773</td>\n",
              "      <td>171.0</td>\n",
              "      <td>0.982565</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>0.410456</td>\n",
              "      <td>241.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003135</td>\n",
              "      <td>-0.923333</td>\n",
              "      <td>0.346667</td>\n",
              "      <td>0.988909</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1.353119</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.808511</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.105357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>-0.657525</td>\n",
              "      <td>-0.449427</td>\n",
              "      <td>176.398697</td>\n",
              "      <td>606.0</td>\n",
              "      <td>1.151450</td>\n",
              "      <td>-0.000129</td>\n",
              "      <td>0.503893</td>\n",
              "      <td>213.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003058</td>\n",
              "      <td>-0.803333</td>\n",
              "      <td>0.793333</td>\n",
              "      <td>0.990702</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.333818</td>\n",
              "      <td>0.829787</td>\n",
              "      <td>0.382979</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.090994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.929717</td>\n",
              "      <td>0.598795</td>\n",
              "      <td>6.205279</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.482157</td>\n",
              "      <td>-0.037601</td>\n",
              "      <td>0.832036</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0.012357</td>\n",
              "      <td>27.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.793333</td>\n",
              "      <td>-0.348889</td>\n",
              "      <td>0.961241</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.532420</td>\n",
              "      <td>0.191489</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.220893</td>\n",
              "      <td>0.460856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>-0.095817</td>\n",
              "      <td>-0.364001</td>\n",
              "      <td>129.712388</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.641576</td>\n",
              "      <td>-0.022489</td>\n",
              "      <td>0.786429</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>20.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010870</td>\n",
              "      <td>-0.624444</td>\n",
              "      <td>0.725556</td>\n",
              "      <td>0.977887</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.471846</td>\n",
              "      <td>0.148936</td>\n",
              "      <td>0.808511</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.345090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>-0.313568</td>\n",
              "      <td>-0.588980</td>\n",
              "      <td>148.528682</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.864443</td>\n",
              "      <td>-0.001518</td>\n",
              "      <td>0.588432</td>\n",
              "      <td>157.0</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>27.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017422</td>\n",
              "      <td>-0.817778</td>\n",
              "      <td>0.375556</td>\n",
              "      <td>0.993133</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.311380</td>\n",
              "      <td>0.170213</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.178764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>-0.961795</td>\n",
              "      <td>-0.824878</td>\n",
              "      <td>177.793075</td>\n",
              "      <td>547.0</td>\n",
              "      <td>0.965974</td>\n",
              "      <td>-0.000187</td>\n",
              "      <td>0.166852</td>\n",
              "      <td>355.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.028169</td>\n",
              "      <td>-0.604444</td>\n",
              "      <td>0.445000</td>\n",
              "      <td>0.997391</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.334889</td>\n",
              "      <td>0.191489</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.061331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>-0.351182</td>\n",
              "      <td>-0.094265</td>\n",
              "      <td>149.211217</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0.873466</td>\n",
              "      <td>-0.000640</td>\n",
              "      <td>0.733037</td>\n",
              "      <td>169.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>134.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012987</td>\n",
              "      <td>-0.764444</td>\n",
              "      <td>0.546667</td>\n",
              "      <td>0.983995</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1.348453</td>\n",
              "      <td>0.148936</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.190187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>-0.289456</td>\n",
              "      <td>-0.005423</td>\n",
              "      <td>10.875520</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.683185</td>\n",
              "      <td>-0.003725</td>\n",
              "      <td>0.802002</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.046832</td>\n",
              "      <td>30.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.017778</td>\n",
              "      <td>-0.770000</td>\n",
              "      <td>0.986902</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.468207</td>\n",
              "      <td>0.191489</td>\n",
              "      <td>0.851064</td>\n",
              "      <td>0.067495</td>\n",
              "      <td>0.298779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>-0.914341</td>\n",
              "      <td>-0.534355</td>\n",
              "      <td>98.418804</td>\n",
              "      <td>94.0</td>\n",
              "      <td>0.700354</td>\n",
              "      <td>-0.000456</td>\n",
              "      <td>0.634038</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>15.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014652</td>\n",
              "      <td>-0.932222</td>\n",
              "      <td>0.367778</td>\n",
              "      <td>0.971991</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.433192</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.255319</td>\n",
              "      <td>0.012272</td>\n",
              "      <td>0.152199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0.859677</td>\n",
              "      <td>0.626340</td>\n",
              "      <td>73.959413</td>\n",
              "      <td>169.0</td>\n",
              "      <td>0.948066</td>\n",
              "      <td>-0.000069</td>\n",
              "      <td>0.451613</td>\n",
              "      <td>370.0</td>\n",
              "      <td>0.018519</td>\n",
              "      <td>193.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055172</td>\n",
              "      <td>-0.078889</td>\n",
              "      <td>-0.830000</td>\n",
              "      <td>0.992968</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.335338</td>\n",
              "      <td>0.170213</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.012272</td>\n",
              "      <td>0.118083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>-0.096265</td>\n",
              "      <td>0.801405</td>\n",
              "      <td>26.182898</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.776090</td>\n",
              "      <td>0.009067</td>\n",
              "      <td>0.704116</td>\n",
              "      <td>165.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>51.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020896</td>\n",
              "      <td>-0.943889</td>\n",
              "      <td>-0.756667</td>\n",
              "      <td>0.986982</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.431331</td>\n",
              "      <td>0.595745</td>\n",
              "      <td>0.468085</td>\n",
              "      <td>0.030680</td>\n",
              "      <td>0.221496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>0.073346</td>\n",
              "      <td>0.344484</td>\n",
              "      <td>27.528522</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.719115</td>\n",
              "      <td>-0.017733</td>\n",
              "      <td>0.818687</td>\n",
              "      <td>104.0</td>\n",
              "      <td>0.023333</td>\n",
              "      <td>19.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.056180</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.859444</td>\n",
              "      <td>0.984740</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.451884</td>\n",
              "      <td>0.191489</td>\n",
              "      <td>0.851064</td>\n",
              "      <td>0.030680</td>\n",
              "      <td>0.329502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>-0.791554</td>\n",
              "      <td>-0.963035</td>\n",
              "      <td>184.202087</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.114340</td>\n",
              "      <td>-0.000296</td>\n",
              "      <td>0.450501</td>\n",
              "      <td>307.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>24.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009901</td>\n",
              "      <td>-0.702222</td>\n",
              "      <td>0.671111</td>\n",
              "      <td>0.994615</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.269879</td>\n",
              "      <td>0.872340</td>\n",
              "      <td>0.851064</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.109059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>-0.266547</td>\n",
              "      <td>-0.534225</td>\n",
              "      <td>138.021671</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.987453</td>\n",
              "      <td>-0.000630</td>\n",
              "      <td>0.617353</td>\n",
              "      <td>286.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>22.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.015337</td>\n",
              "      <td>-0.886667</td>\n",
              "      <td>0.835000</td>\n",
              "      <td>0.991874</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.399781</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.851064</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.143026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>-0.672095</td>\n",
              "      <td>-0.883189</td>\n",
              "      <td>175.091877</td>\n",
              "      <td>629.0</td>\n",
              "      <td>1.017570</td>\n",
              "      <td>-0.000148</td>\n",
              "      <td>0.219132</td>\n",
              "      <td>275.0</td>\n",
              "      <td>0.074074</td>\n",
              "      <td>253.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018382</td>\n",
              "      <td>-0.901111</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.993576</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.265859</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.851064</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.057401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0.547501</td>\n",
              "      <td>-0.716350</td>\n",
              "      <td>164.882534</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.925582</td>\n",
              "      <td>-0.001322</td>\n",
              "      <td>0.650723</td>\n",
              "      <td>229.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>91.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017241</td>\n",
              "      <td>-0.537778</td>\n",
              "      <td>0.593889</td>\n",
              "      <td>0.993763</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1.339380</td>\n",
              "      <td>0.255319</td>\n",
              "      <td>0.851064</td>\n",
              "      <td>0.006136</td>\n",
              "      <td>0.173564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>-0.895575</td>\n",
              "      <td>-0.473484</td>\n",
              "      <td>17.117659</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.556156</td>\n",
              "      <td>-0.005360</td>\n",
              "      <td>0.598443</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>29.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.015291</td>\n",
              "      <td>-0.985556</td>\n",
              "      <td>0.843333</td>\n",
              "      <td>0.967279</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.440512</td>\n",
              "      <td>0.361702</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.055223</td>\n",
              "      <td>0.227309</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>58 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8ceaa1d-e81b-421f-8cba-2b590634f826')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e8ceaa1d-e81b-421f-8cba-2b590634f826 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e8ceaa1d-e81b-421f-8cba-2b590634f826');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-49572c8a-b540-4e42-984b-21b1a56e5706\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-49572c8a-b540-4e42-984b-21b1a56e5706')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-49572c8a-b540-4e42-984b-21b1a56e5706 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    DN_HistogramMode_5  DN_HistogramMode_10   CO_f1ecac  CO_FirstMin_ac  \\\n",
              "0            -0.280376            -0.056302  131.469534            13.0   \n",
              "1            -0.021872            -0.259738   10.134138            16.0   \n",
              "2            -0.793145            -0.586303  100.068878           226.0   \n",
              "3            -1.011285            -0.841802  192.741838           551.0   \n",
              "4            -1.178292            -0.985693  112.879316            42.0   \n",
              "5            -0.745921            -0.947025  164.656942           542.0   \n",
              "6             0.099931            -0.107818    6.142136            12.0   \n",
              "7            -1.267461            -1.097125  198.985008           494.0   \n",
              "8            -0.013961            -0.290944   47.563888            95.0   \n",
              "9            -0.841052            -0.426223    5.450724            14.0   \n",
              "10           -0.141482             0.214495    9.270355            13.0   \n",
              "11            0.101521             0.325300   90.382463            19.0   \n",
              "12            0.188243             0.440189    7.606779            16.0   \n",
              "13           -0.154923             0.598240   11.849673            17.0   \n",
              "14            1.030752             0.839618  198.447773           115.0   \n",
              "15            0.067612            -0.252922   32.132787            67.0   \n",
              "16            1.121035             0.898140  140.915753            84.0   \n",
              "17           -0.327961            -1.015851  170.881913           291.0   \n",
              "18            0.083459             0.349488   93.248392           103.0   \n",
              "19            0.650901             0.302047   24.593907            11.0   \n",
              "20           -0.780709            -0.503035   77.855821           141.0   \n",
              "21           -0.732916            -0.426373   31.998246            20.0   \n",
              "22           -0.624249            -0.822003  144.698248           430.0   \n",
              "23            0.736538             0.442458   64.031296            49.0   \n",
              "24            0.877367             0.681029  167.521161           184.0   \n",
              "25            0.517245             0.244854  161.299686           419.0   \n",
              "26           -0.851754             0.064179   60.454388            89.0   \n",
              "27            0.301233            -0.655935   24.592235            57.0   \n",
              "28            1.070393             1.215513  209.376484           561.0   \n",
              "29            0.614849             0.329864  143.719073           442.0   \n",
              "30           -0.346140             0.675376    8.886032            18.0   \n",
              "31            0.207666             0.462467   87.093572           210.0   \n",
              "32           -1.013582            -0.798812  175.278985           625.0   \n",
              "33           -1.113746            -0.955064  166.639758           457.0   \n",
              "34            0.669673             0.996980   54.211087            74.0   \n",
              "35           -0.246832             0.213515   25.735393            64.0   \n",
              "36           -0.183409            -0.443985  161.769855            79.0   \n",
              "37           -1.006371            -0.398152  168.869551           537.0   \n",
              "38            0.653354             0.878162   35.428951            14.0   \n",
              "39           -0.423438            -0.147632   95.754313           178.0   \n",
              "40            0.308985             0.547460  147.894380            16.0   \n",
              "41           -0.716443            -0.415339  119.547773           171.0   \n",
              "42           -0.657525            -0.449427  176.398697           606.0   \n",
              "43            0.929717             0.598795    6.205279            15.0   \n",
              "44           -0.095817            -0.364001  129.712388            11.0   \n",
              "45           -0.313568            -0.588980  148.528682            16.0   \n",
              "46           -0.961795            -0.824878  177.793075           547.0   \n",
              "47           -0.351182            -0.094265  149.211217            45.0   \n",
              "48           -0.289456            -0.005423   10.875520            18.0   \n",
              "49           -0.914341            -0.534355   98.418804            94.0   \n",
              "50            0.859677             0.626340   73.959413           169.0   \n",
              "51           -0.096265             0.801405   26.182898            38.0   \n",
              "52            0.073346             0.344484   27.528522            12.0   \n",
              "53           -0.791554            -0.963035  184.202087            20.0   \n",
              "54           -0.266547            -0.534225  138.021671            60.0   \n",
              "55           -0.672095            -0.883189  175.091877           629.0   \n",
              "56            0.547501            -0.716350  164.882534            18.0   \n",
              "57           -0.895575            -0.473484   17.117659            20.0   \n",
              "\n",
              "    CO_HistogramAMI_even_2_5  CO_trev_1_num  MD_hrv_classic_pnn40  \\\n",
              "0                   1.092456      -0.000250              0.501669   \n",
              "1                   0.687596      -0.011315              0.832036   \n",
              "2                   1.177175      -0.000111              0.480534   \n",
              "3                   1.058887      -0.000208              0.426029   \n",
              "4                   1.032684      -0.001036              0.550612   \n",
              "5                   1.094689      -0.000073              0.327030   \n",
              "6                   0.585723      -0.037017              0.916574   \n",
              "7                   1.174630       0.000886              0.403782   \n",
              "8                   0.852020       0.001081              0.589544   \n",
              "9                   0.564257      -0.020367              0.919911   \n",
              "10                  0.496756      -0.008647              0.865406   \n",
              "11                  0.891378      -0.000141              0.656285   \n",
              "12                  0.606761      -0.057690              0.760845   \n",
              "13                  0.769563      -0.003912              0.783092   \n",
              "14                  1.093595      -0.000320              0.409344   \n",
              "15                  0.783952       0.013668              0.624027   \n",
              "16                  1.126440      -0.000808              0.541713   \n",
              "17                  0.968521      -0.000243              0.615128   \n",
              "18                  0.834031      -0.000533              0.501669   \n",
              "19                  0.458414      -0.025334              0.833148   \n",
              "20                  0.883222      -0.000041              0.521691   \n",
              "21                  0.499804       0.017245              0.783092   \n",
              "22                  1.100407      -0.000102              0.273637   \n",
              "23                  0.859116      -0.002349              0.649611   \n",
              "24                  1.008720      -0.001020              0.427141   \n",
              "25                  0.944489      -0.000742              0.511680   \n",
              "26                  0.695995      -0.001163              0.517241   \n",
              "27                  0.893032      -0.001710              0.589544   \n",
              "28                  1.333221      -0.000011              0.250278   \n",
              "29                  0.920748      -0.000689              0.552836   \n",
              "30                  0.587235      -0.010494              0.780868   \n",
              "31                  1.126296       0.000069              0.343715   \n",
              "32                  1.220679      -0.000038              0.397108   \n",
              "33                  1.277854      -0.000067              0.394883   \n",
              "34                  0.784303      -0.003990              0.619577   \n",
              "35                  0.339149      -0.006237              0.689655   \n",
              "36                  0.953523      -0.000784              0.669633   \n",
              "37                  1.031949      -0.000112              0.510567   \n",
              "38                  0.743241      -0.003136              0.839822   \n",
              "39                  0.582144      -0.000440              0.380423   \n",
              "40                  0.873313      -0.002479              0.615128   \n",
              "41                  0.982565       0.000173              0.410456   \n",
              "42                  1.151450      -0.000129              0.503893   \n",
              "43                  0.482157      -0.037601              0.832036   \n",
              "44                  0.641576      -0.022489              0.786429   \n",
              "45                  0.864443      -0.001518              0.588432   \n",
              "46                  0.965974      -0.000187              0.166852   \n",
              "47                  0.873466      -0.000640              0.733037   \n",
              "48                  0.683185      -0.003725              0.802002   \n",
              "49                  0.700354      -0.000456              0.634038   \n",
              "50                  0.948066      -0.000069              0.451613   \n",
              "51                  0.776090       0.009067              0.704116   \n",
              "52                  0.719115      -0.017733              0.818687   \n",
              "53                  1.114340      -0.000296              0.450501   \n",
              "54                  0.987453      -0.000630              0.617353   \n",
              "55                  1.017570      -0.000148              0.219132   \n",
              "56                  0.925582      -0.001322              0.650723   \n",
              "57                  0.556156      -0.005360              0.598443   \n",
              "\n",
              "    SB_BinaryStats_mean_longstretch1  SB_TransitionMatrix_3ac_sumdiagcov  \\\n",
              "0                              312.0                            0.062500   \n",
              "1                               61.0                            0.046832   \n",
              "2                              224.0                            0.040000   \n",
              "3                              351.0                            0.166667   \n",
              "4                              155.0                            0.041667   \n",
              "5                              390.0                            0.166667   \n",
              "6                               21.0                            0.021122   \n",
              "7                              435.0                            0.166667   \n",
              "8                              113.0                            0.043333   \n",
              "9                               21.0                            0.007334   \n",
              "10                              91.0                            0.054422   \n",
              "11                             190.0                            0.111111   \n",
              "12                              26.0                            0.028723   \n",
              "13                             193.0                            0.027778   \n",
              "14                             484.0                            0.166667   \n",
              "15                             161.0                            0.062500   \n",
              "16                             261.0                            0.111111   \n",
              "17                             273.0                            0.166667   \n",
              "18                             333.0                            0.166667   \n",
              "19                             143.0                            0.041667   \n",
              "20                             164.0                            0.166667   \n",
              "21                             102.0                            0.036458   \n",
              "22                             350.0                            0.166667   \n",
              "23                             268.0                            0.111111   \n",
              "24                             329.0                            0.166667   \n",
              "25                             564.0                            0.166667   \n",
              "26                             120.0                            0.166667   \n",
              "27                             200.0                            0.074074   \n",
              "28                             429.0                            0.166667   \n",
              "29                             382.0                            0.074074   \n",
              "30                              47.0                            0.005745   \n",
              "31                             314.0                            0.080000   \n",
              "32                             339.0                            0.166667   \n",
              "33                             329.0                            0.111111   \n",
              "34                             413.0                            0.062500   \n",
              "35                              69.0                            0.018519   \n",
              "36                             288.0                            0.166667   \n",
              "37                             315.0                            0.166667   \n",
              "38                              79.0                            0.054422   \n",
              "39                             146.0                            0.080000   \n",
              "40                             172.0                            0.111111   \n",
              "41                             241.0                            0.166667   \n",
              "42                             213.0                            0.166667   \n",
              "43                              55.0                            0.012357   \n",
              "44                             168.0                            0.111111   \n",
              "45                             157.0                            0.074074   \n",
              "46                             355.0                            0.111111   \n",
              "47                             169.0                            0.166667   \n",
              "48                              81.0                            0.046832   \n",
              "49                             200.0                            0.074074   \n",
              "50                             370.0                            0.018519   \n",
              "51                             165.0                            0.166667   \n",
              "52                             104.0                            0.023333   \n",
              "53                             307.0                            0.166667   \n",
              "54                             286.0                            0.166667   \n",
              "55                             275.0                            0.074074   \n",
              "56                             229.0                            0.111111   \n",
              "57                              80.0                            0.166667   \n",
              "\n",
              "    PD_PeriodicityWang_th0_01  ...  FC_LocalSimple_mean1_tauresrat  \\\n",
              "0                        33.0  ...                        0.022321   \n",
              "1                        30.0  ...                        0.078947   \n",
              "2                         0.0  ...                        0.023256   \n",
              "3                       269.0  ...                        0.012780   \n",
              "4                        73.0  ...                        0.035000   \n",
              "5                         0.0  ...                        0.003012   \n",
              "6                        23.0  ...                        0.416667   \n",
              "7                       120.0  ...                        0.019048   \n",
              "8                       236.0  ...                        0.078652   \n",
              "9                        26.0  ...                        0.750000   \n",
              "10                       23.0  ...                        0.048780   \n",
              "11                       27.0  ...                        0.030435   \n",
              "12                       27.0  ...                        0.097561   \n",
              "13                       31.0  ...                        0.042857   \n",
              "14                      156.0  ...                        0.006579   \n",
              "15                      190.0  ...                        0.018349   \n",
              "16                      262.0  ...                        0.020270   \n",
              "17                       36.0  ...                        0.002924   \n",
              "18                        0.0  ...                        0.002825   \n",
              "19                       17.0  ...                        0.021277   \n",
              "20                      146.0  ...                        0.015924   \n",
              "21                       25.0  ...                        0.027027   \n",
              "22                        0.0  ...                        0.003135   \n",
              "23                       54.0  ...                        0.022124   \n",
              "24                      283.0  ...                        0.011905   \n",
              "25                      206.0  ...                        0.022951   \n",
              "26                      104.0  ...                        0.020833   \n",
              "27                      274.0  ...                        0.024306   \n",
              "28                        0.0  ...                        0.003165   \n",
              "29                      261.0  ...                        0.024221   \n",
              "30                       33.0  ...                        0.466667   \n",
              "31                      272.0  ...                        0.041420   \n",
              "32                        0.0  ...                        0.003049   \n",
              "33                      289.0  ...                        0.034221   \n",
              "34                      165.0  ...                        0.033333   \n",
              "35                       69.0  ...                        0.069767   \n",
              "36                      290.0  ...                        0.011869   \n",
              "37                      282.0  ...                        0.003125   \n",
              "38                       26.0  ...                        0.043103   \n",
              "39                      129.0  ...                        0.055215   \n",
              "40                       22.0  ...                        0.015326   \n",
              "41                        0.0  ...                        0.003135   \n",
              "42                        0.0  ...                        0.003058   \n",
              "43                       27.0  ...                        0.416667   \n",
              "44                       20.0  ...                        0.010870   \n",
              "45                       27.0  ...                        0.017422   \n",
              "46                        0.0  ...                        0.028169   \n",
              "47                      134.0  ...                        0.012987   \n",
              "48                       30.0  ...                        0.080000   \n",
              "49                       15.0  ...                        0.014652   \n",
              "50                      193.0  ...                        0.055172   \n",
              "51                       51.0  ...                        0.020896   \n",
              "52                       19.0  ...                        0.056180   \n",
              "53                       24.0  ...                        0.009901   \n",
              "54                       22.0  ...                        0.015337   \n",
              "55                      253.0  ...                        0.018382   \n",
              "56                       91.0  ...                        0.017241   \n",
              "57                       29.0  ...                        0.015291   \n",
              "\n",
              "    DN_OutlierInclude_p_001_mdrmd  DN_OutlierInclude_n_001_mdrmd  \\\n",
              "0                       -0.673333                       0.270000   \n",
              "1                        0.523333                      -0.062222   \n",
              "2                       -0.823333                       0.408889   \n",
              "3                       -0.701667                       0.583333   \n",
              "4                       -0.028889                       0.542778   \n",
              "5                       -0.897778                       0.568333   \n",
              "6                        0.555000                      -0.321667   \n",
              "7                       -0.531111                       0.635556   \n",
              "8                       -0.600556                      -0.375556   \n",
              "9                       -0.207778                       0.286667   \n",
              "10                       0.408889                      -0.183333   \n",
              "11                       0.300000                      -0.418889   \n",
              "12                      -0.007778                      -0.848889   \n",
              "13                      -0.646667                       0.562222   \n",
              "14                       0.635556                      -0.573333   \n",
              "15                      -0.932778                       0.408333   \n",
              "16                       0.660000                      -0.808889   \n",
              "17                      -0.842778                       0.711667   \n",
              "18                      -0.952222                       0.667778   \n",
              "19                      -0.136667                       0.550000   \n",
              "20                      -0.802222                       0.926111   \n",
              "21                      -0.857222                       0.528889   \n",
              "22                      -0.923333                       0.571111   \n",
              "23                      -0.678889                      -0.456111   \n",
              "24                      -0.786667                       0.672778   \n",
              "25                      -0.954444                       0.791111   \n",
              "26                      -0.881111                       0.836667   \n",
              "27                      -0.962222                      -0.843333   \n",
              "28                      -0.616667                       0.682222   \n",
              "29                      -0.941111                       0.817778   \n",
              "30                      -0.815556                       0.708889   \n",
              "31                      -0.933333                       0.110000   \n",
              "32                      -0.880556                       0.673333   \n",
              "33                      -0.388889                       0.585556   \n",
              "34                      -0.186667                       0.850000   \n",
              "35                      -0.886667                       0.945556   \n",
              "36                      -0.949444                       0.774444   \n",
              "37                      -0.883333                       0.683333   \n",
              "38                      -0.317778                       0.527778   \n",
              "39                      -0.956667                       0.212778   \n",
              "40                      -0.386111                       0.694444   \n",
              "41                      -0.923333                       0.346667   \n",
              "42                      -0.803333                       0.793333   \n",
              "43                       0.793333                      -0.348889   \n",
              "44                      -0.624444                       0.725556   \n",
              "45                      -0.817778                       0.375556   \n",
              "46                      -0.604444                       0.445000   \n",
              "47                      -0.764444                       0.546667   \n",
              "48                       0.017778                      -0.770000   \n",
              "49                      -0.932222                       0.367778   \n",
              "50                      -0.078889                      -0.830000   \n",
              "51                      -0.943889                      -0.756667   \n",
              "52                       0.520000                       0.859444   \n",
              "53                      -0.702222                       0.671111   \n",
              "54                      -0.886667                       0.835000   \n",
              "55                      -0.901111                       0.500000   \n",
              "56                      -0.537778                       0.593889   \n",
              "57                      -0.985556                       0.843333   \n",
              "\n",
              "    SP_Summaries_welch_rect_area_5_1  SB_BinaryStats_diff_longstretch0  \\\n",
              "0                           0.994990                              13.0   \n",
              "1                           0.975108                              10.0   \n",
              "2                           0.995906                              14.0   \n",
              "3                           0.994419                              14.0   \n",
              "4                           0.995561                              18.0   \n",
              "5                           0.993356                               9.0   \n",
              "6                           0.981665                              12.0   \n",
              "7                           0.996626                              20.0   \n",
              "8                           0.993662                              14.0   \n",
              "9                           0.982178                              11.0   \n",
              "10                          0.984604                              11.0   \n",
              "11                          0.996696                              21.0   \n",
              "12                          0.949011                              16.0   \n",
              "13                          0.988905                              12.0   \n",
              "14                          0.990450                              10.0   \n",
              "15                          0.984784                              13.0   \n",
              "16                          0.994543                              19.0   \n",
              "17                          0.990444                              10.0   \n",
              "18                          0.988002                              14.0   \n",
              "19                          0.941775                              13.0   \n",
              "20                          0.995319                              13.0   \n",
              "21                          0.942296                              10.0   \n",
              "22                          0.993068                              11.0   \n",
              "23                          0.990852                              11.0   \n",
              "24                          0.994063                              11.0   \n",
              "25                          0.991873                              20.0   \n",
              "26                          0.994359                              14.0   \n",
              "27                          0.987765                              19.0   \n",
              "28                          0.996022                              10.0   \n",
              "29                          0.991840                              14.0   \n",
              "30                          0.983763                              22.0   \n",
              "31                          0.993610                              14.0   \n",
              "32                          0.991869                               7.0   \n",
              "33                          0.996481                              17.0   \n",
              "34                          0.989038                              14.0   \n",
              "35                          0.987596                              12.0   \n",
              "36                          0.984701                              12.0   \n",
              "37                          0.993366                              11.0   \n",
              "38                          0.990303                              12.0   \n",
              "39                          0.986430                              13.0   \n",
              "40                          0.990335                              11.0   \n",
              "41                          0.988909                              23.0   \n",
              "42                          0.990702                               9.0   \n",
              "43                          0.961241                              13.0   \n",
              "44                          0.977887                              12.0   \n",
              "45                          0.993133                              16.0   \n",
              "46                          0.997391                              15.0   \n",
              "47                          0.983995                              14.0   \n",
              "48                          0.986902                              15.0   \n",
              "49                          0.971991                              13.0   \n",
              "50                          0.992968                              20.0   \n",
              "51                          0.986982                              13.0   \n",
              "52                          0.984740                              11.0   \n",
              "53                          0.994615                              13.0   \n",
              "54                          0.991874                              15.0   \n",
              "55                          0.993576                              12.0   \n",
              "56                          0.993763                              19.0   \n",
              "57                          0.967279                              17.0   \n",
              "\n",
              "    SB_MotifThree_quantile_hh  SC_FluctAnal_2_rsrangefit_50_1_logi_prop_r1  \\\n",
              "0                    1.270030                                     0.148936   \n",
              "1                    1.514048                                     0.212766   \n",
              "2                    1.288290                                     0.127660   \n",
              "3                    1.348453                                     0.148936   \n",
              "4                    1.295804                                     0.127660   \n",
              "5                    1.333818                                     0.191489   \n",
              "6                    1.523619                                     0.148936   \n",
              "7                    1.241475                                     0.170213   \n",
              "8                    1.443646                                     0.170213   \n",
              "9                    1.542617                                     0.170213   \n",
              "10                   1.554089                                     0.170213   \n",
              "11                   1.337556                                     0.234043   \n",
              "12                   1.533941                                     0.127660   \n",
              "13                   1.413804                                     0.297872   \n",
              "14                   1.291778                                     0.872340   \n",
              "15                   1.341768                                     0.702128   \n",
              "16                   1.277868                                     0.638298   \n",
              "17                   1.276468                                     0.468085   \n",
              "18                   1.338455                                     0.680851   \n",
              "19                   1.542230                                     0.148936   \n",
              "20                   1.379495                                     0.170213   \n",
              "21                   1.540534                                     0.127660   \n",
              "22                   1.220071                                     0.638298   \n",
              "23                   1.352696                                     0.191489   \n",
              "24                   1.338455                                     0.127660   \n",
              "25                   1.323871                                     0.510638   \n",
              "26                   1.454432                                     0.148936   \n",
              "27                   1.307118                                     0.617021   \n",
              "28                   1.211421                                     0.510638   \n",
              "29                   1.260595                                     0.787234   \n",
              "30                   1.478811                                     0.276596   \n",
              "31                   1.287702                                     0.127660   \n",
              "32                   1.224287                                     0.255319   \n",
              "33                   1.233710                                     0.170213   \n",
              "34                   1.392926                                     0.425532   \n",
              "35                   1.712133                                     0.297872   \n",
              "36                   1.335596                                     0.595745   \n",
              "37                   1.359488                                     0.425532   \n",
              "38                   1.418031                                     0.170213   \n",
              "39                   1.593209                                     0.148936   \n",
              "40                   1.312722                                     0.127660   \n",
              "41                   1.353119                                     0.127660   \n",
              "42                   1.333818                                     0.829787   \n",
              "43                   1.532420                                     0.191489   \n",
              "44                   1.471846                                     0.148936   \n",
              "45                   1.311380                                     0.170213   \n",
              "46                   1.334889                                     0.191489   \n",
              "47                   1.348453                                     0.148936   \n",
              "48                   1.468207                                     0.191489   \n",
              "49                   1.433192                                     0.127660   \n",
              "50                   1.335338                                     0.170213   \n",
              "51                   1.431331                                     0.595745   \n",
              "52                   1.451884                                     0.191489   \n",
              "53                   1.269879                                     0.872340   \n",
              "54                   1.399781                                     0.127660   \n",
              "55                   1.265859                                     0.127660   \n",
              "56                   1.339380                                     0.255319   \n",
              "57                   1.440512                                     0.361702   \n",
              "\n",
              "    SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1  SP_Summaries_welch_rect_centroid  \\\n",
              "0                                 0.829787                          0.006136   \n",
              "1                                 0.127660                          0.036816   \n",
              "2                                 0.723404                          0.006136   \n",
              "3                                 0.851064                          0.006136   \n",
              "4                                 0.872340                          0.006136   \n",
              "5                                 0.872340                          0.006136   \n",
              "6                                 0.872340                          0.257709   \n",
              "7                                 0.829787                          0.006136   \n",
              "8                                 0.872340                          0.024544   \n",
              "9                                 0.234043                          0.227029   \n",
              "10                                0.127660                          0.055223   \n",
              "11                                0.127660                          0.012272   \n",
              "12                                0.872340                          0.128854   \n",
              "13                                0.872340                          0.042951   \n",
              "14                                0.787234                          0.006136   \n",
              "15                                0.361702                          0.030680   \n",
              "16                                0.574468                          0.006136   \n",
              "17                                0.574468                          0.006136   \n",
              "18                                0.382979                          0.012272   \n",
              "19                                0.808511                          0.024544   \n",
              "20                                0.872340                          0.012272   \n",
              "21                                0.829787                          0.024544   \n",
              "22                                0.872340                          0.006136   \n",
              "23                                0.872340                          0.018408   \n",
              "24                                0.829787                          0.006136   \n",
              "25                                0.851064                          0.006136   \n",
              "26                                0.872340                          0.012272   \n",
              "27                                0.468085                          0.042951   \n",
              "28                                0.234043                          0.006136   \n",
              "29                                0.872340                          0.006136   \n",
              "30                                0.127660                          0.141126   \n",
              "31                                0.851064                          0.012272   \n",
              "32                                0.127660                          0.006136   \n",
              "33                                0.829787                          0.006136   \n",
              "34                                0.148936                          0.018408   \n",
              "35                                0.851064                          0.036816   \n",
              "36                                0.851064                          0.006136   \n",
              "37                                0.255319                          0.006136   \n",
              "38                                0.127660                          0.018408   \n",
              "39                                0.872340                          0.012272   \n",
              "40                                0.851064                          0.006136   \n",
              "41                                0.808511                          0.006136   \n",
              "42                                0.382979                          0.006136   \n",
              "43                                0.127660                          0.220893   \n",
              "44                                0.808511                          0.006136   \n",
              "45                                0.872340                          0.006136   \n",
              "46                                0.872340                          0.006136   \n",
              "47                                0.872340                          0.006136   \n",
              "48                                0.851064                          0.067495   \n",
              "49                                0.255319                          0.012272   \n",
              "50                                0.872340                          0.012272   \n",
              "51                                0.468085                          0.030680   \n",
              "52                                0.851064                          0.030680   \n",
              "53                                0.851064                          0.006136   \n",
              "54                                0.851064                          0.006136   \n",
              "55                                0.851064                          0.006136   \n",
              "56                                0.851064                          0.006136   \n",
              "57                                0.127660                          0.055223   \n",
              "\n",
              "    FC_LocalSimple_mean3_stderr  \n",
              "0                      0.135333  \n",
              "1                      0.369431  \n",
              "2                      0.113223  \n",
              "3                      0.088297  \n",
              "4                      0.136545  \n",
              "5                      0.052032  \n",
              "6                      0.457907  \n",
              "7                      0.097188  \n",
              "8                      0.173754  \n",
              "9                      0.467007  \n",
              "10                     0.367303  \n",
              "11                     0.203264  \n",
              "12                     0.447608  \n",
              "13                     0.309761  \n",
              "14                     0.130429  \n",
              "15                     0.201063  \n",
              "16                     0.125602  \n",
              "17                     0.120859  \n",
              "18                     0.106680  \n",
              "19                     0.443191  \n",
              "20                     0.118217  \n",
              "21                     0.429501  \n",
              "22                     0.051919  \n",
              "23                     0.193219  \n",
              "24                     0.128713  \n",
              "25                     0.110496  \n",
              "26                     0.137766  \n",
              "27                     0.158317  \n",
              "28                     0.045121  \n",
              "29                     0.106749  \n",
              "30                     0.342600  \n",
              "31                     0.098374  \n",
              "32                     0.050993  \n",
              "33                     0.079779  \n",
              "34                     0.180425  \n",
              "35                     0.206056  \n",
              "36                     0.167103  \n",
              "37                     0.098501  \n",
              "38                     0.310670  \n",
              "39                     0.095764  \n",
              "40                     0.188269  \n",
              "41                     0.105357  \n",
              "42                     0.090994  \n",
              "43                     0.460856  \n",
              "44                     0.345090  \n",
              "45                     0.178764  \n",
              "46                     0.061331  \n",
              "47                     0.190187  \n",
              "48                     0.298779  \n",
              "49                     0.152199  \n",
              "50                     0.118083  \n",
              "51                     0.221496  \n",
              "52                     0.329502  \n",
              "53                     0.109059  \n",
              "54                     0.143026  \n",
              "55                     0.057401  \n",
              "56                     0.173564  \n",
              "57                     0.227309  \n",
              "\n",
              "[58 rows x 22 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features = np.array([catch22.catch22_all(timeSeriesAux[i][0,:])['values'] for i in range(len(timeSeriesAux))])\n",
        "dfextract = pd.DataFrame(features, columns=fnames22)\n",
        "dfextract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3WW7o_BFzML"
      },
      "source": [
        "## Funções utilizadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O7eyP9FGBXN"
      },
      "source": [
        "Primeiro, funções utilizadas para gerar os splits do kfold e baixá-los para futura reprodutibilidade do experimento, detalhe, os folds não estão normalizados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjMvtOeoF1Sx"
      },
      "outputs": [],
      "source": [
        "# def split_train_valid(train_index, lenValSet):\n",
        "#   np.random.shuffle(train_index)\n",
        "\n",
        "#   val_index = []\n",
        "#   for i in train_index:\n",
        "#     if not i in val_index:\n",
        "#       val_index.append(i)\n",
        "#     if len(val_index) == lenValSet:\n",
        "#       break\n",
        "#   val_index = sorted(val_index)\n",
        "\n",
        "#   train_index = sorted(train_index[lenValSet:])\n",
        "\n",
        "#   return train_index, val_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mgim2VCsGRiT"
      },
      "outputs": [],
      "source": [
        "# def get_folds():\n",
        "#     kf = KFold(n_splits=10)\n",
        "#     i = 0\n",
        "\n",
        "#     for train_index, test_index in kf.split(dfextract2):\n",
        "#         lenValSet = len(test_index)\n",
        "#         train_index, val_index = split_train_valid(train_index, lenValSet)\n",
        "\n",
        "#         X_train, X_val, X_test, y_train, y_val, y_test = (\n",
        "#             dfextract2.loc[train_index],\n",
        "#             dfextract2.loc[val_index],\n",
        "#             dfextract2.loc[test_index],\n",
        "#             df2.loc[train_index],\n",
        "#             df2.loc[val_index],\n",
        "#             df2.loc[test_index],\n",
        "#         )\n",
        "\n",
        "#         X_train.drop(columns=\"index\", inplace = True)\n",
        "#         X_val.drop(columns=\"index\", inplace = True)\n",
        "#         X_train = np.concatenate((X_train, X_val), axis=0)\n",
        "#         y_train = pd.concat([y_train,y_val])\n",
        "\n",
        "#         X_test.drop(columns=\"index\", inplace = True)\n",
        "\n",
        "#         np.save(\"/content/drive/MyDrive/Colab Notebooks/diego/xtreino\" + str(i), X_train)\n",
        "#         np.save(\"/content/drive/MyDrive/Colab Notebooks/diego/xteste\" + str(i), X_test)\n",
        "#         y_train.to_pickle(\"/content/drive/MyDrive/Colab Notebooks/diego/ytreino\" + str(i) + \".pkl\")\n",
        "#         y_test.to_pickle(\"/content/drive/MyDrive/Colab Notebooks/diego/yteste\" + str(i) + \".pkl\")\n",
        "#         i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Loot1vavGe3f"
      },
      "source": [
        "Função para normalizar caso venham a ser utilizados algoritmos de distância (knn, por exemplo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ncm_hMesGka1"
      },
      "outputs": [],
      "source": [
        "def normalize_parameters(parameters):\n",
        "    norm = MinMaxScaler(feature_range = (0,1))\n",
        "    normalized_param = np.reshape(parameters,(parameters.shape[0],1))\n",
        "    normalized_param = norm.fit_transform(normalized_param)\n",
        "\n",
        "    return normalized_param, norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuJC8wLOIxGZ"
      },
      "source": [
        "Funções para rodar os modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsaCnOgFJicH"
      },
      "outputs": [],
      "source": [
        "def get_targets(target):\n",
        "  nan_df = dataframe[target].isna()\n",
        "  nan_df = [not elem for elem in nan_df]\n",
        "\n",
        "  df2 = dataframe[nan_df]\n",
        "  dfextract2 = dfextract[nan_df]\n",
        "  dfextract2.reset_index(inplace = True)\n",
        "\n",
        "  df2.reset_index(inplace = True)\n",
        "\n",
        "  return  dfextract2, df2[target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaBIiUv-LhtT"
      },
      "outputs": [],
      "source": [
        "def run_exp(model,grid,target):\n",
        "    preds = np.zeros([dfextract2.shape[0]], dtype=float)\n",
        "\n",
        "    for i in range(10):\n",
        "\n",
        "        print(\"iteration \" + str(i))\n",
        "        X_train = np.load(\"/content/xtreino\" + str(i) + \".npy\",allow_pickle=True)\n",
        "        y_train = pd.read_pickle(\"/content/ytreino\" + str(i) + \".pkl\")\n",
        "        y_train = y_train[target]\n",
        "\n",
        "        X_test = np.load(\"/content/xteste\" + str(i) + \".npy\",allow_pickle=True)\n",
        "        y_test = pd.read_pickle(\"/content/yteste\" + str(i) + \".pkl\")\n",
        "        test_index = y_test.index\n",
        "        y_test = y_test[target]\n",
        "\n",
        "        # Perform grid search to find the best hyperparameters\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=model,\n",
        "            param_grid=grid,\n",
        "            n_jobs=-1,\n",
        "            verbose=1,\n",
        "            cv = 5\n",
        "        )\n",
        "\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "        # Get the best model from the grid search\n",
        "        reg = grid_search.best_estimator_\n",
        "\n",
        "        reg.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "        y_pred = reg.predict(X_test)\n",
        "\n",
        "        y_pred = y_pred.reshape(-1, 1)\n",
        "\n",
        "        preds[test_index] = y_pred.reshape(preds[test_index].shape)\n",
        "\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJHP06ipI5Qs"
      },
      "source": [
        "Baixando os folds salvos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "sIRHVYM7Rs_9",
        "outputId": "b5935b63-74ab-4a29-80c4-0313fa0f4226"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12s4qWG42Qp3iU6MTh03oNf4Tzqo95dXd\n",
            "To: /content/folds.zip\n",
            "100%|██████████| 151k/151k [00:00<00:00, 49.2MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'folds.zip'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = \"https://drive.google.com/file/d/12s4qWG42Qp3iU6MTh03oNf4Tzqo95dXd/view?usp=sharing\"\n",
        "output = \"folds.zip\"\n",
        "gdown.download(url, output, quiet=False, fuzzy=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJj5HhGNR3PK",
        "outputId": "c6202822-a13b-4f66-96a7-f3532d651458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/folds.zip\n",
            "  inflating: ytreino9.pkl            \n",
            "  inflating: xteste8.npy             \n",
            "  inflating: ytreino2.pkl            \n",
            "  inflating: xtreino6.npy            \n",
            "  inflating: xtreino2.npy            \n",
            "  inflating: xtreino0.npy            \n",
            "  inflating: ytreino6.pkl            \n",
            "  inflating: yteste6.pkl             \n",
            "  inflating: yteste7.pkl             \n",
            "  inflating: ytreino0.pkl            \n",
            "  inflating: xtreino7.npy            \n",
            "  inflating: yteste4.pkl             \n",
            "  inflating: yteste5.pkl             \n",
            "  inflating: xtreino5.npy            \n",
            "  inflating: ytreino7.pkl            \n",
            "  inflating: ytreino8.pkl            \n",
            "  inflating: xtreino3.npy            \n",
            "  inflating: ytreino4.pkl            \n",
            "  inflating: yteste8.pkl             \n",
            "  inflating: xtreino8.npy            \n",
            "  inflating: ytreino3.pkl            \n",
            "  inflating: yteste9.pkl             \n",
            "  inflating: xtreino9.npy            \n",
            "  inflating: ytreino5.pkl            \n",
            "  inflating: yteste2.pkl             \n",
            "  inflating: yteste3.pkl             \n",
            "  inflating: xteste9.npy             \n",
            "  inflating: yteste0.pkl             \n",
            "  inflating: yteste1.pkl             \n",
            "  inflating: ytreino1.pkl            \n",
            "  inflating: xtreino4.npy            \n",
            "  inflating: xtreino1.npy            \n",
            "  inflating: xteste2.npy             \n",
            "  inflating: xteste0.npy             \n",
            "  inflating: xteste5.npy             \n",
            "  inflating: xteste6.npy             \n",
            "  inflating: xteste3.npy             \n",
            "  inflating: xteste1.npy             \n",
            "  inflating: xteste7.npy             \n",
            "  inflating: xteste4.npy             \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/folds.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVdUs6VXNsxn"
      },
      "source": [
        "Definindo os targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz8iDSZ3NsOM"
      },
      "outputs": [],
      "source": [
        "targets = ['ERITRÓCITOS [x10⁶/μL]','PLAQUETAS [n°/mm³]' , 'LEUCÓCITOS [n°/mm³]' ,'HEMOGLOBINA [g/dL]']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL-7T_VaFxAb"
      },
      "source": [
        "## CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utBAWxJLF44S",
        "outputId": "aa0f371e-28e0-4aff-d79e-7d6b9123c1b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "from catboost import CatBoostRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kgowk-CEEDCr"
      },
      "outputs": [],
      "source": [
        "model = CatBoostRegressor()\n",
        "grid = {'learning_rate': [0.03, 0.1],\n",
        "        'depth': [4, 6, 10],\n",
        "        'l2_leaf_reg': [1, 3, 5, 7]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U1zX7EtX034p",
        "outputId": "a1abb3f8-d9d4-4e01-f4c3-2a293fa93fe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration 0\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "0:\tlearn: 0.5155193\ttotal: 10ms\tremaining: 9.99s\n",
            "1:\tlearn: 0.5041317\ttotal: 14.8ms\tremaining: 7.38s\n",
            "2:\tlearn: 0.4923521\ttotal: 23.7ms\tremaining: 7.87s\n",
            "3:\tlearn: 0.4818788\ttotal: 31.7ms\tremaining: 7.9s\n",
            "4:\tlearn: 0.4692249\ttotal: 38.9ms\tremaining: 7.74s\n",
            "5:\tlearn: 0.4550076\ttotal: 46.4ms\tremaining: 7.69s\n",
            "6:\tlearn: 0.4448427\ttotal: 53.5ms\tremaining: 7.59s\n",
            "7:\tlearn: 0.4343420\ttotal: 60.5ms\tremaining: 7.5s\n",
            "8:\tlearn: 0.4238805\ttotal: 67.7ms\tremaining: 7.45s\n",
            "9:\tlearn: 0.4139966\ttotal: 74.6ms\tremaining: 7.38s\n",
            "10:\tlearn: 0.4042411\ttotal: 81.4ms\tremaining: 7.32s\n",
            "11:\tlearn: 0.3926621\ttotal: 89ms\tremaining: 7.32s\n",
            "12:\tlearn: 0.3845368\ttotal: 91.4ms\tremaining: 6.94s\n",
            "13:\tlearn: 0.3738907\ttotal: 98.7ms\tremaining: 6.95s\n",
            "14:\tlearn: 0.3645914\ttotal: 106ms\tremaining: 6.95s\n",
            "15:\tlearn: 0.3545210\ttotal: 113ms\tremaining: 6.96s\n",
            "16:\tlearn: 0.3445194\ttotal: 116ms\tremaining: 6.68s\n",
            "17:\tlearn: 0.3344455\ttotal: 123ms\tremaining: 6.71s\n",
            "18:\tlearn: 0.3257406\ttotal: 130ms\tremaining: 6.72s\n",
            "19:\tlearn: 0.3175869\ttotal: 134ms\tremaining: 6.57s\n",
            "20:\tlearn: 0.3101109\ttotal: 135ms\tremaining: 6.3s\n",
            "21:\tlearn: 0.3022513\ttotal: 143ms\tremaining: 6.37s\n",
            "22:\tlearn: 0.2956292\ttotal: 150ms\tremaining: 6.39s\n",
            "23:\tlearn: 0.2867630\ttotal: 158ms\tremaining: 6.41s\n",
            "24:\tlearn: 0.2805233\ttotal: 165ms\tremaining: 6.42s\n",
            "25:\tlearn: 0.2744802\ttotal: 172ms\tremaining: 6.44s\n",
            "26:\tlearn: 0.2671565\ttotal: 179ms\tremaining: 6.45s\n",
            "27:\tlearn: 0.2604491\ttotal: 188ms\tremaining: 6.54s\n",
            "28:\tlearn: 0.2553337\ttotal: 190ms\tremaining: 6.36s\n",
            "29:\tlearn: 0.2489354\ttotal: 192ms\tremaining: 6.22s\n",
            "30:\tlearn: 0.2415616\ttotal: 194ms\tremaining: 6.06s\n",
            "31:\tlearn: 0.2357047\ttotal: 198ms\tremaining: 5.97s\n",
            "32:\tlearn: 0.2321340\ttotal: 200ms\tremaining: 5.86s\n",
            "33:\tlearn: 0.2264794\ttotal: 210ms\tremaining: 5.98s\n",
            "34:\tlearn: 0.2203902\ttotal: 217ms\tremaining: 5.99s\n",
            "35:\tlearn: 0.2165466\ttotal: 220ms\tremaining: 5.88s\n",
            "36:\tlearn: 0.2110865\ttotal: 224ms\tremaining: 5.83s\n",
            "37:\tlearn: 0.2058469\ttotal: 231ms\tremaining: 5.85s\n",
            "38:\tlearn: 0.2005133\ttotal: 238ms\tremaining: 5.87s\n",
            "39:\tlearn: 0.1950738\ttotal: 242ms\tremaining: 5.81s\n",
            "40:\tlearn: 0.1903034\ttotal: 249ms\tremaining: 5.82s\n",
            "41:\tlearn: 0.1853582\ttotal: 256ms\tremaining: 5.83s\n",
            "42:\tlearn: 0.1804987\ttotal: 263ms\tremaining: 5.85s\n",
            "43:\tlearn: 0.1766287\ttotal: 264ms\tremaining: 5.74s\n",
            "44:\tlearn: 0.1720583\ttotal: 272ms\tremaining: 5.78s\n",
            "45:\tlearn: 0.1677678\ttotal: 279ms\tremaining: 5.79s\n",
            "46:\tlearn: 0.1625646\ttotal: 286ms\tremaining: 5.81s\n",
            "47:\tlearn: 0.1585859\ttotal: 290ms\tremaining: 5.76s\n",
            "48:\tlearn: 0.1570425\ttotal: 291ms\tremaining: 5.65s\n",
            "49:\tlearn: 0.1539663\ttotal: 295ms\tremaining: 5.61s\n",
            "50:\tlearn: 0.1501108\ttotal: 302ms\tremaining: 5.63s\n",
            "51:\tlearn: 0.1467327\ttotal: 309ms\tremaining: 5.64s\n",
            "52:\tlearn: 0.1430539\ttotal: 316ms\tremaining: 5.65s\n",
            "53:\tlearn: 0.1394940\ttotal: 323ms\tremaining: 5.67s\n",
            "54:\tlearn: 0.1367200\ttotal: 331ms\tremaining: 5.68s\n",
            "55:\tlearn: 0.1347959\ttotal: 333ms\tremaining: 5.62s\n",
            "56:\tlearn: 0.1308333\ttotal: 340ms\tremaining: 5.63s\n",
            "57:\tlearn: 0.1283309\ttotal: 348ms\tremaining: 5.65s\n",
            "58:\tlearn: 0.1250744\ttotal: 355ms\tremaining: 5.67s\n",
            "59:\tlearn: 0.1222501\ttotal: 363ms\tremaining: 5.68s\n",
            "60:\tlearn: 0.1207115\ttotal: 367ms\tremaining: 5.65s\n",
            "61:\tlearn: 0.1176994\ttotal: 374ms\tremaining: 5.66s\n",
            "62:\tlearn: 0.1151919\ttotal: 382ms\tremaining: 5.68s\n",
            "63:\tlearn: 0.1123651\ttotal: 389ms\tremaining: 5.69s\n",
            "64:\tlearn: 0.1098001\ttotal: 396ms\tremaining: 5.7s\n",
            "65:\tlearn: 0.1071086\ttotal: 404ms\tremaining: 5.71s\n",
            "66:\tlearn: 0.1040775\ttotal: 417ms\tremaining: 5.81s\n",
            "67:\tlearn: 0.1013712\ttotal: 424ms\tremaining: 5.82s\n",
            "68:\tlearn: 0.0989101\ttotal: 432ms\tremaining: 5.82s\n",
            "69:\tlearn: 0.0964136\ttotal: 439ms\tremaining: 5.83s\n",
            "70:\tlearn: 0.0939282\ttotal: 446ms\tremaining: 5.84s\n",
            "71:\tlearn: 0.0916190\ttotal: 454ms\tremaining: 5.85s\n",
            "72:\tlearn: 0.0892015\ttotal: 461ms\tremaining: 5.86s\n",
            "73:\tlearn: 0.0869886\ttotal: 468ms\tremaining: 5.86s\n",
            "74:\tlearn: 0.0848484\ttotal: 476ms\tremaining: 5.87s\n",
            "75:\tlearn: 0.0827617\ttotal: 483ms\tremaining: 5.87s\n",
            "76:\tlearn: 0.0806972\ttotal: 490ms\tremaining: 5.87s\n",
            "77:\tlearn: 0.0786540\ttotal: 497ms\tremaining: 5.87s\n",
            "78:\tlearn: 0.0766769\ttotal: 504ms\tremaining: 5.87s\n",
            "79:\tlearn: 0.0747750\ttotal: 511ms\tremaining: 5.87s\n",
            "80:\tlearn: 0.0729002\ttotal: 518ms\tremaining: 5.87s\n",
            "81:\tlearn: 0.0706989\ttotal: 525ms\tremaining: 5.88s\n",
            "82:\tlearn: 0.0687038\ttotal: 532ms\tremaining: 5.88s\n",
            "83:\tlearn: 0.0670144\ttotal: 539ms\tremaining: 5.88s\n",
            "84:\tlearn: 0.0653680\ttotal: 546ms\tremaining: 5.88s\n",
            "85:\tlearn: 0.0637221\ttotal: 554ms\tremaining: 5.88s\n",
            "86:\tlearn: 0.0621469\ttotal: 561ms\tremaining: 5.88s\n",
            "87:\tlearn: 0.0605498\ttotal: 568ms\tremaining: 5.88s\n",
            "88:\tlearn: 0.0590598\ttotal: 575ms\tremaining: 5.88s\n",
            "89:\tlearn: 0.0575570\ttotal: 582ms\tremaining: 5.88s\n",
            "90:\tlearn: 0.0561046\ttotal: 589ms\tremaining: 5.88s\n",
            "91:\tlearn: 0.0547259\ttotal: 596ms\tremaining: 5.88s\n",
            "92:\tlearn: 0.0533679\ttotal: 603ms\tremaining: 5.88s\n",
            "93:\tlearn: 0.0520324\ttotal: 610ms\tremaining: 5.88s\n",
            "94:\tlearn: 0.0507134\ttotal: 621ms\tremaining: 5.91s\n",
            "95:\tlearn: 0.0494166\ttotal: 628ms\tremaining: 5.91s\n",
            "96:\tlearn: 0.0481832\ttotal: 636ms\tremaining: 5.92s\n",
            "97:\tlearn: 0.0469633\ttotal: 643ms\tremaining: 5.92s\n",
            "98:\tlearn: 0.0457750\ttotal: 650ms\tremaining: 5.91s\n",
            "99:\tlearn: 0.0446166\ttotal: 657ms\tremaining: 5.91s\n",
            "100:\tlearn: 0.0434893\ttotal: 665ms\tremaining: 5.92s\n",
            "101:\tlearn: 0.0423867\ttotal: 673ms\tremaining: 5.93s\n",
            "102:\tlearn: 0.0413318\ttotal: 682ms\tremaining: 5.94s\n",
            "103:\tlearn: 0.0402871\ttotal: 690ms\tremaining: 5.94s\n",
            "104:\tlearn: 0.0392735\ttotal: 697ms\tremaining: 5.94s\n",
            "105:\tlearn: 0.0382834\ttotal: 704ms\tremaining: 5.94s\n",
            "106:\tlearn: 0.0373327\ttotal: 711ms\tremaining: 5.93s\n",
            "107:\tlearn: 0.0363934\ttotal: 718ms\tremaining: 5.93s\n",
            "108:\tlearn: 0.0354788\ttotal: 725ms\tremaining: 5.92s\n",
            "109:\tlearn: 0.0345827\ttotal: 732ms\tremaining: 5.92s\n",
            "110:\tlearn: 0.0337256\ttotal: 740ms\tremaining: 5.92s\n",
            "111:\tlearn: 0.0328787\ttotal: 748ms\tremaining: 5.93s\n",
            "112:\tlearn: 0.0320487\ttotal: 756ms\tremaining: 5.93s\n",
            "113:\tlearn: 0.0312402\ttotal: 763ms\tremaining: 5.93s\n",
            "114:\tlearn: 0.0304560\ttotal: 769ms\tremaining: 5.92s\n",
            "115:\tlearn: 0.0296882\ttotal: 776ms\tremaining: 5.91s\n",
            "116:\tlearn: 0.0289433\ttotal: 783ms\tremaining: 5.91s\n",
            "117:\tlearn: 0.0282141\ttotal: 790ms\tremaining: 5.91s\n",
            "118:\tlearn: 0.0275066\ttotal: 797ms\tremaining: 5.9s\n",
            "119:\tlearn: 0.0268140\ttotal: 804ms\tremaining: 5.89s\n",
            "120:\tlearn: 0.0261419\ttotal: 813ms\tremaining: 5.9s\n",
            "121:\tlearn: 0.0254841\ttotal: 822ms\tremaining: 5.92s\n",
            "122:\tlearn: 0.0248456\ttotal: 838ms\tremaining: 5.97s\n",
            "123:\tlearn: 0.0242208\ttotal: 845ms\tremaining: 5.97s\n",
            "124:\tlearn: 0.0236144\ttotal: 852ms\tremaining: 5.97s\n",
            "125:\tlearn: 0.0230140\ttotal: 859ms\tremaining: 5.96s\n",
            "126:\tlearn: 0.0224378\ttotal: 866ms\tremaining: 5.95s\n",
            "127:\tlearn: 0.0218764\ttotal: 873ms\tremaining: 5.95s\n",
            "128:\tlearn: 0.0213203\ttotal: 881ms\tremaining: 5.95s\n",
            "129:\tlearn: 0.0207868\ttotal: 887ms\tremaining: 5.94s\n",
            "130:\tlearn: 0.0202587\ttotal: 894ms\tremaining: 5.93s\n",
            "131:\tlearn: 0.0197518\ttotal: 901ms\tremaining: 5.92s\n",
            "132:\tlearn: 0.0192579\ttotal: 908ms\tremaining: 5.92s\n",
            "133:\tlearn: 0.0187687\ttotal: 915ms\tremaining: 5.91s\n",
            "134:\tlearn: 0.0182993\ttotal: 921ms\tremaining: 5.9s\n",
            "135:\tlearn: 0.0178347\ttotal: 932ms\tremaining: 5.92s\n",
            "136:\tlearn: 0.0173890\ttotal: 939ms\tremaining: 5.92s\n",
            "137:\tlearn: 0.0169544\ttotal: 946ms\tremaining: 5.91s\n",
            "138:\tlearn: 0.0165309\ttotal: 953ms\tremaining: 5.9s\n",
            "139:\tlearn: 0.0161180\ttotal: 960ms\tremaining: 5.9s\n",
            "140:\tlearn: 0.0157092\ttotal: 967ms\tremaining: 5.89s\n",
            "141:\tlearn: 0.0153169\ttotal: 974ms\tremaining: 5.89s\n",
            "142:\tlearn: 0.0149346\ttotal: 981ms\tremaining: 5.88s\n",
            "143:\tlearn: 0.0145619\ttotal: 988ms\tremaining: 5.87s\n",
            "144:\tlearn: 0.0141985\ttotal: 996ms\tremaining: 5.87s\n",
            "145:\tlearn: 0.0138444\ttotal: 1s\tremaining: 5.86s\n",
            "146:\tlearn: 0.0134992\ttotal: 1.01s\tremaining: 5.85s\n",
            "147:\tlearn: 0.0131571\ttotal: 1.01s\tremaining: 5.85s\n",
            "148:\tlearn: 0.0128291\ttotal: 1.02s\tremaining: 5.84s\n",
            "149:\tlearn: 0.0125094\ttotal: 1.03s\tremaining: 5.85s\n",
            "150:\tlearn: 0.0121977\ttotal: 1.04s\tremaining: 5.84s\n",
            "151:\tlearn: 0.0118940\ttotal: 1.05s\tremaining: 5.84s\n",
            "152:\tlearn: 0.0115979\ttotal: 1.05s\tremaining: 5.84s\n",
            "153:\tlearn: 0.0113092\ttotal: 1.06s\tremaining: 5.83s\n",
            "154:\tlearn: 0.0110279\ttotal: 1.07s\tremaining: 5.83s\n",
            "155:\tlearn: 0.0107537\ttotal: 1.08s\tremaining: 5.83s\n",
            "156:\tlearn: 0.0104816\ttotal: 1.08s\tremaining: 5.82s\n",
            "157:\tlearn: 0.0102210\ttotal: 1.09s\tremaining: 5.82s\n",
            "158:\tlearn: 0.0099670\ttotal: 1.1s\tremaining: 5.81s\n",
            "159:\tlearn: 0.0097194\ttotal: 1.1s\tremaining: 5.8s\n",
            "160:\tlearn: 0.0094781\ttotal: 1.11s\tremaining: 5.79s\n",
            "161:\tlearn: 0.0092429\ttotal: 1.12s\tremaining: 5.79s\n",
            "162:\tlearn: 0.0090136\ttotal: 1.13s\tremaining: 5.78s\n",
            "163:\tlearn: 0.0087901\ttotal: 1.13s\tremaining: 5.78s\n",
            "164:\tlearn: 0.0085723\ttotal: 1.14s\tremaining: 5.78s\n",
            "165:\tlearn: 0.0083551\ttotal: 1.15s\tremaining: 5.77s\n",
            "166:\tlearn: 0.0081435\ttotal: 1.16s\tremaining: 5.79s\n",
            "167:\tlearn: 0.0079417\ttotal: 1.17s\tremaining: 5.78s\n",
            "168:\tlearn: 0.0077407\ttotal: 1.18s\tremaining: 5.78s\n",
            "169:\tlearn: 0.0075448\ttotal: 1.18s\tremaining: 5.78s\n",
            "170:\tlearn: 0.0073555\ttotal: 1.19s\tremaining: 5.77s\n",
            "171:\tlearn: 0.0071732\ttotal: 1.2s\tremaining: 5.77s\n",
            "172:\tlearn: 0.0069918\ttotal: 1.21s\tremaining: 5.77s\n",
            "173:\tlearn: 0.0068150\ttotal: 1.21s\tremaining: 5.76s\n",
            "174:\tlearn: 0.0066439\ttotal: 1.22s\tremaining: 5.77s\n",
            "175:\tlearn: 0.0064793\ttotal: 1.23s\tremaining: 5.77s\n",
            "176:\tlearn: 0.0063155\ttotal: 1.24s\tremaining: 5.76s\n",
            "177:\tlearn: 0.0061560\ttotal: 1.25s\tremaining: 5.76s\n",
            "178:\tlearn: 0.0060015\ttotal: 1.25s\tremaining: 5.76s\n",
            "179:\tlearn: 0.0058528\ttotal: 1.26s\tremaining: 5.75s\n",
            "180:\tlearn: 0.0057050\ttotal: 1.27s\tremaining: 5.75s\n",
            "181:\tlearn: 0.0055610\ttotal: 1.28s\tremaining: 5.74s\n",
            "182:\tlearn: 0.0054232\ttotal: 1.28s\tremaining: 5.74s\n",
            "183:\tlearn: 0.0052872\ttotal: 1.29s\tremaining: 5.73s\n",
            "184:\tlearn: 0.0051539\ttotal: 1.3s\tremaining: 5.73s\n",
            "185:\tlearn: 0.0050239\ttotal: 1.31s\tremaining: 5.72s\n",
            "186:\tlearn: 0.0048994\ttotal: 1.32s\tremaining: 5.72s\n",
            "187:\tlearn: 0.0047759\ttotal: 1.32s\tremaining: 5.72s\n",
            "188:\tlearn: 0.0046555\ttotal: 1.33s\tremaining: 5.72s\n",
            "189:\tlearn: 0.0045388\ttotal: 1.34s\tremaining: 5.72s\n",
            "190:\tlearn: 0.0044263\ttotal: 1.35s\tremaining: 5.71s\n",
            "191:\tlearn: 0.0043148\ttotal: 1.36s\tremaining: 5.71s\n",
            "192:\tlearn: 0.0042062\ttotal: 1.36s\tremaining: 5.71s\n",
            "193:\tlearn: 0.0041020\ttotal: 1.37s\tremaining: 5.71s\n",
            "194:\tlearn: 0.0039987\ttotal: 1.38s\tremaining: 5.71s\n",
            "195:\tlearn: 0.0038984\ttotal: 1.39s\tremaining: 5.71s\n",
            "196:\tlearn: 0.0038006\ttotal: 1.4s\tremaining: 5.71s\n",
            "197:\tlearn: 0.0037053\ttotal: 1.41s\tremaining: 5.7s\n",
            "198:\tlearn: 0.0036125\ttotal: 1.41s\tremaining: 5.7s\n",
            "199:\tlearn: 0.0035220\ttotal: 1.43s\tremaining: 5.7s\n",
            "200:\tlearn: 0.0034339\ttotal: 1.43s\tremaining: 5.7s\n",
            "201:\tlearn: 0.0033480\ttotal: 1.44s\tremaining: 5.69s\n",
            "202:\tlearn: 0.0032641\ttotal: 1.45s\tremaining: 5.68s\n",
            "203:\tlearn: 0.0031825\ttotal: 1.45s\tremaining: 5.68s\n",
            "204:\tlearn: 0.0031031\ttotal: 1.46s\tremaining: 5.67s\n",
            "205:\tlearn: 0.0030256\ttotal: 1.47s\tremaining: 5.66s\n",
            "206:\tlearn: 0.0029501\ttotal: 1.48s\tremaining: 5.66s\n",
            "207:\tlearn: 0.0028762\ttotal: 1.48s\tremaining: 5.65s\n",
            "208:\tlearn: 0.0028045\ttotal: 1.49s\tremaining: 5.64s\n",
            "209:\tlearn: 0.0027347\ttotal: 1.5s\tremaining: 5.63s\n",
            "210:\tlearn: 0.0026666\ttotal: 1.5s\tremaining: 5.63s\n",
            "211:\tlearn: 0.0025998\ttotal: 1.51s\tremaining: 5.62s\n",
            "212:\tlearn: 0.0025338\ttotal: 1.52s\tremaining: 5.62s\n",
            "213:\tlearn: 0.0024707\ttotal: 1.53s\tremaining: 5.61s\n",
            "214:\tlearn: 0.0024093\ttotal: 1.53s\tremaining: 5.6s\n",
            "215:\tlearn: 0.0023494\ttotal: 1.54s\tremaining: 5.6s\n",
            "216:\tlearn: 0.0022910\ttotal: 1.55s\tremaining: 5.59s\n",
            "217:\tlearn: 0.0022337\ttotal: 1.56s\tremaining: 5.58s\n",
            "218:\tlearn: 0.0021782\ttotal: 1.56s\tremaining: 5.58s\n",
            "219:\tlearn: 0.0021241\ttotal: 1.57s\tremaining: 5.57s\n",
            "220:\tlearn: 0.0020714\ttotal: 1.58s\tremaining: 5.57s\n",
            "221:\tlearn: 0.0020201\ttotal: 1.59s\tremaining: 5.56s\n",
            "222:\tlearn: 0.0019700\ttotal: 1.59s\tremaining: 5.56s\n",
            "223:\tlearn: 0.0019202\ttotal: 1.6s\tremaining: 5.55s\n",
            "224:\tlearn: 0.0018727\ttotal: 1.61s\tremaining: 5.55s\n",
            "225:\tlearn: 0.0018252\ttotal: 1.62s\tremaining: 5.54s\n",
            "226:\tlearn: 0.0017800\ttotal: 1.63s\tremaining: 5.55s\n",
            "227:\tlearn: 0.0017343\ttotal: 1.64s\tremaining: 5.55s\n",
            "228:\tlearn: 0.0016897\ttotal: 1.65s\tremaining: 5.54s\n",
            "229:\tlearn: 0.0016470\ttotal: 1.65s\tremaining: 5.53s\n",
            "230:\tlearn: 0.0016057\ttotal: 1.66s\tremaining: 5.52s\n",
            "231:\tlearn: 0.0015659\ttotal: 1.67s\tremaining: 5.52s\n",
            "232:\tlearn: 0.0015267\ttotal: 1.68s\tremaining: 5.53s\n",
            "233:\tlearn: 0.0014882\ttotal: 1.69s\tremaining: 5.52s\n",
            "234:\tlearn: 0.0014508\ttotal: 1.69s\tremaining: 5.51s\n",
            "235:\tlearn: 0.0014145\ttotal: 1.7s\tremaining: 5.5s\n",
            "236:\tlearn: 0.0013790\ttotal: 1.71s\tremaining: 5.49s\n",
            "237:\tlearn: 0.0013444\ttotal: 1.71s\tremaining: 5.49s\n",
            "238:\tlearn: 0.0013107\ttotal: 1.72s\tremaining: 5.48s\n",
            "239:\tlearn: 0.0012782\ttotal: 1.73s\tremaining: 5.47s\n",
            "240:\tlearn: 0.0012462\ttotal: 1.74s\tremaining: 5.47s\n",
            "241:\tlearn: 0.0012144\ttotal: 1.74s\tremaining: 5.46s\n",
            "242:\tlearn: 0.0011835\ttotal: 1.75s\tremaining: 5.46s\n",
            "243:\tlearn: 0.0011533\ttotal: 1.76s\tremaining: 5.45s\n",
            "244:\tlearn: 0.0011240\ttotal: 1.77s\tremaining: 5.45s\n",
            "245:\tlearn: 0.0010954\ttotal: 1.77s\tremaining: 5.44s\n",
            "246:\tlearn: 0.0010683\ttotal: 1.78s\tremaining: 5.43s\n",
            "247:\tlearn: 0.0010411\ttotal: 1.79s\tremaining: 5.43s\n",
            "248:\tlearn: 0.0010147\ttotal: 1.8s\tremaining: 5.42s\n",
            "249:\tlearn: 0.0009892\ttotal: 1.8s\tremaining: 5.41s\n",
            "250:\tlearn: 0.0009641\ttotal: 1.81s\tremaining: 5.41s\n",
            "251:\tlearn: 0.0009397\ttotal: 1.82s\tremaining: 5.42s\n",
            "252:\tlearn: 0.0009158\ttotal: 1.84s\tremaining: 5.43s\n",
            "253:\tlearn: 0.0008926\ttotal: 1.85s\tremaining: 5.42s\n",
            "254:\tlearn: 0.0008700\ttotal: 1.85s\tremaining: 5.41s\n",
            "255:\tlearn: 0.0008485\ttotal: 1.86s\tremaining: 5.41s\n",
            "256:\tlearn: 0.0008270\ttotal: 1.87s\tremaining: 5.4s\n",
            "257:\tlearn: 0.0008061\ttotal: 1.87s\tremaining: 5.39s\n",
            "258:\tlearn: 0.0007857\ttotal: 1.88s\tremaining: 5.38s\n",
            "259:\tlearn: 0.0007658\ttotal: 1.89s\tremaining: 5.37s\n",
            "260:\tlearn: 0.0007465\ttotal: 1.9s\tremaining: 5.37s\n",
            "261:\tlearn: 0.0007279\ttotal: 1.9s\tremaining: 5.36s\n",
            "262:\tlearn: 0.0007099\ttotal: 1.91s\tremaining: 5.35s\n",
            "263:\tlearn: 0.0006923\ttotal: 1.92s\tremaining: 5.34s\n",
            "264:\tlearn: 0.0006751\ttotal: 1.93s\tremaining: 5.34s\n",
            "265:\tlearn: 0.0006583\ttotal: 1.94s\tremaining: 5.34s\n",
            "266:\tlearn: 0.0006418\ttotal: 1.94s\tremaining: 5.33s\n",
            "267:\tlearn: 0.0006256\ttotal: 1.95s\tremaining: 5.33s\n",
            "268:\tlearn: 0.0006099\ttotal: 1.96s\tremaining: 5.32s\n",
            "269:\tlearn: 0.0005945\ttotal: 1.96s\tremaining: 5.31s\n",
            "270:\tlearn: 0.0005795\ttotal: 1.97s\tremaining: 5.3s\n",
            "271:\tlearn: 0.0005651\ttotal: 1.98s\tremaining: 5.3s\n",
            "272:\tlearn: 0.0005511\ttotal: 1.99s\tremaining: 5.29s\n",
            "273:\tlearn: 0.0005373\ttotal: 1.99s\tremaining: 5.28s\n",
            "274:\tlearn: 0.0005238\ttotal: 2s\tremaining: 5.28s\n",
            "275:\tlearn: 0.0005106\ttotal: 2.01s\tremaining: 5.27s\n",
            "276:\tlearn: 0.0004977\ttotal: 2.01s\tremaining: 5.26s\n",
            "277:\tlearn: 0.0004853\ttotal: 2.02s\tremaining: 5.25s\n",
            "278:\tlearn: 0.0004733\ttotal: 2.03s\tremaining: 5.24s\n",
            "279:\tlearn: 0.0004615\ttotal: 2.04s\tremaining: 5.24s\n",
            "280:\tlearn: 0.0004501\ttotal: 2.05s\tremaining: 5.24s\n",
            "281:\tlearn: 0.0004388\ttotal: 2.05s\tremaining: 5.23s\n",
            "282:\tlearn: 0.0004277\ttotal: 2.06s\tremaining: 5.22s\n",
            "283:\tlearn: 0.0004170\ttotal: 2.07s\tremaining: 5.21s\n",
            "284:\tlearn: 0.0004065\ttotal: 2.08s\tremaining: 5.21s\n",
            "285:\tlearn: 0.0003963\ttotal: 2.08s\tremaining: 5.2s\n",
            "286:\tlearn: 0.0003863\ttotal: 2.09s\tremaining: 5.19s\n",
            "287:\tlearn: 0.0003767\ttotal: 2.1s\tremaining: 5.18s\n",
            "288:\tlearn: 0.0003673\ttotal: 2.1s\tremaining: 5.18s\n",
            "289:\tlearn: 0.0003581\ttotal: 2.11s\tremaining: 5.17s\n",
            "290:\tlearn: 0.0003491\ttotal: 2.12s\tremaining: 5.16s\n",
            "291:\tlearn: 0.0003405\ttotal: 2.13s\tremaining: 5.16s\n",
            "292:\tlearn: 0.0003319\ttotal: 2.13s\tremaining: 5.15s\n",
            "293:\tlearn: 0.0003236\ttotal: 2.14s\tremaining: 5.14s\n",
            "294:\tlearn: 0.0003155\ttotal: 2.15s\tremaining: 5.13s\n",
            "295:\tlearn: 0.0003076\ttotal: 2.15s\tremaining: 5.13s\n",
            "296:\tlearn: 0.0002999\ttotal: 2.16s\tremaining: 5.12s\n",
            "297:\tlearn: 0.0002924\ttotal: 2.17s\tremaining: 5.12s\n",
            "298:\tlearn: 0.0002851\ttotal: 2.18s\tremaining: 5.12s\n",
            "299:\tlearn: 0.0002776\ttotal: 2.19s\tremaining: 5.11s\n",
            "300:\tlearn: 0.0002703\ttotal: 2.2s\tremaining: 5.1s\n",
            "301:\tlearn: 0.0002638\ttotal: 2.21s\tremaining: 5.1s\n",
            "302:\tlearn: 0.0002571\ttotal: 2.21s\tremaining: 5.09s\n",
            "303:\tlearn: 0.0002507\ttotal: 2.22s\tremaining: 5.09s\n",
            "304:\tlearn: 0.0002444\ttotal: 2.23s\tremaining: 5.08s\n",
            "305:\tlearn: 0.0002382\ttotal: 2.24s\tremaining: 5.08s\n",
            "306:\tlearn: 0.0002322\ttotal: 2.25s\tremaining: 5.08s\n",
            "307:\tlearn: 0.0002264\ttotal: 2.26s\tremaining: 5.07s\n",
            "308:\tlearn: 0.0002207\ttotal: 2.27s\tremaining: 5.07s\n",
            "309:\tlearn: 0.0002152\ttotal: 2.27s\tremaining: 5.06s\n",
            "310:\tlearn: 0.0002098\ttotal: 2.28s\tremaining: 5.05s\n",
            "311:\tlearn: 0.0002045\ttotal: 2.29s\tremaining: 5.04s\n",
            "312:\tlearn: 0.0001994\ttotal: 2.29s\tremaining: 5.04s\n",
            "313:\tlearn: 0.0001944\ttotal: 2.3s\tremaining: 5.03s\n",
            "314:\tlearn: 0.0001895\ttotal: 2.31s\tremaining: 5.02s\n",
            "315:\tlearn: 0.0001847\ttotal: 2.32s\tremaining: 5.02s\n",
            "316:\tlearn: 0.0001801\ttotal: 2.33s\tremaining: 5.02s\n",
            "317:\tlearn: 0.0001756\ttotal: 2.35s\tremaining: 5.04s\n",
            "318:\tlearn: 0.0001712\ttotal: 2.36s\tremaining: 5.04s\n",
            "319:\tlearn: 0.0001669\ttotal: 2.37s\tremaining: 5.04s\n",
            "320:\tlearn: 0.0001627\ttotal: 2.38s\tremaining: 5.04s\n",
            "321:\tlearn: 0.0001587\ttotal: 2.39s\tremaining: 5.03s\n",
            "322:\tlearn: 0.0001547\ttotal: 2.4s\tremaining: 5.02s\n",
            "323:\tlearn: 0.0001508\ttotal: 2.4s\tremaining: 5.01s\n",
            "324:\tlearn: 0.0001471\ttotal: 2.41s\tremaining: 5.01s\n",
            "325:\tlearn: 0.0001434\ttotal: 2.42s\tremaining: 5s\n",
            "326:\tlearn: 0.0001398\ttotal: 2.42s\tremaining: 4.99s\n",
            "327:\tlearn: 0.0001363\ttotal: 2.43s\tremaining: 4.98s\n",
            "328:\tlearn: 0.0001329\ttotal: 2.44s\tremaining: 4.97s\n",
            "329:\tlearn: 0.0001296\ttotal: 2.45s\tremaining: 4.97s\n",
            "330:\tlearn: 0.0001264\ttotal: 2.46s\tremaining: 4.97s\n",
            "331:\tlearn: 0.0001232\ttotal: 2.47s\tremaining: 4.97s\n",
            "332:\tlearn: 0.0001202\ttotal: 2.48s\tremaining: 4.96s\n",
            "333:\tlearn: 0.0001172\ttotal: 2.48s\tremaining: 4.95s\n",
            "334:\tlearn: 0.0001142\ttotal: 2.49s\tremaining: 4.94s\n",
            "335:\tlearn: 0.0001114\ttotal: 2.5s\tremaining: 4.93s\n",
            "336:\tlearn: 0.0001086\ttotal: 2.5s\tremaining: 4.92s\n",
            "337:\tlearn: 0.0001059\ttotal: 2.51s\tremaining: 4.92s\n",
            "338:\tlearn: 0.0001033\ttotal: 2.52s\tremaining: 4.91s\n",
            "339:\tlearn: 0.0001007\ttotal: 2.52s\tremaining: 4.9s\n",
            "340:\tlearn: 0.0000982\ttotal: 2.53s\tremaining: 4.89s\n",
            "341:\tlearn: 0.0000958\ttotal: 2.54s\tremaining: 4.89s\n",
            "342:\tlearn: 0.0000934\ttotal: 2.55s\tremaining: 4.88s\n",
            "343:\tlearn: 0.0000910\ttotal: 2.56s\tremaining: 4.87s\n",
            "344:\tlearn: 0.0000888\ttotal: 2.56s\tremaining: 4.87s\n",
            "345:\tlearn: 0.0000866\ttotal: 2.57s\tremaining: 4.86s\n",
            "346:\tlearn: 0.0000844\ttotal: 2.58s\tremaining: 4.86s\n",
            "347:\tlearn: 0.0000823\ttotal: 2.59s\tremaining: 4.85s\n",
            "348:\tlearn: 0.0000803\ttotal: 2.6s\tremaining: 4.84s\n",
            "349:\tlearn: 0.0000783\ttotal: 2.6s\tremaining: 4.83s\n",
            "350:\tlearn: 0.0000763\ttotal: 2.61s\tremaining: 4.83s\n",
            "351:\tlearn: 0.0000744\ttotal: 2.62s\tremaining: 4.82s\n",
            "352:\tlearn: 0.0000726\ttotal: 2.63s\tremaining: 4.81s\n",
            "353:\tlearn: 0.0000708\ttotal: 2.63s\tremaining: 4.81s\n",
            "354:\tlearn: 0.0000690\ttotal: 2.64s\tremaining: 4.8s\n",
            "355:\tlearn: 0.0000673\ttotal: 2.65s\tremaining: 4.79s\n",
            "356:\tlearn: 0.0000656\ttotal: 2.66s\tremaining: 4.79s\n",
            "357:\tlearn: 0.0000640\ttotal: 2.67s\tremaining: 4.79s\n",
            "358:\tlearn: 0.0000624\ttotal: 2.68s\tremaining: 4.78s\n",
            "359:\tlearn: 0.0000609\ttotal: 2.68s\tremaining: 4.77s\n",
            "360:\tlearn: 0.0000594\ttotal: 2.69s\tremaining: 4.76s\n",
            "361:\tlearn: 0.0000579\ttotal: 2.7s\tremaining: 4.76s\n",
            "362:\tlearn: 0.0000564\ttotal: 2.71s\tremaining: 4.76s\n",
            "363:\tlearn: 0.0000550\ttotal: 2.72s\tremaining: 4.75s\n",
            "364:\tlearn: 0.0000537\ttotal: 2.73s\tremaining: 4.75s\n",
            "365:\tlearn: 0.0000524\ttotal: 2.73s\tremaining: 4.74s\n",
            "366:\tlearn: 0.0000510\ttotal: 2.74s\tremaining: 4.73s\n",
            "367:\tlearn: 0.0000498\ttotal: 2.75s\tremaining: 4.72s\n",
            "368:\tlearn: 0.0000485\ttotal: 2.76s\tremaining: 4.72s\n",
            "369:\tlearn: 0.0000473\ttotal: 2.77s\tremaining: 4.71s\n",
            "370:\tlearn: 0.0000461\ttotal: 2.77s\tremaining: 4.7s\n",
            "371:\tlearn: 0.0000450\ttotal: 2.78s\tremaining: 4.69s\n",
            "372:\tlearn: 0.0000439\ttotal: 2.79s\tremaining: 4.69s\n",
            "373:\tlearn: 0.0000428\ttotal: 2.79s\tremaining: 4.68s\n",
            "374:\tlearn: 0.0000417\ttotal: 2.8s\tremaining: 4.67s\n",
            "375:\tlearn: 0.0000407\ttotal: 2.81s\tremaining: 4.66s\n",
            "376:\tlearn: 0.0000396\ttotal: 2.82s\tremaining: 4.66s\n",
            "377:\tlearn: 0.0000387\ttotal: 2.83s\tremaining: 4.66s\n",
            "378:\tlearn: 0.0000377\ttotal: 2.84s\tremaining: 4.65s\n",
            "379:\tlearn: 0.0000368\ttotal: 2.85s\tremaining: 4.64s\n",
            "380:\tlearn: 0.0000358\ttotal: 2.85s\tremaining: 4.64s\n",
            "381:\tlearn: 0.0000349\ttotal: 2.86s\tremaining: 4.63s\n",
            "382:\tlearn: 0.0000341\ttotal: 2.87s\tremaining: 4.63s\n",
            "383:\tlearn: 0.0000332\ttotal: 2.88s\tremaining: 4.62s\n",
            "384:\tlearn: 0.0000324\ttotal: 2.88s\tremaining: 4.61s\n",
            "385:\tlearn: 0.0000316\ttotal: 2.89s\tremaining: 4.6s\n",
            "386:\tlearn: 0.0000308\ttotal: 2.9s\tremaining: 4.59s\n",
            "387:\tlearn: 0.0000300\ttotal: 2.91s\tremaining: 4.58s\n",
            "388:\tlearn: 0.0000293\ttotal: 2.91s\tremaining: 4.58s\n",
            "389:\tlearn: 0.0000286\ttotal: 2.92s\tremaining: 4.57s\n",
            "390:\tlearn: 0.0000279\ttotal: 2.93s\tremaining: 4.56s\n",
            "391:\tlearn: 0.0000272\ttotal: 2.93s\tremaining: 4.55s\n",
            "392:\tlearn: 0.0000265\ttotal: 2.94s\tremaining: 4.55s\n",
            "393:\tlearn: 0.0000258\ttotal: 2.95s\tremaining: 4.54s\n",
            "394:\tlearn: 0.0000252\ttotal: 2.96s\tremaining: 4.53s\n",
            "395:\tlearn: 0.0000245\ttotal: 2.97s\tremaining: 4.52s\n",
            "396:\tlearn: 0.0000239\ttotal: 2.97s\tremaining: 4.52s\n",
            "397:\tlearn: 0.0000233\ttotal: 2.98s\tremaining: 4.51s\n",
            "398:\tlearn: 0.0000227\ttotal: 2.99s\tremaining: 4.5s\n",
            "399:\tlearn: 0.0000222\ttotal: 2.99s\tremaining: 4.49s\n",
            "400:\tlearn: 0.0000216\ttotal: 3s\tremaining: 4.48s\n",
            "401:\tlearn: 0.0000211\ttotal: 3.01s\tremaining: 4.47s\n",
            "402:\tlearn: 0.0000205\ttotal: 3.01s\tremaining: 4.47s\n",
            "403:\tlearn: 0.0000200\ttotal: 3.02s\tremaining: 4.46s\n",
            "404:\tlearn: 0.0000195\ttotal: 3.03s\tremaining: 4.45s\n",
            "405:\tlearn: 0.0000190\ttotal: 3.04s\tremaining: 4.44s\n",
            "406:\tlearn: 0.0000185\ttotal: 3.04s\tremaining: 4.43s\n",
            "407:\tlearn: 0.0000181\ttotal: 3.05s\tremaining: 4.43s\n",
            "408:\tlearn: 0.0000176\ttotal: 3.06s\tremaining: 4.42s\n",
            "409:\tlearn: 0.0000172\ttotal: 3.07s\tremaining: 4.42s\n",
            "410:\tlearn: 0.0000167\ttotal: 3.08s\tremaining: 4.41s\n",
            "411:\tlearn: 0.0000163\ttotal: 3.08s\tremaining: 4.4s\n",
            "412:\tlearn: 0.0000159\ttotal: 3.09s\tremaining: 4.39s\n",
            "413:\tlearn: 0.0000155\ttotal: 3.1s\tremaining: 4.39s\n",
            "414:\tlearn: 0.0000151\ttotal: 3.11s\tremaining: 4.38s\n",
            "415:\tlearn: 0.0000147\ttotal: 3.11s\tremaining: 4.37s\n",
            "416:\tlearn: 0.0000144\ttotal: 3.12s\tremaining: 4.36s\n",
            "417:\tlearn: 0.0000140\ttotal: 3.13s\tremaining: 4.35s\n",
            "418:\tlearn: 0.0000137\ttotal: 3.13s\tremaining: 4.35s\n",
            "419:\tlearn: 0.0000133\ttotal: 3.14s\tremaining: 4.34s\n",
            "420:\tlearn: 0.0000130\ttotal: 3.15s\tremaining: 4.33s\n",
            "421:\tlearn: 0.0000127\ttotal: 3.15s\tremaining: 4.32s\n",
            "422:\tlearn: 0.0000123\ttotal: 3.16s\tremaining: 4.31s\n",
            "423:\tlearn: 0.0000120\ttotal: 3.17s\tremaining: 4.31s\n",
            "424:\tlearn: 0.0000117\ttotal: 3.18s\tremaining: 4.3s\n",
            "425:\tlearn: 0.0000114\ttotal: 3.18s\tremaining: 4.29s\n",
            "426:\tlearn: 0.0000111\ttotal: 3.19s\tremaining: 4.28s\n",
            "427:\tlearn: 0.0000109\ttotal: 3.2s\tremaining: 4.28s\n",
            "428:\tlearn: 0.0000106\ttotal: 3.21s\tremaining: 4.27s\n",
            "429:\tlearn: 0.0000103\ttotal: 3.21s\tremaining: 4.26s\n",
            "430:\tlearn: 0.0000101\ttotal: 3.22s\tremaining: 4.25s\n",
            "431:\tlearn: 0.0000098\ttotal: 3.23s\tremaining: 4.25s\n",
            "432:\tlearn: 0.0000096\ttotal: 3.24s\tremaining: 4.24s\n",
            "433:\tlearn: 0.0000093\ttotal: 3.24s\tremaining: 4.23s\n",
            "434:\tlearn: 0.0000091\ttotal: 3.25s\tremaining: 4.22s\n",
            "435:\tlearn: 0.0000089\ttotal: 3.26s\tremaining: 4.21s\n",
            "436:\tlearn: 0.0000086\ttotal: 3.26s\tremaining: 4.21s\n",
            "437:\tlearn: 0.0000084\ttotal: 3.27s\tremaining: 4.2s\n",
            "438:\tlearn: 0.0000082\ttotal: 3.28s\tremaining: 4.19s\n",
            "439:\tlearn: 0.0000080\ttotal: 3.29s\tremaining: 4.19s\n",
            "440:\tlearn: 0.0000078\ttotal: 3.29s\tremaining: 4.18s\n",
            "441:\tlearn: 0.0000076\ttotal: 3.3s\tremaining: 4.17s\n",
            "442:\tlearn: 0.0000074\ttotal: 3.31s\tremaining: 4.16s\n",
            "443:\tlearn: 0.0000072\ttotal: 3.32s\tremaining: 4.15s\n",
            "444:\tlearn: 0.0000071\ttotal: 3.32s\tremaining: 4.14s\n",
            "445:\tlearn: 0.0000069\ttotal: 3.33s\tremaining: 4.14s\n",
            "446:\tlearn: 0.0000067\ttotal: 3.34s\tremaining: 4.13s\n",
            "447:\tlearn: 0.0000065\ttotal: 3.35s\tremaining: 4.12s\n",
            "448:\tlearn: 0.0000064\ttotal: 3.35s\tremaining: 4.11s\n",
            "449:\tlearn: 0.0000062\ttotal: 3.36s\tremaining: 4.11s\n",
            "450:\tlearn: 0.0000061\ttotal: 3.37s\tremaining: 4.1s\n",
            "451:\tlearn: 0.0000059\ttotal: 3.37s\tremaining: 4.09s\n",
            "452:\tlearn: 0.0000058\ttotal: 3.38s\tremaining: 4.08s\n",
            "453:\tlearn: 0.0000056\ttotal: 3.39s\tremaining: 4.07s\n",
            "454:\tlearn: 0.0000055\ttotal: 3.39s\tremaining: 4.07s\n",
            "455:\tlearn: 0.0000053\ttotal: 3.4s\tremaining: 4.06s\n",
            "456:\tlearn: 0.0000052\ttotal: 3.41s\tremaining: 4.05s\n",
            "457:\tlearn: 0.0000051\ttotal: 3.42s\tremaining: 4.04s\n",
            "458:\tlearn: 0.0000049\ttotal: 3.42s\tremaining: 4.03s\n",
            "459:\tlearn: 0.0000048\ttotal: 3.43s\tremaining: 4.03s\n",
            "460:\tlearn: 0.0000047\ttotal: 3.44s\tremaining: 4.02s\n",
            "461:\tlearn: 0.0000046\ttotal: 3.45s\tremaining: 4.01s\n",
            "462:\tlearn: 0.0000045\ttotal: 3.46s\tremaining: 4.01s\n",
            "463:\tlearn: 0.0000044\ttotal: 3.46s\tremaining: 4s\n",
            "464:\tlearn: 0.0000042\ttotal: 3.47s\tremaining: 3.99s\n",
            "465:\tlearn: 0.0000041\ttotal: 3.48s\tremaining: 3.99s\n",
            "466:\tlearn: 0.0000040\ttotal: 3.49s\tremaining: 3.98s\n",
            "467:\tlearn: 0.0000039\ttotal: 3.49s\tremaining: 3.97s\n",
            "468:\tlearn: 0.0000038\ttotal: 3.5s\tremaining: 3.96s\n",
            "469:\tlearn: 0.0000037\ttotal: 3.51s\tremaining: 3.96s\n",
            "470:\tlearn: 0.0000036\ttotal: 3.52s\tremaining: 3.95s\n",
            "471:\tlearn: 0.0000036\ttotal: 3.52s\tremaining: 3.94s\n",
            "472:\tlearn: 0.0000035\ttotal: 3.53s\tremaining: 3.93s\n",
            "473:\tlearn: 0.0000034\ttotal: 3.54s\tremaining: 3.92s\n",
            "474:\tlearn: 0.0000033\ttotal: 3.55s\tremaining: 3.92s\n",
            "475:\tlearn: 0.0000032\ttotal: 3.55s\tremaining: 3.91s\n",
            "476:\tlearn: 0.0000031\ttotal: 3.56s\tremaining: 3.9s\n",
            "477:\tlearn: 0.0000031\ttotal: 3.57s\tremaining: 3.9s\n",
            "478:\tlearn: 0.0000030\ttotal: 3.58s\tremaining: 3.89s\n",
            "479:\tlearn: 0.0000029\ttotal: 3.58s\tremaining: 3.88s\n",
            "480:\tlearn: 0.0000028\ttotal: 3.59s\tremaining: 3.87s\n",
            "481:\tlearn: 0.0000028\ttotal: 3.6s\tremaining: 3.87s\n",
            "482:\tlearn: 0.0000027\ttotal: 3.6s\tremaining: 3.86s\n",
            "483:\tlearn: 0.0000026\ttotal: 3.61s\tremaining: 3.85s\n",
            "484:\tlearn: 0.0000026\ttotal: 3.62s\tremaining: 3.84s\n",
            "485:\tlearn: 0.0000025\ttotal: 3.63s\tremaining: 3.84s\n",
            "486:\tlearn: 0.0000024\ttotal: 3.63s\tremaining: 3.83s\n",
            "487:\tlearn: 0.0000024\ttotal: 3.64s\tremaining: 3.82s\n",
            "488:\tlearn: 0.0000023\ttotal: 3.65s\tremaining: 3.81s\n",
            "489:\tlearn: 0.0000023\ttotal: 3.66s\tremaining: 3.81s\n",
            "490:\tlearn: 0.0000022\ttotal: 3.66s\tremaining: 3.8s\n",
            "491:\tlearn: 0.0000021\ttotal: 3.67s\tremaining: 3.79s\n",
            "492:\tlearn: 0.0000021\ttotal: 3.68s\tremaining: 3.78s\n",
            "493:\tlearn: 0.0000020\ttotal: 3.69s\tremaining: 3.78s\n",
            "494:\tlearn: 0.0000020\ttotal: 3.69s\tremaining: 3.77s\n",
            "495:\tlearn: 0.0000019\ttotal: 3.71s\tremaining: 3.77s\n",
            "496:\tlearn: 0.0000019\ttotal: 3.71s\tremaining: 3.76s\n",
            "497:\tlearn: 0.0000018\ttotal: 3.72s\tremaining: 3.75s\n",
            "498:\tlearn: 0.0000018\ttotal: 3.73s\tremaining: 3.74s\n",
            "499:\tlearn: 0.0000018\ttotal: 3.74s\tremaining: 3.74s\n",
            "500:\tlearn: 0.0000017\ttotal: 3.74s\tremaining: 3.73s\n",
            "501:\tlearn: 0.0000017\ttotal: 3.75s\tremaining: 3.72s\n",
            "502:\tlearn: 0.0000016\ttotal: 3.76s\tremaining: 3.71s\n",
            "503:\tlearn: 0.0000016\ttotal: 3.77s\tremaining: 3.71s\n",
            "504:\tlearn: 0.0000015\ttotal: 3.77s\tremaining: 3.7s\n",
            "505:\tlearn: 0.0000015\ttotal: 3.78s\tremaining: 3.69s\n",
            "506:\tlearn: 0.0000015\ttotal: 3.79s\tremaining: 3.68s\n",
            "507:\tlearn: 0.0000014\ttotal: 3.8s\tremaining: 3.68s\n",
            "508:\tlearn: 0.0000014\ttotal: 3.8s\tremaining: 3.67s\n",
            "509:\tlearn: 0.0000014\ttotal: 3.81s\tremaining: 3.66s\n",
            "510:\tlearn: 0.0000013\ttotal: 3.82s\tremaining: 3.66s\n",
            "511:\tlearn: 0.0000013\ttotal: 3.83s\tremaining: 3.65s\n",
            "512:\tlearn: 0.0000013\ttotal: 3.84s\tremaining: 3.65s\n",
            "513:\tlearn: 0.0000012\ttotal: 3.85s\tremaining: 3.64s\n",
            "514:\tlearn: 0.0000012\ttotal: 3.86s\tremaining: 3.63s\n",
            "515:\tlearn: 0.0000012\ttotal: 3.86s\tremaining: 3.62s\n",
            "516:\tlearn: 0.0000011\ttotal: 3.87s\tremaining: 3.62s\n",
            "517:\tlearn: 0.0000011\ttotal: 3.88s\tremaining: 3.61s\n",
            "518:\tlearn: 0.0000011\ttotal: 3.89s\tremaining: 3.6s\n",
            "519:\tlearn: 0.0000011\ttotal: 3.9s\tremaining: 3.6s\n",
            "520:\tlearn: 0.0000010\ttotal: 3.9s\tremaining: 3.59s\n",
            "521:\tlearn: 0.0000010\ttotal: 3.91s\tremaining: 3.58s\n",
            "522:\tlearn: 0.0000010\ttotal: 3.92s\tremaining: 3.57s\n",
            "523:\tlearn: 0.0000010\ttotal: 3.92s\tremaining: 3.56s\n",
            "524:\tlearn: 0.0000009\ttotal: 3.93s\tremaining: 3.56s\n",
            "525:\tlearn: 0.0000009\ttotal: 3.94s\tremaining: 3.55s\n",
            "526:\tlearn: 0.0000009\ttotal: 3.94s\tremaining: 3.54s\n",
            "527:\tlearn: 0.0000009\ttotal: 3.95s\tremaining: 3.53s\n",
            "528:\tlearn: 0.0000008\ttotal: 3.96s\tremaining: 3.52s\n",
            "529:\tlearn: 0.0000008\ttotal: 3.97s\tremaining: 3.52s\n",
            "530:\tlearn: 0.0000008\ttotal: 3.98s\tremaining: 3.51s\n",
            "531:\tlearn: 0.0000008\ttotal: 3.98s\tremaining: 3.51s\n",
            "532:\tlearn: 0.0000008\ttotal: 3.99s\tremaining: 3.5s\n",
            "533:\tlearn: 0.0000007\ttotal: 4s\tremaining: 3.49s\n",
            "534:\tlearn: 0.0000007\ttotal: 4.01s\tremaining: 3.48s\n",
            "535:\tlearn: 0.0000007\ttotal: 4.01s\tremaining: 3.48s\n",
            "536:\tlearn: 0.0000007\ttotal: 4.02s\tremaining: 3.47s\n",
            "537:\tlearn: 0.0000007\ttotal: 4.03s\tremaining: 3.46s\n",
            "538:\tlearn: 0.0000007\ttotal: 4.04s\tremaining: 3.45s\n",
            "539:\tlearn: 0.0000006\ttotal: 4.04s\tremaining: 3.44s\n",
            "540:\tlearn: 0.0000006\ttotal: 4.05s\tremaining: 3.44s\n",
            "541:\tlearn: 0.0000006\ttotal: 4.06s\tremaining: 3.43s\n",
            "542:\tlearn: 0.0000006\ttotal: 4.06s\tremaining: 3.42s\n",
            "543:\tlearn: 0.0000006\ttotal: 4.07s\tremaining: 3.41s\n",
            "544:\tlearn: 0.0000006\ttotal: 4.08s\tremaining: 3.4s\n",
            "545:\tlearn: 0.0000005\ttotal: 4.09s\tremaining: 3.4s\n",
            "546:\tlearn: 0.0000005\ttotal: 4.1s\tremaining: 3.39s\n",
            "547:\tlearn: 0.0000005\ttotal: 4.1s\tremaining: 3.38s\n",
            "548:\tlearn: 0.0000005\ttotal: 4.11s\tremaining: 3.38s\n",
            "549:\tlearn: 0.0000005\ttotal: 4.12s\tremaining: 3.37s\n",
            "550:\tlearn: 0.0000005\ttotal: 4.13s\tremaining: 3.36s\n",
            "551:\tlearn: 0.0000005\ttotal: 4.13s\tremaining: 3.35s\n",
            "552:\tlearn: 0.0000005\ttotal: 4.14s\tremaining: 3.35s\n",
            "553:\tlearn: 0.0000004\ttotal: 4.15s\tremaining: 3.34s\n",
            "554:\tlearn: 0.0000004\ttotal: 4.16s\tremaining: 3.33s\n",
            "555:\tlearn: 0.0000004\ttotal: 4.16s\tremaining: 3.33s\n",
            "556:\tlearn: 0.0000004\ttotal: 4.17s\tremaining: 3.32s\n",
            "557:\tlearn: 0.0000004\ttotal: 4.18s\tremaining: 3.31s\n",
            "558:\tlearn: 0.0000004\ttotal: 4.19s\tremaining: 3.3s\n",
            "559:\tlearn: 0.0000004\ttotal: 4.19s\tremaining: 3.29s\n",
            "560:\tlearn: 0.0000004\ttotal: 4.21s\tremaining: 3.29s\n",
            "561:\tlearn: 0.0000004\ttotal: 4.21s\tremaining: 3.28s\n",
            "562:\tlearn: 0.0000004\ttotal: 4.22s\tremaining: 3.27s\n",
            "563:\tlearn: 0.0000003\ttotal: 4.23s\tremaining: 3.27s\n",
            "564:\tlearn: 0.0000003\ttotal: 4.23s\tremaining: 3.26s\n",
            "565:\tlearn: 0.0000003\ttotal: 4.24s\tremaining: 3.25s\n",
            "566:\tlearn: 0.0000003\ttotal: 4.25s\tremaining: 3.24s\n",
            "567:\tlearn: 0.0000003\ttotal: 4.26s\tremaining: 3.24s\n",
            "568:\tlearn: 0.0000003\ttotal: 4.26s\tremaining: 3.23s\n",
            "569:\tlearn: 0.0000003\ttotal: 4.27s\tremaining: 3.22s\n",
            "570:\tlearn: 0.0000003\ttotal: 4.28s\tremaining: 3.21s\n",
            "571:\tlearn: 0.0000003\ttotal: 4.29s\tremaining: 3.21s\n",
            "572:\tlearn: 0.0000003\ttotal: 4.3s\tremaining: 3.2s\n",
            "573:\tlearn: 0.0000003\ttotal: 4.31s\tremaining: 3.2s\n",
            "574:\tlearn: 0.0000003\ttotal: 4.31s\tremaining: 3.19s\n",
            "575:\tlearn: 0.0000003\ttotal: 4.32s\tremaining: 3.18s\n",
            "576:\tlearn: 0.0000003\ttotal: 4.33s\tremaining: 3.17s\n",
            "577:\tlearn: 0.0000002\ttotal: 4.34s\tremaining: 3.17s\n",
            "578:\tlearn: 0.0000002\ttotal: 4.35s\tremaining: 3.16s\n",
            "579:\tlearn: 0.0000002\ttotal: 4.36s\tremaining: 3.15s\n",
            "580:\tlearn: 0.0000002\ttotal: 4.37s\tremaining: 3.15s\n",
            "581:\tlearn: 0.0000002\ttotal: 4.37s\tremaining: 3.14s\n",
            "582:\tlearn: 0.0000002\ttotal: 4.38s\tremaining: 3.13s\n",
            "583:\tlearn: 0.0000002\ttotal: 4.39s\tremaining: 3.13s\n",
            "584:\tlearn: 0.0000002\ttotal: 4.39s\tremaining: 3.12s\n",
            "585:\tlearn: 0.0000002\ttotal: 4.4s\tremaining: 3.11s\n",
            "586:\tlearn: 0.0000002\ttotal: 4.41s\tremaining: 3.1s\n",
            "587:\tlearn: 0.0000002\ttotal: 4.42s\tremaining: 3.1s\n",
            "588:\tlearn: 0.0000002\ttotal: 4.42s\tremaining: 3.09s\n",
            "589:\tlearn: 0.0000002\ttotal: 4.43s\tremaining: 3.08s\n",
            "590:\tlearn: 0.0000002\ttotal: 4.44s\tremaining: 3.07s\n",
            "591:\tlearn: 0.0000002\ttotal: 4.45s\tremaining: 3.06s\n",
            "592:\tlearn: 0.0000002\ttotal: 4.46s\tremaining: 3.06s\n",
            "593:\tlearn: 0.0000002\ttotal: 4.46s\tremaining: 3.05s\n",
            "594:\tlearn: 0.0000002\ttotal: 4.47s\tremaining: 3.04s\n",
            "595:\tlearn: 0.0000002\ttotal: 4.48s\tremaining: 3.03s\n",
            "596:\tlearn: 0.0000002\ttotal: 4.48s\tremaining: 3.03s\n",
            "597:\tlearn: 0.0000001\ttotal: 4.49s\tremaining: 3.02s\n",
            "598:\tlearn: 0.0000001\ttotal: 4.5s\tremaining: 3.01s\n",
            "599:\tlearn: 0.0000001\ttotal: 4.51s\tremaining: 3s\n",
            "600:\tlearn: 0.0000001\ttotal: 4.51s\tremaining: 3s\n",
            "601:\tlearn: 0.0000001\ttotal: 4.52s\tremaining: 2.99s\n",
            "602:\tlearn: 0.0000001\ttotal: 4.53s\tremaining: 2.98s\n",
            "603:\tlearn: 0.0000001\ttotal: 4.54s\tremaining: 2.98s\n",
            "604:\tlearn: 0.0000001\ttotal: 4.55s\tremaining: 2.97s\n",
            "605:\tlearn: 0.0000001\ttotal: 4.55s\tremaining: 2.96s\n",
            "606:\tlearn: 0.0000001\ttotal: 4.56s\tremaining: 2.95s\n",
            "607:\tlearn: 0.0000001\ttotal: 4.57s\tremaining: 2.94s\n",
            "608:\tlearn: 0.0000001\ttotal: 4.58s\tremaining: 2.94s\n",
            "609:\tlearn: 0.0000001\ttotal: 4.58s\tremaining: 2.93s\n",
            "610:\tlearn: 0.0000001\ttotal: 4.59s\tremaining: 2.92s\n",
            "611:\tlearn: 0.0000001\ttotal: 4.6s\tremaining: 2.92s\n",
            "612:\tlearn: 0.0000001\ttotal: 4.61s\tremaining: 2.91s\n",
            "613:\tlearn: 0.0000001\ttotal: 4.62s\tremaining: 2.9s\n",
            "614:\tlearn: 0.0000001\ttotal: 4.62s\tremaining: 2.89s\n",
            "615:\tlearn: 0.0000001\ttotal: 4.63s\tremaining: 2.89s\n",
            "616:\tlearn: 0.0000001\ttotal: 4.64s\tremaining: 2.88s\n",
            "617:\tlearn: 0.0000001\ttotal: 4.65s\tremaining: 2.87s\n",
            "618:\tlearn: 0.0000001\ttotal: 4.65s\tremaining: 2.86s\n",
            "619:\tlearn: 0.0000001\ttotal: 4.66s\tremaining: 2.86s\n",
            "620:\tlearn: 0.0000001\ttotal: 4.67s\tremaining: 2.85s\n",
            "621:\tlearn: 0.0000001\ttotal: 4.67s\tremaining: 2.84s\n",
            "622:\tlearn: 0.0000001\ttotal: 4.68s\tremaining: 2.83s\n",
            "623:\tlearn: 0.0000001\ttotal: 4.69s\tremaining: 2.83s\n",
            "624:\tlearn: 0.0000001\ttotal: 4.7s\tremaining: 2.82s\n",
            "625:\tlearn: 0.0000001\ttotal: 4.71s\tremaining: 2.81s\n",
            "626:\tlearn: 0.0000001\ttotal: 4.72s\tremaining: 2.81s\n",
            "627:\tlearn: 0.0000001\ttotal: 4.72s\tremaining: 2.8s\n",
            "628:\tlearn: 0.0000001\ttotal: 4.73s\tremaining: 2.79s\n",
            "629:\tlearn: 0.0000001\ttotal: 4.74s\tremaining: 2.78s\n",
            "630:\tlearn: 0.0000001\ttotal: 4.74s\tremaining: 2.77s\n",
            "631:\tlearn: 0.0000001\ttotal: 4.75s\tremaining: 2.77s\n",
            "632:\tlearn: 0.0000001\ttotal: 4.76s\tremaining: 2.76s\n",
            "633:\tlearn: 0.0000001\ttotal: 4.76s\tremaining: 2.75s\n",
            "634:\tlearn: 0.0000001\ttotal: 4.77s\tremaining: 2.74s\n",
            "635:\tlearn: 0.0000001\ttotal: 4.78s\tremaining: 2.73s\n",
            "636:\tlearn: 0.0000001\ttotal: 4.79s\tremaining: 2.73s\n",
            "637:\tlearn: 0.0000001\ttotal: 4.79s\tremaining: 2.72s\n",
            "638:\tlearn: 0.0000001\ttotal: 4.8s\tremaining: 2.71s\n",
            "639:\tlearn: 0.0000001\ttotal: 4.81s\tremaining: 2.7s\n",
            "640:\tlearn: 0.0000000\ttotal: 4.81s\tremaining: 2.69s\n",
            "641:\tlearn: 0.0000000\ttotal: 4.82s\tremaining: 2.69s\n",
            "642:\tlearn: 0.0000000\ttotal: 4.84s\tremaining: 2.69s\n",
            "643:\tlearn: 0.0000000\ttotal: 4.85s\tremaining: 2.68s\n",
            "644:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 2.67s\n",
            "645:\tlearn: 0.0000000\ttotal: 4.86s\tremaining: 2.67s\n",
            "646:\tlearn: 0.0000000\ttotal: 4.87s\tremaining: 2.66s\n",
            "647:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 2.65s\n",
            "648:\tlearn: 0.0000000\ttotal: 4.88s\tremaining: 2.64s\n",
            "649:\tlearn: 0.0000000\ttotal: 4.89s\tremaining: 2.63s\n",
            "650:\tlearn: 0.0000000\ttotal: 4.9s\tremaining: 2.63s\n",
            "651:\tlearn: 0.0000000\ttotal: 4.91s\tremaining: 2.62s\n",
            "652:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 2.61s\n",
            "653:\tlearn: 0.0000000\ttotal: 4.92s\tremaining: 2.6s\n",
            "654:\tlearn: 0.0000000\ttotal: 4.93s\tremaining: 2.6s\n",
            "655:\tlearn: 0.0000000\ttotal: 4.94s\tremaining: 2.59s\n",
            "656:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 2.58s\n",
            "657:\tlearn: 0.0000000\ttotal: 4.95s\tremaining: 2.57s\n",
            "658:\tlearn: 0.0000000\ttotal: 4.96s\tremaining: 2.57s\n",
            "659:\tlearn: 0.0000000\ttotal: 4.97s\tremaining: 2.56s\n",
            "660:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 2.55s\n",
            "661:\tlearn: 0.0000000\ttotal: 4.98s\tremaining: 2.54s\n",
            "662:\tlearn: 0.0000000\ttotal: 4.99s\tremaining: 2.54s\n",
            "663:\tlearn: 0.0000000\ttotal: 5s\tremaining: 2.53s\n",
            "664:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 2.52s\n",
            "665:\tlearn: 0.0000000\ttotal: 5.01s\tremaining: 2.51s\n",
            "666:\tlearn: 0.0000000\ttotal: 5.02s\tremaining: 2.51s\n",
            "667:\tlearn: 0.0000000\ttotal: 5.03s\tremaining: 2.5s\n",
            "668:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 2.49s\n",
            "669:\tlearn: 0.0000000\ttotal: 5.04s\tremaining: 2.48s\n",
            "670:\tlearn: 0.0000000\ttotal: 5.05s\tremaining: 2.48s\n",
            "671:\tlearn: 0.0000000\ttotal: 5.06s\tremaining: 2.47s\n",
            "672:\tlearn: 0.0000000\ttotal: 5.07s\tremaining: 2.46s\n",
            "673:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 2.45s\n",
            "674:\tlearn: 0.0000000\ttotal: 5.08s\tremaining: 2.45s\n",
            "675:\tlearn: 0.0000000\ttotal: 5.09s\tremaining: 2.44s\n",
            "676:\tlearn: 0.0000000\ttotal: 5.1s\tremaining: 2.44s\n",
            "677:\tlearn: 0.0000000\ttotal: 5.11s\tremaining: 2.43s\n",
            "678:\tlearn: 0.0000000\ttotal: 5.12s\tremaining: 2.42s\n",
            "679:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 2.41s\n",
            "680:\tlearn: 0.0000000\ttotal: 5.13s\tremaining: 2.4s\n",
            "681:\tlearn: 0.0000000\ttotal: 5.14s\tremaining: 2.4s\n",
            "682:\tlearn: 0.0000000\ttotal: 5.15s\tremaining: 2.39s\n",
            "683:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 2.38s\n",
            "684:\tlearn: 0.0000000\ttotal: 5.16s\tremaining: 2.38s\n",
            "685:\tlearn: 0.0000000\ttotal: 5.17s\tremaining: 2.37s\n",
            "686:\tlearn: 0.0000000\ttotal: 5.18s\tremaining: 2.36s\n",
            "687:\tlearn: 0.0000000\ttotal: 5.19s\tremaining: 2.35s\n",
            "688:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 2.34s\n",
            "689:\tlearn: 0.0000000\ttotal: 5.2s\tremaining: 2.34s\n",
            "690:\tlearn: 0.0000000\ttotal: 5.21s\tremaining: 2.33s\n",
            "691:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 2.32s\n",
            "692:\tlearn: 0.0000000\ttotal: 5.22s\tremaining: 2.31s\n",
            "693:\tlearn: 0.0000000\ttotal: 5.23s\tremaining: 2.31s\n",
            "694:\tlearn: 0.0000000\ttotal: 5.24s\tremaining: 2.3s\n",
            "695:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 2.29s\n",
            "696:\tlearn: 0.0000000\ttotal: 5.25s\tremaining: 2.28s\n",
            "697:\tlearn: 0.0000000\ttotal: 5.26s\tremaining: 2.28s\n",
            "698:\tlearn: 0.0000000\ttotal: 5.27s\tremaining: 2.27s\n",
            "699:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 2.26s\n",
            "700:\tlearn: 0.0000000\ttotal: 5.28s\tremaining: 2.25s\n",
            "701:\tlearn: 0.0000000\ttotal: 5.29s\tremaining: 2.25s\n",
            "702:\tlearn: 0.0000000\ttotal: 5.3s\tremaining: 2.24s\n",
            "703:\tlearn: 0.0000000\ttotal: 5.31s\tremaining: 2.23s\n",
            "704:\tlearn: 0.0000000\ttotal: 5.32s\tremaining: 2.22s\n",
            "705:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 2.22s\n",
            "706:\tlearn: 0.0000000\ttotal: 5.33s\tremaining: 2.21s\n",
            "707:\tlearn: 0.0000000\ttotal: 5.34s\tremaining: 2.2s\n",
            "708:\tlearn: 0.0000000\ttotal: 5.35s\tremaining: 2.19s\n",
            "709:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 2.19s\n",
            "710:\tlearn: 0.0000000\ttotal: 5.36s\tremaining: 2.18s\n",
            "711:\tlearn: 0.0000000\ttotal: 5.37s\tremaining: 2.17s\n",
            "712:\tlearn: 0.0000000\ttotal: 5.38s\tremaining: 2.16s\n",
            "713:\tlearn: 0.0000000\ttotal: 5.38s\tremaining: 2.16s\n",
            "714:\tlearn: 0.0000000\ttotal: 5.39s\tremaining: 2.15s\n",
            "715:\tlearn: 0.0000000\ttotal: 5.4s\tremaining: 2.14s\n",
            "716:\tlearn: 0.0000000\ttotal: 5.41s\tremaining: 2.13s\n",
            "717:\tlearn: 0.0000000\ttotal: 5.41s\tremaining: 2.13s\n",
            "718:\tlearn: 0.0000000\ttotal: 5.42s\tremaining: 2.12s\n",
            "719:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 2.11s\n",
            "720:\tlearn: 0.0000000\ttotal: 5.43s\tremaining: 2.1s\n",
            "721:\tlearn: 0.0000000\ttotal: 5.44s\tremaining: 2.1s\n",
            "722:\tlearn: 0.0000000\ttotal: 5.45s\tremaining: 2.09s\n",
            "723:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 2.08s\n",
            "724:\tlearn: 0.0000000\ttotal: 5.46s\tremaining: 2.07s\n",
            "725:\tlearn: 0.0000000\ttotal: 5.47s\tremaining: 2.06s\n",
            "726:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 2.06s\n",
            "727:\tlearn: 0.0000000\ttotal: 5.48s\tremaining: 2.05s\n",
            "728:\tlearn: 0.0000000\ttotal: 5.49s\tremaining: 2.04s\n",
            "729:\tlearn: 0.0000000\ttotal: 5.5s\tremaining: 2.03s\n",
            "730:\tlearn: 0.0000000\ttotal: 5.51s\tremaining: 2.03s\n",
            "731:\tlearn: 0.0000000\ttotal: 5.52s\tremaining: 2.02s\n",
            "732:\tlearn: 0.0000000\ttotal: 5.53s\tremaining: 2.01s\n",
            "733:\tlearn: 0.0000000\ttotal: 5.53s\tremaining: 2s\n",
            "734:\tlearn: 0.0000000\ttotal: 5.54s\tremaining: 2s\n",
            "735:\tlearn: 0.0000000\ttotal: 5.55s\tremaining: 1.99s\n",
            "736:\tlearn: 0.0000000\ttotal: 5.55s\tremaining: 1.98s\n",
            "737:\tlearn: 0.0000000\ttotal: 5.56s\tremaining: 1.97s\n",
            "738:\tlearn: 0.0000000\ttotal: 5.57s\tremaining: 1.97s\n",
            "739:\tlearn: 0.0000000\ttotal: 5.57s\tremaining: 1.96s\n",
            "740:\tlearn: 0.0000000\ttotal: 5.58s\tremaining: 1.95s\n",
            "741:\tlearn: 0.0000000\ttotal: 5.59s\tremaining: 1.94s\n",
            "742:\tlearn: 0.0000000\ttotal: 5.6s\tremaining: 1.94s\n",
            "743:\tlearn: 0.0000000\ttotal: 5.6s\tremaining: 1.93s\n",
            "744:\tlearn: 0.0000000\ttotal: 5.61s\tremaining: 1.92s\n",
            "745:\tlearn: 0.0000000\ttotal: 5.62s\tremaining: 1.91s\n",
            "746:\tlearn: 0.0000000\ttotal: 5.63s\tremaining: 1.91s\n",
            "747:\tlearn: 0.0000000\ttotal: 5.63s\tremaining: 1.9s\n",
            "748:\tlearn: 0.0000000\ttotal: 5.64s\tremaining: 1.89s\n",
            "749:\tlearn: 0.0000000\ttotal: 5.65s\tremaining: 1.88s\n",
            "750:\tlearn: 0.0000000\ttotal: 5.66s\tremaining: 1.88s\n",
            "751:\tlearn: 0.0000000\ttotal: 5.66s\tremaining: 1.87s\n",
            "752:\tlearn: 0.0000000\ttotal: 5.67s\tremaining: 1.86s\n",
            "753:\tlearn: 0.0000000\ttotal: 5.68s\tremaining: 1.85s\n",
            "754:\tlearn: 0.0000000\ttotal: 5.69s\tremaining: 1.85s\n",
            "755:\tlearn: 0.0000000\ttotal: 5.7s\tremaining: 1.84s\n",
            "756:\tlearn: 0.0000000\ttotal: 5.7s\tremaining: 1.83s\n",
            "757:\tlearn: 0.0000000\ttotal: 5.71s\tremaining: 1.82s\n",
            "758:\tlearn: 0.0000000\ttotal: 5.72s\tremaining: 1.82s\n",
            "759:\tlearn: 0.0000000\ttotal: 5.73s\tremaining: 1.81s\n",
            "760:\tlearn: 0.0000000\ttotal: 5.74s\tremaining: 1.8s\n",
            "761:\tlearn: 0.0000000\ttotal: 5.74s\tremaining: 1.79s\n",
            "762:\tlearn: 0.0000000\ttotal: 5.75s\tremaining: 1.79s\n",
            "763:\tlearn: 0.0000000\ttotal: 5.76s\tremaining: 1.78s\n",
            "764:\tlearn: 0.0000000\ttotal: 5.76s\tremaining: 1.77s\n",
            "765:\tlearn: 0.0000000\ttotal: 5.77s\tremaining: 1.76s\n",
            "766:\tlearn: 0.0000000\ttotal: 5.78s\tremaining: 1.75s\n",
            "767:\tlearn: 0.0000000\ttotal: 5.79s\tremaining: 1.75s\n",
            "768:\tlearn: 0.0000000\ttotal: 5.79s\tremaining: 1.74s\n",
            "769:\tlearn: 0.0000000\ttotal: 5.8s\tremaining: 1.73s\n",
            "770:\tlearn: 0.0000000\ttotal: 5.81s\tremaining: 1.72s\n",
            "771:\tlearn: 0.0000000\ttotal: 5.81s\tremaining: 1.72s\n",
            "772:\tlearn: 0.0000000\ttotal: 5.83s\tremaining: 1.71s\n",
            "773:\tlearn: 0.0000000\ttotal: 5.84s\tremaining: 1.71s\n",
            "774:\tlearn: 0.0000000\ttotal: 5.85s\tremaining: 1.7s\n",
            "775:\tlearn: 0.0000000\ttotal: 5.86s\tremaining: 1.69s\n",
            "776:\tlearn: 0.0000000\ttotal: 5.87s\tremaining: 1.68s\n",
            "777:\tlearn: 0.0000000\ttotal: 5.87s\tremaining: 1.68s\n",
            "778:\tlearn: 0.0000000\ttotal: 5.88s\tremaining: 1.67s\n",
            "779:\tlearn: 0.0000000\ttotal: 5.89s\tremaining: 1.66s\n",
            "780:\tlearn: 0.0000000\ttotal: 5.89s\tremaining: 1.65s\n",
            "781:\tlearn: 0.0000000\ttotal: 5.9s\tremaining: 1.65s\n",
            "782:\tlearn: 0.0000000\ttotal: 5.91s\tremaining: 1.64s\n",
            "783:\tlearn: 0.0000000\ttotal: 5.92s\tremaining: 1.63s\n",
            "784:\tlearn: 0.0000000\ttotal: 5.93s\tremaining: 1.62s\n",
            "785:\tlearn: 0.0000000\ttotal: 5.93s\tremaining: 1.62s\n",
            "786:\tlearn: 0.0000000\ttotal: 5.94s\tremaining: 1.61s\n",
            "787:\tlearn: 0.0000000\ttotal: 5.95s\tremaining: 1.6s\n",
            "788:\tlearn: 0.0000000\ttotal: 5.96s\tremaining: 1.59s\n",
            "789:\tlearn: 0.0000000\ttotal: 5.96s\tremaining: 1.58s\n",
            "790:\tlearn: 0.0000000\ttotal: 5.97s\tremaining: 1.58s\n",
            "791:\tlearn: 0.0000000\ttotal: 5.98s\tremaining: 1.57s\n",
            "792:\tlearn: 0.0000000\ttotal: 5.99s\tremaining: 1.56s\n",
            "793:\tlearn: 0.0000000\ttotal: 5.99s\tremaining: 1.55s\n",
            "794:\tlearn: 0.0000000\ttotal: 6s\tremaining: 1.55s\n",
            "795:\tlearn: 0.0000000\ttotal: 6.01s\tremaining: 1.54s\n",
            "796:\tlearn: 0.0000000\ttotal: 6.01s\tremaining: 1.53s\n",
            "797:\tlearn: 0.0000000\ttotal: 6.02s\tremaining: 1.52s\n",
            "798:\tlearn: 0.0000000\ttotal: 6.03s\tremaining: 1.52s\n",
            "799:\tlearn: 0.0000000\ttotal: 6.04s\tremaining: 1.51s\n",
            "800:\tlearn: 0.0000000\ttotal: 6.04s\tremaining: 1.5s\n",
            "801:\tlearn: 0.0000000\ttotal: 6.05s\tremaining: 1.49s\n",
            "802:\tlearn: 0.0000000\ttotal: 6.06s\tremaining: 1.49s\n",
            "803:\tlearn: 0.0000000\ttotal: 6.07s\tremaining: 1.48s\n",
            "804:\tlearn: 0.0000000\ttotal: 6.07s\tremaining: 1.47s\n",
            "805:\tlearn: 0.0000000\ttotal: 6.08s\tremaining: 1.46s\n",
            "806:\tlearn: 0.0000000\ttotal: 6.09s\tremaining: 1.46s\n",
            "807:\tlearn: 0.0000000\ttotal: 6.1s\tremaining: 1.45s\n",
            "808:\tlearn: 0.0000000\ttotal: 6.11s\tremaining: 1.44s\n",
            "809:\tlearn: 0.0000000\ttotal: 6.12s\tremaining: 1.44s\n",
            "810:\tlearn: 0.0000000\ttotal: 6.13s\tremaining: 1.43s\n",
            "811:\tlearn: 0.0000000\ttotal: 6.14s\tremaining: 1.42s\n",
            "812:\tlearn: 0.0000000\ttotal: 6.15s\tremaining: 1.41s\n",
            "813:\tlearn: 0.0000000\ttotal: 6.15s\tremaining: 1.41s\n",
            "814:\tlearn: 0.0000000\ttotal: 6.16s\tremaining: 1.4s\n",
            "815:\tlearn: 0.0000000\ttotal: 6.17s\tremaining: 1.39s\n",
            "816:\tlearn: 0.0000000\ttotal: 6.18s\tremaining: 1.38s\n",
            "817:\tlearn: 0.0000000\ttotal: 6.18s\tremaining: 1.38s\n",
            "818:\tlearn: 0.0000000\ttotal: 6.19s\tremaining: 1.37s\n",
            "819:\tlearn: 0.0000000\ttotal: 6.2s\tremaining: 1.36s\n",
            "820:\tlearn: 0.0000000\ttotal: 6.21s\tremaining: 1.35s\n",
            "821:\tlearn: 0.0000000\ttotal: 6.21s\tremaining: 1.34s\n",
            "822:\tlearn: 0.0000000\ttotal: 6.22s\tremaining: 1.34s\n",
            "823:\tlearn: 0.0000000\ttotal: 6.23s\tremaining: 1.33s\n",
            "824:\tlearn: 0.0000000\ttotal: 6.24s\tremaining: 1.32s\n",
            "825:\tlearn: 0.0000000\ttotal: 6.24s\tremaining: 1.31s\n",
            "826:\tlearn: 0.0000000\ttotal: 6.25s\tremaining: 1.31s\n",
            "827:\tlearn: 0.0000000\ttotal: 6.26s\tremaining: 1.3s\n",
            "828:\tlearn: 0.0000000\ttotal: 6.27s\tremaining: 1.29s\n",
            "829:\tlearn: 0.0000000\ttotal: 6.27s\tremaining: 1.28s\n",
            "830:\tlearn: 0.0000000\ttotal: 6.28s\tremaining: 1.28s\n",
            "831:\tlearn: 0.0000000\ttotal: 6.29s\tremaining: 1.27s\n",
            "832:\tlearn: 0.0000000\ttotal: 6.3s\tremaining: 1.26s\n",
            "833:\tlearn: 0.0000000\ttotal: 6.3s\tremaining: 1.25s\n",
            "834:\tlearn: 0.0000000\ttotal: 6.31s\tremaining: 1.25s\n",
            "835:\tlearn: 0.0000000\ttotal: 6.32s\tremaining: 1.24s\n",
            "836:\tlearn: 0.0000000\ttotal: 6.33s\tremaining: 1.23s\n",
            "837:\tlearn: 0.0000000\ttotal: 6.34s\tremaining: 1.23s\n",
            "838:\tlearn: 0.0000000\ttotal: 6.35s\tremaining: 1.22s\n",
            "839:\tlearn: 0.0000000\ttotal: 6.35s\tremaining: 1.21s\n",
            "840:\tlearn: 0.0000000\ttotal: 6.36s\tremaining: 1.2s\n",
            "841:\tlearn: 0.0000000\ttotal: 6.37s\tremaining: 1.2s\n",
            "842:\tlearn: 0.0000000\ttotal: 6.38s\tremaining: 1.19s\n",
            "843:\tlearn: 0.0000000\ttotal: 6.38s\tremaining: 1.18s\n",
            "844:\tlearn: 0.0000000\ttotal: 6.39s\tremaining: 1.17s\n",
            "845:\tlearn: 0.0000000\ttotal: 6.4s\tremaining: 1.16s\n",
            "846:\tlearn: 0.0000000\ttotal: 6.41s\tremaining: 1.16s\n",
            "847:\tlearn: 0.0000000\ttotal: 6.41s\tremaining: 1.15s\n",
            "848:\tlearn: 0.0000000\ttotal: 6.42s\tremaining: 1.14s\n",
            "849:\tlearn: 0.0000000\ttotal: 6.43s\tremaining: 1.13s\n",
            "850:\tlearn: 0.0000000\ttotal: 6.43s\tremaining: 1.13s\n",
            "851:\tlearn: 0.0000000\ttotal: 6.44s\tremaining: 1.12s\n",
            "852:\tlearn: 0.0000000\ttotal: 6.45s\tremaining: 1.11s\n",
            "853:\tlearn: 0.0000000\ttotal: 6.46s\tremaining: 1.1s\n",
            "854:\tlearn: 0.0000000\ttotal: 6.46s\tremaining: 1.1s\n",
            "855:\tlearn: 0.0000000\ttotal: 6.47s\tremaining: 1.09s\n",
            "856:\tlearn: 0.0000000\ttotal: 6.48s\tremaining: 1.08s\n",
            "857:\tlearn: 0.0000000\ttotal: 6.49s\tremaining: 1.07s\n",
            "858:\tlearn: 0.0000000\ttotal: 6.49s\tremaining: 1.07s\n",
            "859:\tlearn: 0.0000000\ttotal: 6.5s\tremaining: 1.06s\n",
            "860:\tlearn: 0.0000000\ttotal: 6.51s\tremaining: 1.05s\n",
            "861:\tlearn: 0.0000000\ttotal: 6.52s\tremaining: 1.04s\n",
            "862:\tlearn: 0.0000000\ttotal: 6.53s\tremaining: 1.03s\n",
            "863:\tlearn: 0.0000000\ttotal: 6.54s\tremaining: 1.03s\n",
            "864:\tlearn: 0.0000000\ttotal: 6.54s\tremaining: 1.02s\n",
            "865:\tlearn: 0.0000000\ttotal: 6.55s\tremaining: 1.01s\n",
            "866:\tlearn: 0.0000000\ttotal: 6.56s\tremaining: 1.01s\n",
            "867:\tlearn: 0.0000000\ttotal: 6.57s\tremaining: 999ms\n",
            "868:\tlearn: 0.0000000\ttotal: 6.57s\tremaining: 991ms\n",
            "869:\tlearn: 0.0000000\ttotal: 6.58s\tremaining: 983ms\n",
            "870:\tlearn: 0.0000000\ttotal: 6.59s\tremaining: 976ms\n",
            "871:\tlearn: 0.0000000\ttotal: 6.6s\tremaining: 969ms\n",
            "872:\tlearn: 0.0000000\ttotal: 6.61s\tremaining: 961ms\n",
            "873:\tlearn: 0.0000000\ttotal: 6.61s\tremaining: 954ms\n",
            "874:\tlearn: 0.0000000\ttotal: 6.62s\tremaining: 946ms\n",
            "875:\tlearn: 0.0000000\ttotal: 6.63s\tremaining: 939ms\n",
            "876:\tlearn: 0.0000000\ttotal: 6.64s\tremaining: 932ms\n",
            "877:\tlearn: 0.0000000\ttotal: 6.65s\tremaining: 925ms\n",
            "878:\tlearn: 0.0000000\ttotal: 6.66s\tremaining: 917ms\n",
            "879:\tlearn: 0.0000000\ttotal: 6.67s\tremaining: 910ms\n",
            "880:\tlearn: 0.0000000\ttotal: 6.68s\tremaining: 903ms\n",
            "881:\tlearn: 0.0000000\ttotal: 6.7s\tremaining: 896ms\n",
            "882:\tlearn: 0.0000000\ttotal: 6.71s\tremaining: 889ms\n",
            "883:\tlearn: 0.0000000\ttotal: 6.72s\tremaining: 882ms\n",
            "884:\tlearn: 0.0000000\ttotal: 6.73s\tremaining: 875ms\n",
            "885:\tlearn: 0.0000000\ttotal: 6.74s\tremaining: 868ms\n",
            "886:\tlearn: 0.0000000\ttotal: 6.75s\tremaining: 860ms\n",
            "887:\tlearn: 0.0000000\ttotal: 6.76s\tremaining: 853ms\n",
            "888:\tlearn: 0.0000000\ttotal: 6.78s\tremaining: 846ms\n",
            "889:\tlearn: 0.0000000\ttotal: 6.79s\tremaining: 839ms\n",
            "890:\tlearn: 0.0000000\ttotal: 6.8s\tremaining: 832ms\n",
            "891:\tlearn: 0.0000000\ttotal: 6.81s\tremaining: 824ms\n",
            "892:\tlearn: 0.0000000\ttotal: 6.82s\tremaining: 818ms\n",
            "893:\tlearn: 0.0000000\ttotal: 6.84s\tremaining: 811ms\n",
            "894:\tlearn: 0.0000000\ttotal: 6.86s\tremaining: 805ms\n",
            "895:\tlearn: 0.0000000\ttotal: 6.87s\tremaining: 797ms\n",
            "896:\tlearn: 0.0000000\ttotal: 6.88s\tremaining: 790ms\n",
            "897:\tlearn: 0.0000000\ttotal: 6.89s\tremaining: 782ms\n",
            "898:\tlearn: 0.0000000\ttotal: 6.9s\tremaining: 775ms\n",
            "899:\tlearn: 0.0000000\ttotal: 6.91s\tremaining: 768ms\n",
            "900:\tlearn: 0.0000000\ttotal: 6.92s\tremaining: 760ms\n",
            "901:\tlearn: 0.0000000\ttotal: 6.94s\tremaining: 754ms\n",
            "902:\tlearn: 0.0000000\ttotal: 6.96s\tremaining: 747ms\n",
            "903:\tlearn: 0.0000000\ttotal: 6.97s\tremaining: 741ms\n",
            "904:\tlearn: 0.0000000\ttotal: 6.99s\tremaining: 734ms\n",
            "905:\tlearn: 0.0000000\ttotal: 7.01s\tremaining: 727ms\n",
            "906:\tlearn: 0.0000000\ttotal: 7.02s\tremaining: 720ms\n",
            "907:\tlearn: 0.0000000\ttotal: 7.04s\tremaining: 713ms\n",
            "908:\tlearn: 0.0000000\ttotal: 7.05s\tremaining: 706ms\n",
            "909:\tlearn: 0.0000000\ttotal: 7.07s\tremaining: 699ms\n",
            "910:\tlearn: 0.0000000\ttotal: 7.08s\tremaining: 692ms\n",
            "911:\tlearn: 0.0000000\ttotal: 7.09s\tremaining: 685ms\n",
            "912:\tlearn: 0.0000000\ttotal: 7.11s\tremaining: 678ms\n",
            "913:\tlearn: 0.0000000\ttotal: 7.13s\tremaining: 671ms\n",
            "914:\tlearn: 0.0000000\ttotal: 7.15s\tremaining: 664ms\n",
            "915:\tlearn: 0.0000000\ttotal: 7.16s\tremaining: 657ms\n",
            "916:\tlearn: 0.0000000\ttotal: 7.18s\tremaining: 650ms\n",
            "917:\tlearn: 0.0000000\ttotal: 7.2s\tremaining: 643ms\n",
            "918:\tlearn: 0.0000000\ttotal: 7.21s\tremaining: 636ms\n",
            "919:\tlearn: 0.0000000\ttotal: 7.22s\tremaining: 628ms\n",
            "920:\tlearn: 0.0000000\ttotal: 7.24s\tremaining: 621ms\n",
            "921:\tlearn: 0.0000000\ttotal: 7.26s\tremaining: 614ms\n",
            "922:\tlearn: 0.0000000\ttotal: 7.27s\tremaining: 607ms\n",
            "923:\tlearn: 0.0000000\ttotal: 7.29s\tremaining: 600ms\n",
            "924:\tlearn: 0.0000000\ttotal: 7.3s\tremaining: 592ms\n",
            "925:\tlearn: 0.0000000\ttotal: 7.32s\tremaining: 585ms\n",
            "926:\tlearn: 0.0000000\ttotal: 7.34s\tremaining: 578ms\n",
            "927:\tlearn: 0.0000000\ttotal: 7.35s\tremaining: 571ms\n",
            "928:\tlearn: 0.0000000\ttotal: 7.37s\tremaining: 563ms\n",
            "929:\tlearn: 0.0000000\ttotal: 7.38s\tremaining: 556ms\n",
            "930:\tlearn: 0.0000000\ttotal: 7.4s\tremaining: 548ms\n",
            "931:\tlearn: 0.0000000\ttotal: 7.42s\tremaining: 541ms\n",
            "932:\tlearn: 0.0000000\ttotal: 7.43s\tremaining: 534ms\n",
            "933:\tlearn: 0.0000000\ttotal: 7.45s\tremaining: 527ms\n",
            "934:\tlearn: 0.0000000\ttotal: 7.47s\tremaining: 519ms\n",
            "935:\tlearn: 0.0000000\ttotal: 7.49s\tremaining: 512ms\n",
            "936:\tlearn: 0.0000000\ttotal: 7.5s\tremaining: 505ms\n",
            "937:\tlearn: 0.0000000\ttotal: 7.52s\tremaining: 497ms\n",
            "938:\tlearn: 0.0000000\ttotal: 7.54s\tremaining: 490ms\n",
            "939:\tlearn: 0.0000000\ttotal: 7.56s\tremaining: 483ms\n",
            "940:\tlearn: 0.0000000\ttotal: 7.58s\tremaining: 475ms\n",
            "941:\tlearn: 0.0000000\ttotal: 7.59s\tremaining: 468ms\n",
            "942:\tlearn: 0.0000000\ttotal: 7.61s\tremaining: 460ms\n",
            "943:\tlearn: 0.0000000\ttotal: 7.62s\tremaining: 452ms\n",
            "944:\tlearn: 0.0000000\ttotal: 7.64s\tremaining: 445ms\n",
            "945:\tlearn: 0.0000000\ttotal: 7.65s\tremaining: 437ms\n",
            "946:\tlearn: 0.0000000\ttotal: 7.67s\tremaining: 429ms\n",
            "947:\tlearn: 0.0000000\ttotal: 7.68s\tremaining: 422ms\n",
            "948:\tlearn: 0.0000000\ttotal: 7.7s\tremaining: 414ms\n",
            "949:\tlearn: 0.0000000\ttotal: 7.72s\tremaining: 406ms\n",
            "950:\tlearn: 0.0000000\ttotal: 7.73s\tremaining: 398ms\n",
            "951:\tlearn: 0.0000000\ttotal: 7.74s\tremaining: 390ms\n",
            "952:\tlearn: 0.0000000\ttotal: 7.76s\tremaining: 383ms\n",
            "953:\tlearn: 0.0000000\ttotal: 7.78s\tremaining: 375ms\n",
            "954:\tlearn: 0.0000000\ttotal: 7.8s\tremaining: 367ms\n",
            "955:\tlearn: 0.0000000\ttotal: 7.81s\tremaining: 359ms\n",
            "956:\tlearn: 0.0000000\ttotal: 7.82s\tremaining: 352ms\n",
            "957:\tlearn: 0.0000000\ttotal: 7.84s\tremaining: 344ms\n",
            "958:\tlearn: 0.0000000\ttotal: 7.86s\tremaining: 336ms\n",
            "959:\tlearn: 0.0000000\ttotal: 7.87s\tremaining: 328ms\n",
            "960:\tlearn: 0.0000000\ttotal: 7.89s\tremaining: 320ms\n",
            "961:\tlearn: 0.0000000\ttotal: 7.9s\tremaining: 312ms\n",
            "962:\tlearn: 0.0000000\ttotal: 7.92s\tremaining: 304ms\n",
            "963:\tlearn: 0.0000000\ttotal: 7.93s\tremaining: 296ms\n",
            "964:\tlearn: 0.0000000\ttotal: 7.94s\tremaining: 288ms\n",
            "965:\tlearn: 0.0000000\ttotal: 7.96s\tremaining: 280ms\n",
            "966:\tlearn: 0.0000000\ttotal: 7.98s\tremaining: 272ms\n",
            "967:\tlearn: 0.0000000\ttotal: 7.99s\tremaining: 264ms\n",
            "968:\tlearn: 0.0000000\ttotal: 8.01s\tremaining: 256ms\n",
            "969:\tlearn: 0.0000000\ttotal: 8.02s\tremaining: 248ms\n",
            "970:\tlearn: 0.0000000\ttotal: 8.04s\tremaining: 240ms\n",
            "971:\tlearn: 0.0000000\ttotal: 8.05s\tremaining: 232ms\n",
            "972:\tlearn: 0.0000000\ttotal: 8.07s\tremaining: 224ms\n",
            "973:\tlearn: 0.0000000\ttotal: 8.09s\tremaining: 216ms\n",
            "974:\tlearn: 0.0000000\ttotal: 8.1s\tremaining: 208ms\n",
            "975:\tlearn: 0.0000000\ttotal: 8.12s\tremaining: 200ms\n",
            "976:\tlearn: 0.0000000\ttotal: 8.14s\tremaining: 192ms\n",
            "977:\tlearn: 0.0000000\ttotal: 8.15s\tremaining: 183ms\n",
            "978:\tlearn: 0.0000000\ttotal: 8.17s\tremaining: 175ms\n",
            "979:\tlearn: 0.0000000\ttotal: 8.19s\tremaining: 167ms\n",
            "980:\tlearn: 0.0000000\ttotal: 8.21s\tremaining: 159ms\n",
            "981:\tlearn: 0.0000000\ttotal: 8.23s\tremaining: 151ms\n",
            "982:\tlearn: 0.0000000\ttotal: 8.24s\tremaining: 143ms\n",
            "983:\tlearn: 0.0000000\ttotal: 8.26s\tremaining: 134ms\n",
            "984:\tlearn: 0.0000000\ttotal: 8.28s\tremaining: 126ms\n",
            "985:\tlearn: 0.0000000\ttotal: 8.29s\tremaining: 118ms\n",
            "986:\tlearn: 0.0000000\ttotal: 8.31s\tremaining: 109ms\n",
            "987:\tlearn: 0.0000000\ttotal: 8.33s\tremaining: 101ms\n",
            "988:\tlearn: 0.0000000\ttotal: 8.35s\tremaining: 92.9ms\n",
            "989:\tlearn: 0.0000000\ttotal: 8.36s\tremaining: 84.5ms\n",
            "990:\tlearn: 0.0000000\ttotal: 8.38s\tremaining: 76.1ms\n",
            "991:\tlearn: 0.0000000\ttotal: 8.4s\tremaining: 67.7ms\n",
            "992:\tlearn: 0.0000000\ttotal: 8.42s\tremaining: 59.3ms\n",
            "993:\tlearn: 0.0000000\ttotal: 8.43s\tremaining: 50.9ms\n",
            "994:\tlearn: 0.0000000\ttotal: 8.45s\tremaining: 42.4ms\n",
            "995:\tlearn: 0.0000000\ttotal: 8.46s\tremaining: 34ms\n",
            "996:\tlearn: 0.0000000\ttotal: 8.48s\tremaining: 25.5ms\n",
            "997:\tlearn: 0.0000000\ttotal: 8.5s\tremaining: 17ms\n",
            "998:\tlearn: 0.0000000\ttotal: 8.52s\tremaining: 8.53ms\n",
            "999:\tlearn: 0.0000000\ttotal: 8.53s\tremaining: 0us\n",
            "0:\tlearn: 0.5155193\ttotal: 11.2ms\tremaining: 11.2s\n",
            "1:\tlearn: 0.5041317\ttotal: 22.2ms\tremaining: 11.1s\n",
            "2:\tlearn: 0.4923521\ttotal: 38.4ms\tremaining: 12.8s\n",
            "3:\tlearn: 0.4818788\ttotal: 55.1ms\tremaining: 13.7s\n",
            "4:\tlearn: 0.4692249\ttotal: 71.6ms\tremaining: 14.2s\n",
            "5:\tlearn: 0.4550076\ttotal: 86.9ms\tremaining: 14.4s\n",
            "6:\tlearn: 0.4448427\ttotal: 102ms\tremaining: 14.5s\n",
            "7:\tlearn: 0.4343420\ttotal: 116ms\tremaining: 14.4s\n",
            "8:\tlearn: 0.4238805\ttotal: 127ms\tremaining: 13.9s\n",
            "9:\tlearn: 0.4139966\ttotal: 137ms\tremaining: 13.6s\n",
            "10:\tlearn: 0.4042411\ttotal: 147ms\tremaining: 13.2s\n",
            "11:\tlearn: 0.3926621\ttotal: 164ms\tremaining: 13.5s\n",
            "12:\tlearn: 0.3845368\ttotal: 168ms\tremaining: 12.8s\n",
            "13:\tlearn: 0.3738907\ttotal: 184ms\tremaining: 12.9s\n",
            "14:\tlearn: 0.3645914\ttotal: 193ms\tremaining: 12.7s\n",
            "15:\tlearn: 0.3545210\ttotal: 202ms\tremaining: 12.4s\n",
            "16:\tlearn: 0.3445194\ttotal: 206ms\tremaining: 11.9s\n",
            "17:\tlearn: 0.3344455\ttotal: 226ms\tremaining: 12.3s\n",
            "18:\tlearn: 0.3257406\ttotal: 243ms\tremaining: 12.6s\n",
            "19:\tlearn: 0.3175869\ttotal: 254ms\tremaining: 12.4s\n",
            "20:\tlearn: 0.3101109\ttotal: 257ms\tremaining: 12s\n",
            "21:\tlearn: 0.3022513\ttotal: 272ms\tremaining: 12.1s\n",
            "22:\tlearn: 0.2956292\ttotal: 286ms\tremaining: 12.1s\n",
            "23:\tlearn: 0.2867630\ttotal: 299ms\tremaining: 12.2s\n",
            "24:\tlearn: 0.2805233\ttotal: 315ms\tremaining: 12.3s\n",
            "25:\tlearn: 0.2744802\ttotal: 330ms\tremaining: 12.4s\n",
            "26:\tlearn: 0.2671565\ttotal: 345ms\tremaining: 12.4s\n",
            "27:\tlearn: 0.2604491\ttotal: 359ms\tremaining: 12.5s\n",
            "28:\tlearn: 0.2553337\ttotal: 360ms\tremaining: 12.1s\n",
            "29:\tlearn: 0.2489354\ttotal: 363ms\tremaining: 11.7s\n",
            "30:\tlearn: 0.2415616\ttotal: 365ms\tremaining: 11.4s\n",
            "31:\tlearn: 0.2357047\ttotal: 374ms\tremaining: 11.3s\n",
            "32:\tlearn: 0.2321340\ttotal: 381ms\tremaining: 11.2s\n",
            "33:\tlearn: 0.2264794\ttotal: 396ms\tremaining: 11.3s\n",
            "34:\tlearn: 0.2203902\ttotal: 410ms\tremaining: 11.3s\n",
            "35:\tlearn: 0.2165466\ttotal: 416ms\tremaining: 11.1s\n",
            "36:\tlearn: 0.2110865\ttotal: 431ms\tremaining: 11.2s\n",
            "37:\tlearn: 0.2058469\ttotal: 446ms\tremaining: 11.3s\n",
            "38:\tlearn: 0.2005133\ttotal: 462ms\tremaining: 11.4s\n",
            "39:\tlearn: 0.1950738\ttotal: 470ms\tremaining: 11.3s\n",
            "40:\tlearn: 0.1903034\ttotal: 485ms\tremaining: 11.3s\n",
            "41:\tlearn: 0.1853582\ttotal: 499ms\tremaining: 11.4s\n",
            "42:\tlearn: 0.1804987\ttotal: 513ms\tremaining: 11.4s\n",
            "43:\tlearn: 0.1766287\ttotal: 518ms\tremaining: 11.3s\n",
            "44:\tlearn: 0.1720583\ttotal: 533ms\tremaining: 11.3s\n",
            "45:\tlearn: 0.1677678\ttotal: 549ms\tremaining: 11.4s\n",
            "46:\tlearn: 0.1625646\ttotal: 566ms\tremaining: 11.5s\n",
            "47:\tlearn: 0.1585859\ttotal: 577ms\tremaining: 11.4s\n",
            "48:\tlearn: 0.1570425\ttotal: 579ms\tremaining: 11.2s\n",
            "49:\tlearn: 0.1539663\ttotal: 588ms\tremaining: 11.2s\n",
            "50:\tlearn: 0.1501108\ttotal: 605ms\tremaining: 11.3s\n",
            "51:\tlearn: 0.1467327\ttotal: 622ms\tremaining: 11.3s\n",
            "52:\tlearn: 0.1430539\ttotal: 643ms\tremaining: 11.5s\n",
            "53:\tlearn: 0.1394940\ttotal: 659ms\tremaining: 11.5s\n",
            "54:\tlearn: 0.1367200\ttotal: 676ms\tremaining: 11.6s\n",
            "55:\tlearn: 0.1347959\ttotal: 682ms\tremaining: 11.5s\n",
            "56:\tlearn: 0.1308333\ttotal: 699ms\tremaining: 11.6s\n",
            "57:\tlearn: 0.1283309\ttotal: 718ms\tremaining: 11.7s\n",
            "58:\tlearn: 0.1250744\ttotal: 734ms\tremaining: 11.7s\n",
            "59:\tlearn: 0.1222501\ttotal: 751ms\tremaining: 11.8s\n",
            "60:\tlearn: 0.1207115\ttotal: 763ms\tremaining: 11.7s\n",
            "61:\tlearn: 0.1176994\ttotal: 780ms\tremaining: 11.8s\n",
            "62:\tlearn: 0.1151919\ttotal: 797ms\tremaining: 11.9s\n",
            "63:\tlearn: 0.1123651\ttotal: 815ms\tremaining: 11.9s\n",
            "64:\tlearn: 0.1098001\ttotal: 832ms\tremaining: 12s\n",
            "65:\tlearn: 0.1071086\ttotal: 853ms\tremaining: 12.1s\n",
            "66:\tlearn: 0.1040775\ttotal: 870ms\tremaining: 12.1s\n",
            "67:\tlearn: 0.1013712\ttotal: 885ms\tremaining: 12.1s\n",
            "68:\tlearn: 0.0989101\ttotal: 902ms\tremaining: 12.2s\n",
            "69:\tlearn: 0.0964136\ttotal: 919ms\tremaining: 12.2s\n",
            "70:\tlearn: 0.0939282\ttotal: 933ms\tremaining: 12.2s\n",
            "71:\tlearn: 0.0916190\ttotal: 949ms\tremaining: 12.2s\n",
            "72:\tlearn: 0.0892015\ttotal: 963ms\tremaining: 12.2s\n",
            "73:\tlearn: 0.0869886\ttotal: 979ms\tremaining: 12.3s\n",
            "74:\tlearn: 0.0848484\ttotal: 993ms\tremaining: 12.2s\n",
            "75:\tlearn: 0.0827617\ttotal: 1.01s\tremaining: 12.3s\n",
            "76:\tlearn: 0.0806972\ttotal: 1.02s\tremaining: 12.3s\n",
            "77:\tlearn: 0.0786540\ttotal: 1.04s\tremaining: 12.3s\n",
            "78:\tlearn: 0.0766769\ttotal: 1.05s\tremaining: 12.3s\n",
            "79:\tlearn: 0.0747750\ttotal: 1.07s\tremaining: 12.3s\n",
            "80:\tlearn: 0.0729002\ttotal: 1.08s\tremaining: 12.3s\n",
            "81:\tlearn: 0.0706989\ttotal: 1.1s\tremaining: 12.3s\n",
            "82:\tlearn: 0.0687038\ttotal: 1.11s\tremaining: 12.3s\n",
            "83:\tlearn: 0.0670144\ttotal: 1.13s\tremaining: 12.3s\n",
            "84:\tlearn: 0.0653680\ttotal: 1.14s\tremaining: 12.3s\n",
            "85:\tlearn: 0.0637221\ttotal: 1.16s\tremaining: 12.4s\n",
            "86:\tlearn: 0.0621469\ttotal: 1.18s\tremaining: 12.4s\n",
            "87:\tlearn: 0.0605498\ttotal: 1.2s\tremaining: 12.4s\n",
            "88:\tlearn: 0.0590598\ttotal: 1.21s\tremaining: 12.4s\n",
            "89:\tlearn: 0.0575570\ttotal: 1.22s\tremaining: 12.4s\n",
            "90:\tlearn: 0.0561046\ttotal: 1.24s\tremaining: 12.4s\n",
            "91:\tlearn: 0.0547259\ttotal: 1.26s\tremaining: 12.4s\n",
            "92:\tlearn: 0.0533679\ttotal: 1.26s\tremaining: 12.3s\n",
            "93:\tlearn: 0.0520324\ttotal: 1.28s\tremaining: 12.4s\n",
            "94:\tlearn: 0.0507134\ttotal: 1.29s\tremaining: 12.3s\n",
            "95:\tlearn: 0.0494166\ttotal: 1.31s\tremaining: 12.3s\n",
            "96:\tlearn: 0.0481832\ttotal: 1.32s\tremaining: 12.3s\n",
            "97:\tlearn: 0.0469633\ttotal: 1.34s\tremaining: 12.3s\n",
            "98:\tlearn: 0.0457750\ttotal: 1.36s\tremaining: 12.3s\n",
            "99:\tlearn: 0.0446166\ttotal: 1.37s\tremaining: 12.3s\n",
            "100:\tlearn: 0.0434893\ttotal: 1.39s\tremaining: 12.3s\n",
            "101:\tlearn: 0.0423867\ttotal: 1.4s\tremaining: 12.3s\n",
            "102:\tlearn: 0.0413318\ttotal: 1.42s\tremaining: 12.4s\n",
            "103:\tlearn: 0.0402871\ttotal: 1.43s\tremaining: 12.4s\n",
            "104:\tlearn: 0.0392735\ttotal: 1.45s\tremaining: 12.4s\n",
            "105:\tlearn: 0.0382834\ttotal: 1.47s\tremaining: 12.4s\n",
            "106:\tlearn: 0.0373327\ttotal: 1.48s\tremaining: 12.4s\n",
            "107:\tlearn: 0.0363934\ttotal: 1.5s\tremaining: 12.4s\n",
            "108:\tlearn: 0.0354788\ttotal: 1.52s\tremaining: 12.4s\n",
            "109:\tlearn: 0.0345827\ttotal: 1.53s\tremaining: 12.4s\n",
            "110:\tlearn: 0.0337256\ttotal: 1.55s\tremaining: 12.4s\n",
            "111:\tlearn: 0.0328787\ttotal: 1.57s\tremaining: 12.4s\n",
            "112:\tlearn: 0.0320487\ttotal: 1.58s\tremaining: 12.4s\n",
            "113:\tlearn: 0.0312402\ttotal: 1.6s\tremaining: 12.4s\n",
            "114:\tlearn: 0.0304560\ttotal: 1.61s\tremaining: 12.4s\n",
            "115:\tlearn: 0.0296882\ttotal: 1.63s\tremaining: 12.4s\n",
            "116:\tlearn: 0.0289433\ttotal: 1.65s\tremaining: 12.4s\n",
            "117:\tlearn: 0.0282141\ttotal: 1.66s\tremaining: 12.4s\n",
            "118:\tlearn: 0.0275066\ttotal: 1.67s\tremaining: 12.4s\n",
            "119:\tlearn: 0.0268140\ttotal: 1.69s\tremaining: 12.4s\n",
            "120:\tlearn: 0.0261419\ttotal: 1.7s\tremaining: 12.4s\n",
            "121:\tlearn: 0.0254841\ttotal: 1.72s\tremaining: 12.3s\n",
            "122:\tlearn: 0.0248456\ttotal: 1.73s\tremaining: 12.3s\n",
            "123:\tlearn: 0.0242208\ttotal: 1.74s\tremaining: 12.3s\n",
            "124:\tlearn: 0.0236144\ttotal: 1.75s\tremaining: 12.2s\n",
            "125:\tlearn: 0.0230140\ttotal: 1.76s\tremaining: 12.2s\n",
            "126:\tlearn: 0.0224378\ttotal: 1.78s\tremaining: 12.2s\n",
            "127:\tlearn: 0.0218764\ttotal: 1.79s\tremaining: 12.2s\n",
            "128:\tlearn: 0.0213203\ttotal: 1.8s\tremaining: 12.2s\n",
            "129:\tlearn: 0.0207868\ttotal: 1.82s\tremaining: 12.2s\n",
            "130:\tlearn: 0.0202587\ttotal: 1.83s\tremaining: 12.1s\n",
            "131:\tlearn: 0.0197518\ttotal: 1.84s\tremaining: 12.1s\n",
            "132:\tlearn: 0.0192579\ttotal: 1.85s\tremaining: 12.1s\n",
            "133:\tlearn: 0.0187687\ttotal: 1.86s\tremaining: 12s\n",
            "134:\tlearn: 0.0182993\ttotal: 1.87s\tremaining: 12s\n",
            "135:\tlearn: 0.0178347\ttotal: 1.88s\tremaining: 12s\n",
            "136:\tlearn: 0.0173890\ttotal: 1.89s\tremaining: 11.9s\n",
            "137:\tlearn: 0.0169544\ttotal: 1.9s\tremaining: 11.9s\n",
            "138:\tlearn: 0.0165309\ttotal: 1.91s\tremaining: 11.8s\n",
            "139:\tlearn: 0.0161180\ttotal: 1.92s\tremaining: 11.8s\n",
            "140:\tlearn: 0.0157092\ttotal: 1.94s\tremaining: 11.8s\n",
            "141:\tlearn: 0.0153169\ttotal: 1.95s\tremaining: 11.8s\n",
            "142:\tlearn: 0.0149346\ttotal: 1.97s\tremaining: 11.8s\n",
            "143:\tlearn: 0.0145619\ttotal: 1.98s\tremaining: 11.8s\n",
            "144:\tlearn: 0.0141985\ttotal: 1.99s\tremaining: 11.7s\n",
            "145:\tlearn: 0.0138444\ttotal: 2s\tremaining: 11.7s\n",
            "146:\tlearn: 0.0134992\ttotal: 2.01s\tremaining: 11.6s\n",
            "147:\tlearn: 0.0131571\ttotal: 2.02s\tremaining: 11.6s\n",
            "148:\tlearn: 0.0128291\ttotal: 2.03s\tremaining: 11.6s\n",
            "149:\tlearn: 0.0125094\ttotal: 2.04s\tremaining: 11.6s\n",
            "150:\tlearn: 0.0121977\ttotal: 2.05s\tremaining: 11.5s\n",
            "151:\tlearn: 0.0118940\ttotal: 2.07s\tremaining: 11.6s\n",
            "152:\tlearn: 0.0115979\ttotal: 2.09s\tremaining: 11.6s\n",
            "153:\tlearn: 0.0113092\ttotal: 2.11s\tremaining: 11.6s\n",
            "154:\tlearn: 0.0110279\ttotal: 2.12s\tremaining: 11.6s\n",
            "155:\tlearn: 0.0107537\ttotal: 2.14s\tremaining: 11.6s\n",
            "156:\tlearn: 0.0104816\ttotal: 2.15s\tremaining: 11.6s\n",
            "157:\tlearn: 0.0102210\ttotal: 2.17s\tremaining: 11.6s\n",
            "158:\tlearn: 0.0099670\ttotal: 2.19s\tremaining: 11.6s\n",
            "159:\tlearn: 0.0097194\ttotal: 2.21s\tremaining: 11.6s\n",
            "160:\tlearn: 0.0094781\ttotal: 2.22s\tremaining: 11.6s\n",
            "161:\tlearn: 0.0092429\ttotal: 2.25s\tremaining: 11.6s\n",
            "162:\tlearn: 0.0090136\ttotal: 2.27s\tremaining: 11.6s\n",
            "163:\tlearn: 0.0087901\ttotal: 2.29s\tremaining: 11.7s\n",
            "164:\tlearn: 0.0085723\ttotal: 2.3s\tremaining: 11.7s\n",
            "165:\tlearn: 0.0083551\ttotal: 2.32s\tremaining: 11.6s\n",
            "166:\tlearn: 0.0081435\ttotal: 2.33s\tremaining: 11.6s\n",
            "167:\tlearn: 0.0079417\ttotal: 2.35s\tremaining: 11.6s\n",
            "168:\tlearn: 0.0077407\ttotal: 2.36s\tremaining: 11.6s\n",
            "169:\tlearn: 0.0075448\ttotal: 2.38s\tremaining: 11.6s\n",
            "170:\tlearn: 0.0073555\ttotal: 2.39s\tremaining: 11.6s\n",
            "171:\tlearn: 0.0071732\ttotal: 2.41s\tremaining: 11.6s\n",
            "172:\tlearn: 0.0069918\ttotal: 2.42s\tremaining: 11.6s\n",
            "173:\tlearn: 0.0068150\ttotal: 2.44s\tremaining: 11.6s\n",
            "174:\tlearn: 0.0066439\ttotal: 2.44s\tremaining: 11.5s\n",
            "175:\tlearn: 0.0064793\ttotal: 2.45s\tremaining: 11.5s\n",
            "176:\tlearn: 0.0063155\ttotal: 2.46s\tremaining: 11.4s\n",
            "177:\tlearn: 0.0061560\ttotal: 2.47s\tremaining: 11.4s\n",
            "178:\tlearn: 0.0060015\ttotal: 2.48s\tremaining: 11.4s\n",
            "179:\tlearn: 0.0058528\ttotal: 2.49s\tremaining: 11.3s\n",
            "180:\tlearn: 0.0057050\ttotal: 2.49s\tremaining: 11.3s\n",
            "181:\tlearn: 0.0055610\ttotal: 2.5s\tremaining: 11.2s\n",
            "182:\tlearn: 0.0054232\ttotal: 2.51s\tremaining: 11.2s\n",
            "183:\tlearn: 0.0052872\ttotal: 2.52s\tremaining: 11.2s\n",
            "184:\tlearn: 0.0051539\ttotal: 2.52s\tremaining: 11.1s\n",
            "185:\tlearn: 0.0050239\ttotal: 2.53s\tremaining: 11.1s\n",
            "186:\tlearn: 0.0048994\ttotal: 2.54s\tremaining: 11s\n",
            "187:\tlearn: 0.0047759\ttotal: 2.54s\tremaining: 11s\n",
            "188:\tlearn: 0.0046555\ttotal: 2.55s\tremaining: 11s\n",
            "189:\tlearn: 0.0045388\ttotal: 2.56s\tremaining: 10.9s\n",
            "190:\tlearn: 0.0044263\ttotal: 2.57s\tremaining: 10.9s\n",
            "191:\tlearn: 0.0043148\ttotal: 2.57s\tremaining: 10.8s\n",
            "192:\tlearn: 0.0042062\ttotal: 2.58s\tremaining: 10.8s\n",
            "193:\tlearn: 0.0041020\ttotal: 2.59s\tremaining: 10.8s\n",
            "194:\tlearn: 0.0039987\ttotal: 2.59s\tremaining: 10.7s\n",
            "195:\tlearn: 0.0038984\ttotal: 2.6s\tremaining: 10.7s\n",
            "196:\tlearn: 0.0038006\ttotal: 2.61s\tremaining: 10.6s\n",
            "197:\tlearn: 0.0037053\ttotal: 2.62s\tremaining: 10.6s\n",
            "198:\tlearn: 0.0036125\ttotal: 2.62s\tremaining: 10.6s\n",
            "199:\tlearn: 0.0035220\ttotal: 2.63s\tremaining: 10.5s\n",
            "200:\tlearn: 0.0034339\ttotal: 2.64s\tremaining: 10.5s\n",
            "201:\tlearn: 0.0033480\ttotal: 2.65s\tremaining: 10.5s\n",
            "202:\tlearn: 0.0032641\ttotal: 2.65s\tremaining: 10.4s\n",
            "203:\tlearn: 0.0031825\ttotal: 2.66s\tremaining: 10.4s\n",
            "204:\tlearn: 0.0031031\ttotal: 2.67s\tremaining: 10.3s\n",
            "205:\tlearn: 0.0030256\ttotal: 2.68s\tremaining: 10.3s\n",
            "206:\tlearn: 0.0029501\ttotal: 2.69s\tremaining: 10.3s\n",
            "207:\tlearn: 0.0028762\ttotal: 2.69s\tremaining: 10.3s\n",
            "208:\tlearn: 0.0028045\ttotal: 2.7s\tremaining: 10.2s\n",
            "209:\tlearn: 0.0027347\ttotal: 2.71s\tremaining: 10.2s\n",
            "210:\tlearn: 0.0026666\ttotal: 2.72s\tremaining: 10.2s\n",
            "211:\tlearn: 0.0025998\ttotal: 2.73s\tremaining: 10.1s\n",
            "212:\tlearn: 0.0025338\ttotal: 2.73s\tremaining: 10.1s\n",
            "213:\tlearn: 0.0024707\ttotal: 2.74s\tremaining: 10.1s\n",
            "214:\tlearn: 0.0024093\ttotal: 2.75s\tremaining: 10s\n",
            "215:\tlearn: 0.0023494\ttotal: 2.76s\tremaining: 10s\n",
            "216:\tlearn: 0.0022910\ttotal: 2.77s\tremaining: 9.98s\n",
            "217:\tlearn: 0.0022337\ttotal: 2.77s\tremaining: 9.95s\n",
            "218:\tlearn: 0.0021782\ttotal: 2.78s\tremaining: 9.91s\n",
            "219:\tlearn: 0.0021241\ttotal: 2.79s\tremaining: 9.88s\n",
            "220:\tlearn: 0.0020714\ttotal: 2.79s\tremaining: 9.85s\n",
            "221:\tlearn: 0.0020201\ttotal: 2.8s\tremaining: 9.81s\n",
            "222:\tlearn: 0.0019700\ttotal: 2.81s\tremaining: 9.78s\n",
            "223:\tlearn: 0.0019202\ttotal: 2.81s\tremaining: 9.75s\n",
            "224:\tlearn: 0.0018727\ttotal: 2.82s\tremaining: 9.72s\n",
            "225:\tlearn: 0.0018252\ttotal: 2.83s\tremaining: 9.69s\n",
            "226:\tlearn: 0.0017800\ttotal: 2.83s\tremaining: 9.65s\n",
            "227:\tlearn: 0.0017343\ttotal: 2.84s\tremaining: 9.63s\n",
            "228:\tlearn: 0.0016897\ttotal: 2.85s\tremaining: 9.6s\n",
            "229:\tlearn: 0.0016470\ttotal: 2.86s\tremaining: 9.57s\n",
            "230:\tlearn: 0.0016057\ttotal: 2.86s\tremaining: 9.54s\n",
            "231:\tlearn: 0.0015659\ttotal: 2.87s\tremaining: 9.51s\n",
            "232:\tlearn: 0.0015267\ttotal: 2.88s\tremaining: 9.48s\n",
            "233:\tlearn: 0.0014882\ttotal: 2.89s\tremaining: 9.46s\n",
            "234:\tlearn: 0.0014508\ttotal: 2.9s\tremaining: 9.43s\n",
            "235:\tlearn: 0.0014145\ttotal: 2.9s\tremaining: 9.4s\n",
            "236:\tlearn: 0.0013790\ttotal: 2.91s\tremaining: 9.37s\n",
            "237:\tlearn: 0.0013444\ttotal: 2.92s\tremaining: 9.34s\n",
            "238:\tlearn: 0.0013107\ttotal: 2.92s\tremaining: 9.31s\n",
            "239:\tlearn: 0.0012782\ttotal: 2.93s\tremaining: 9.28s\n",
            "240:\tlearn: 0.0012462\ttotal: 2.94s\tremaining: 9.25s\n",
            "241:\tlearn: 0.0012144\ttotal: 2.94s\tremaining: 9.22s\n",
            "242:\tlearn: 0.0011835\ttotal: 2.95s\tremaining: 9.2s\n",
            "243:\tlearn: 0.0011533\ttotal: 2.96s\tremaining: 9.18s\n",
            "244:\tlearn: 0.0011240\ttotal: 2.97s\tremaining: 9.15s\n",
            "245:\tlearn: 0.0010954\ttotal: 2.98s\tremaining: 9.12s\n",
            "246:\tlearn: 0.0010683\ttotal: 2.98s\tremaining: 9.1s\n",
            "247:\tlearn: 0.0010411\ttotal: 2.99s\tremaining: 9.07s\n",
            "248:\tlearn: 0.0010147\ttotal: 3s\tremaining: 9.04s\n",
            "249:\tlearn: 0.0009892\ttotal: 3s\tremaining: 9.01s\n",
            "250:\tlearn: 0.0009641\ttotal: 3.01s\tremaining: 8.99s\n",
            "251:\tlearn: 0.0009397\ttotal: 3.02s\tremaining: 8.96s\n",
            "252:\tlearn: 0.0009158\ttotal: 3.03s\tremaining: 8.94s\n",
            "253:\tlearn: 0.0008926\ttotal: 3.03s\tremaining: 8.91s\n",
            "254:\tlearn: 0.0008700\ttotal: 3.04s\tremaining: 8.88s\n",
            "255:\tlearn: 0.0008485\ttotal: 3.05s\tremaining: 8.86s\n",
            "256:\tlearn: 0.0008270\ttotal: 3.06s\tremaining: 8.83s\n",
            "257:\tlearn: 0.0008061\ttotal: 3.06s\tremaining: 8.81s\n",
            "258:\tlearn: 0.0007857\ttotal: 3.07s\tremaining: 8.78s\n",
            "259:\tlearn: 0.0007658\ttotal: 3.08s\tremaining: 8.76s\n",
            "260:\tlearn: 0.0007465\ttotal: 3.09s\tremaining: 8.74s\n",
            "261:\tlearn: 0.0007279\ttotal: 3.1s\tremaining: 8.72s\n",
            "262:\tlearn: 0.0007099\ttotal: 3.1s\tremaining: 8.69s\n",
            "263:\tlearn: 0.0006923\ttotal: 3.11s\tremaining: 8.67s\n",
            "264:\tlearn: 0.0006751\ttotal: 3.12s\tremaining: 8.64s\n",
            "265:\tlearn: 0.0006583\ttotal: 3.12s\tremaining: 8.62s\n",
            "266:\tlearn: 0.0006418\ttotal: 3.13s\tremaining: 8.59s\n",
            "267:\tlearn: 0.0006256\ttotal: 3.14s\tremaining: 8.57s\n",
            "268:\tlearn: 0.0006099\ttotal: 3.14s\tremaining: 8.54s\n",
            "269:\tlearn: 0.0005945\ttotal: 3.15s\tremaining: 8.52s\n",
            "270:\tlearn: 0.0005795\ttotal: 3.16s\tremaining: 8.5s\n",
            "271:\tlearn: 0.0005651\ttotal: 3.17s\tremaining: 8.47s\n",
            "272:\tlearn: 0.0005511\ttotal: 3.17s\tremaining: 8.45s\n",
            "273:\tlearn: 0.0005373\ttotal: 3.18s\tremaining: 8.43s\n",
            "274:\tlearn: 0.0005238\ttotal: 3.2s\tremaining: 8.43s\n",
            "275:\tlearn: 0.0005106\ttotal: 3.21s\tremaining: 8.41s\n",
            "276:\tlearn: 0.0004977\ttotal: 3.21s\tremaining: 8.38s\n",
            "277:\tlearn: 0.0004853\ttotal: 3.22s\tremaining: 8.37s\n",
            "278:\tlearn: 0.0004733\ttotal: 3.23s\tremaining: 8.35s\n",
            "279:\tlearn: 0.0004615\ttotal: 3.24s\tremaining: 8.32s\n",
            "280:\tlearn: 0.0004501\ttotal: 3.25s\tremaining: 8.31s\n",
            "281:\tlearn: 0.0004388\ttotal: 3.26s\tremaining: 8.29s\n",
            "282:\tlearn: 0.0004277\ttotal: 3.26s\tremaining: 8.27s\n",
            "283:\tlearn: 0.0004170\ttotal: 3.27s\tremaining: 8.25s\n",
            "284:\tlearn: 0.0004065\ttotal: 3.28s\tremaining: 8.23s\n",
            "285:\tlearn: 0.0003963\ttotal: 3.29s\tremaining: 8.22s\n",
            "286:\tlearn: 0.0003863\ttotal: 3.3s\tremaining: 8.2s\n",
            "287:\tlearn: 0.0003767\ttotal: 3.31s\tremaining: 8.18s\n",
            "288:\tlearn: 0.0003673\ttotal: 3.31s\tremaining: 8.16s\n",
            "289:\tlearn: 0.0003581\ttotal: 3.32s\tremaining: 8.13s\n",
            "290:\tlearn: 0.0003491\ttotal: 3.33s\tremaining: 8.11s\n",
            "291:\tlearn: 0.0003405\ttotal: 3.34s\tremaining: 8.09s\n",
            "292:\tlearn: 0.0003319\ttotal: 3.34s\tremaining: 8.07s\n",
            "293:\tlearn: 0.0003236\ttotal: 3.35s\tremaining: 8.05s\n",
            "294:\tlearn: 0.0003155\ttotal: 3.36s\tremaining: 8.03s\n",
            "295:\tlearn: 0.0003076\ttotal: 3.37s\tremaining: 8.01s\n",
            "296:\tlearn: 0.0002999\ttotal: 3.37s\tremaining: 7.98s\n",
            "297:\tlearn: 0.0002924\ttotal: 3.38s\tremaining: 7.96s\n",
            "298:\tlearn: 0.0002851\ttotal: 3.39s\tremaining: 7.94s\n",
            "299:\tlearn: 0.0002776\ttotal: 3.4s\tremaining: 7.92s\n",
            "300:\tlearn: 0.0002703\ttotal: 3.4s\tremaining: 7.9s\n",
            "301:\tlearn: 0.0002638\ttotal: 3.41s\tremaining: 7.88s\n",
            "302:\tlearn: 0.0002571\ttotal: 3.42s\tremaining: 7.86s\n",
            "303:\tlearn: 0.0002507\ttotal: 3.42s\tremaining: 7.84s\n",
            "304:\tlearn: 0.0002444\ttotal: 3.43s\tremaining: 7.82s\n",
            "305:\tlearn: 0.0002382\ttotal: 3.44s\tremaining: 7.8s\n",
            "306:\tlearn: 0.0002322\ttotal: 3.44s\tremaining: 7.78s\n",
            "307:\tlearn: 0.0002264\ttotal: 3.45s\tremaining: 7.76s\n",
            "308:\tlearn: 0.0002207\ttotal: 3.46s\tremaining: 7.74s\n",
            "309:\tlearn: 0.0002152\ttotal: 3.47s\tremaining: 7.72s\n",
            "310:\tlearn: 0.0002098\ttotal: 3.48s\tremaining: 7.7s\n",
            "311:\tlearn: 0.0002045\ttotal: 3.48s\tremaining: 7.68s\n",
            "312:\tlearn: 0.0001994\ttotal: 3.5s\tremaining: 7.67s\n",
            "313:\tlearn: 0.0001944\ttotal: 3.51s\tremaining: 7.66s\n",
            "314:\tlearn: 0.0001895\ttotal: 3.51s\tremaining: 7.64s\n",
            "315:\tlearn: 0.0001847\ttotal: 3.52s\tremaining: 7.62s\n",
            "316:\tlearn: 0.0001801\ttotal: 3.53s\tremaining: 7.61s\n",
            "317:\tlearn: 0.0001756\ttotal: 3.54s\tremaining: 7.59s\n",
            "318:\tlearn: 0.0001712\ttotal: 3.54s\tremaining: 7.57s\n",
            "319:\tlearn: 0.0001669\ttotal: 3.55s\tremaining: 7.55s\n",
            "320:\tlearn: 0.0001627\ttotal: 3.56s\tremaining: 7.53s\n",
            "321:\tlearn: 0.0001587\ttotal: 3.57s\tremaining: 7.51s\n",
            "322:\tlearn: 0.0001547\ttotal: 3.58s\tremaining: 7.5s\n",
            "323:\tlearn: 0.0001508\ttotal: 3.58s\tremaining: 7.48s\n",
            "324:\tlearn: 0.0001471\ttotal: 3.59s\tremaining: 7.46s\n",
            "325:\tlearn: 0.0001434\ttotal: 3.6s\tremaining: 7.44s\n",
            "326:\tlearn: 0.0001398\ttotal: 3.61s\tremaining: 7.42s\n",
            "327:\tlearn: 0.0001363\ttotal: 3.61s\tremaining: 7.41s\n",
            "328:\tlearn: 0.0001329\ttotal: 3.62s\tremaining: 7.39s\n",
            "329:\tlearn: 0.0001296\ttotal: 3.63s\tremaining: 7.37s\n",
            "330:\tlearn: 0.0001264\ttotal: 3.64s\tremaining: 7.36s\n",
            "331:\tlearn: 0.0001232\ttotal: 3.66s\tremaining: 7.36s\n",
            "332:\tlearn: 0.0001202\ttotal: 3.67s\tremaining: 7.34s\n",
            "333:\tlearn: 0.0001172\ttotal: 3.68s\tremaining: 7.33s\n",
            "334:\tlearn: 0.0001142\ttotal: 3.68s\tremaining: 7.31s\n",
            "335:\tlearn: 0.0001114\ttotal: 3.69s\tremaining: 7.3s\n",
            "336:\tlearn: 0.0001086\ttotal: 3.7s\tremaining: 7.29s\n",
            "337:\tlearn: 0.0001059\ttotal: 3.71s\tremaining: 7.27s\n",
            "338:\tlearn: 0.0001033\ttotal: 3.72s\tremaining: 7.25s\n",
            "339:\tlearn: 0.0001007\ttotal: 3.72s\tremaining: 7.23s\n",
            "340:\tlearn: 0.0000982\ttotal: 3.73s\tremaining: 7.21s\n",
            "341:\tlearn: 0.0000958\ttotal: 3.74s\tremaining: 7.19s\n",
            "342:\tlearn: 0.0000934\ttotal: 3.75s\tremaining: 7.18s\n",
            "343:\tlearn: 0.0000910\ttotal: 3.75s\tremaining: 7.16s\n",
            "344:\tlearn: 0.0000888\ttotal: 3.76s\tremaining: 7.14s\n",
            "345:\tlearn: 0.0000866\ttotal: 3.77s\tremaining: 7.12s\n",
            "346:\tlearn: 0.0000844\ttotal: 3.78s\tremaining: 7.11s\n",
            "347:\tlearn: 0.0000823\ttotal: 3.78s\tremaining: 7.09s\n",
            "348:\tlearn: 0.0000803\ttotal: 3.79s\tremaining: 7.07s\n",
            "349:\tlearn: 0.0000783\ttotal: 3.81s\tremaining: 7.07s\n",
            "350:\tlearn: 0.0000763\ttotal: 3.81s\tremaining: 7.05s\n",
            "351:\tlearn: 0.0000744\ttotal: 3.82s\tremaining: 7.04s\n",
            "352:\tlearn: 0.0000726\ttotal: 3.83s\tremaining: 7.02s\n",
            "353:\tlearn: 0.0000708\ttotal: 3.84s\tremaining: 7s\n",
            "354:\tlearn: 0.0000690\ttotal: 3.84s\tremaining: 6.98s\n",
            "355:\tlearn: 0.0000673\ttotal: 3.85s\tremaining: 6.97s\n",
            "356:\tlearn: 0.0000656\ttotal: 3.86s\tremaining: 6.95s\n",
            "357:\tlearn: 0.0000640\ttotal: 3.87s\tremaining: 6.93s\n",
            "358:\tlearn: 0.0000624\ttotal: 3.87s\tremaining: 6.92s\n",
            "359:\tlearn: 0.0000609\ttotal: 3.88s\tremaining: 6.9s\n",
            "360:\tlearn: 0.0000594\ttotal: 3.89s\tremaining: 6.88s\n",
            "361:\tlearn: 0.0000579\ttotal: 3.9s\tremaining: 6.87s\n",
            "362:\tlearn: 0.0000564\ttotal: 3.91s\tremaining: 6.86s\n",
            "363:\tlearn: 0.0000550\ttotal: 3.92s\tremaining: 6.84s\n",
            "364:\tlearn: 0.0000537\ttotal: 3.92s\tremaining: 6.82s\n",
            "365:\tlearn: 0.0000524\ttotal: 3.93s\tremaining: 6.81s\n",
            "366:\tlearn: 0.0000510\ttotal: 3.94s\tremaining: 6.79s\n",
            "367:\tlearn: 0.0000498\ttotal: 3.94s\tremaining: 6.77s\n",
            "368:\tlearn: 0.0000485\ttotal: 3.95s\tremaining: 6.76s\n",
            "369:\tlearn: 0.0000473\ttotal: 3.96s\tremaining: 6.74s\n",
            "370:\tlearn: 0.0000461\ttotal: 3.96s\tremaining: 6.72s\n",
            "371:\tlearn: 0.0000450\ttotal: 3.97s\tremaining: 6.71s\n",
            "372:\tlearn: 0.0000439\ttotal: 3.98s\tremaining: 6.69s\n",
            "373:\tlearn: 0.0000428\ttotal: 3.99s\tremaining: 6.67s\n",
            "374:\tlearn: 0.0000417\ttotal: 3.99s\tremaining: 6.66s\n",
            "375:\tlearn: 0.0000407\ttotal: 4s\tremaining: 6.64s\n",
            "376:\tlearn: 0.0000396\ttotal: 4.01s\tremaining: 6.62s\n",
            "377:\tlearn: 0.0000387\ttotal: 4.02s\tremaining: 6.61s\n",
            "378:\tlearn: 0.0000377\ttotal: 4.02s\tremaining: 6.59s\n",
            "379:\tlearn: 0.0000368\ttotal: 4.03s\tremaining: 6.58s\n",
            "380:\tlearn: 0.0000358\ttotal: 4.04s\tremaining: 6.56s\n",
            "381:\tlearn: 0.0000349\ttotal: 4.05s\tremaining: 6.55s\n",
            "382:\tlearn: 0.0000341\ttotal: 4.05s\tremaining: 6.53s\n",
            "383:\tlearn: 0.0000332\ttotal: 4.06s\tremaining: 6.52s\n",
            "384:\tlearn: 0.0000324\ttotal: 4.07s\tremaining: 6.5s\n",
            "385:\tlearn: 0.0000316\ttotal: 4.08s\tremaining: 6.48s\n",
            "386:\tlearn: 0.0000308\ttotal: 4.08s\tremaining: 6.47s\n",
            "387:\tlearn: 0.0000300\ttotal: 4.09s\tremaining: 6.45s\n",
            "388:\tlearn: 0.0000293\ttotal: 4.1s\tremaining: 6.43s\n",
            "389:\tlearn: 0.0000286\ttotal: 4.11s\tremaining: 6.43s\n",
            "390:\tlearn: 0.0000279\ttotal: 4.12s\tremaining: 6.41s\n",
            "391:\tlearn: 0.0000272\ttotal: 4.12s\tremaining: 6.4s\n",
            "392:\tlearn: 0.0000265\ttotal: 4.13s\tremaining: 6.38s\n",
            "393:\tlearn: 0.0000258\ttotal: 4.14s\tremaining: 6.36s\n",
            "394:\tlearn: 0.0000252\ttotal: 4.14s\tremaining: 6.35s\n",
            "395:\tlearn: 0.0000245\ttotal: 4.15s\tremaining: 6.33s\n",
            "396:\tlearn: 0.0000239\ttotal: 4.16s\tremaining: 6.32s\n",
            "397:\tlearn: 0.0000233\ttotal: 4.17s\tremaining: 6.3s\n",
            "398:\tlearn: 0.0000227\ttotal: 4.17s\tremaining: 6.29s\n",
            "399:\tlearn: 0.0000222\ttotal: 4.18s\tremaining: 6.28s\n",
            "400:\tlearn: 0.0000216\ttotal: 4.2s\tremaining: 6.27s\n",
            "401:\tlearn: 0.0000211\ttotal: 4.2s\tremaining: 6.25s\n",
            "402:\tlearn: 0.0000205\ttotal: 4.21s\tremaining: 6.24s\n",
            "403:\tlearn: 0.0000200\ttotal: 4.22s\tremaining: 6.22s\n",
            "404:\tlearn: 0.0000195\ttotal: 4.22s\tremaining: 6.21s\n",
            "405:\tlearn: 0.0000190\ttotal: 4.23s\tremaining: 6.19s\n",
            "406:\tlearn: 0.0000185\ttotal: 4.24s\tremaining: 6.18s\n",
            "407:\tlearn: 0.0000181\ttotal: 4.25s\tremaining: 6.16s\n",
            "408:\tlearn: 0.0000176\ttotal: 4.25s\tremaining: 6.15s\n",
            "409:\tlearn: 0.0000172\ttotal: 4.26s\tremaining: 6.13s\n",
            "410:\tlearn: 0.0000167\ttotal: 4.27s\tremaining: 6.12s\n",
            "411:\tlearn: 0.0000163\ttotal: 4.28s\tremaining: 6.1s\n",
            "412:\tlearn: 0.0000159\ttotal: 4.28s\tremaining: 6.09s\n",
            "413:\tlearn: 0.0000155\ttotal: 4.29s\tremaining: 6.07s\n",
            "414:\tlearn: 0.0000151\ttotal: 4.3s\tremaining: 6.06s\n",
            "415:\tlearn: 0.0000147\ttotal: 4.31s\tremaining: 6.05s\n",
            "416:\tlearn: 0.0000144\ttotal: 4.32s\tremaining: 6.04s\n",
            "417:\tlearn: 0.0000140\ttotal: 4.33s\tremaining: 6.03s\n",
            "418:\tlearn: 0.0000137\ttotal: 4.34s\tremaining: 6.02s\n",
            "419:\tlearn: 0.0000133\ttotal: 4.35s\tremaining: 6s\n",
            "420:\tlearn: 0.0000130\ttotal: 4.35s\tremaining: 5.99s\n",
            "421:\tlearn: 0.0000127\ttotal: 4.36s\tremaining: 5.97s\n",
            "422:\tlearn: 0.0000123\ttotal: 4.37s\tremaining: 5.96s\n",
            "423:\tlearn: 0.0000120\ttotal: 4.38s\tremaining: 5.95s\n",
            "424:\tlearn: 0.0000117\ttotal: 4.38s\tremaining: 5.93s\n",
            "425:\tlearn: 0.0000114\ttotal: 4.39s\tremaining: 5.92s\n",
            "426:\tlearn: 0.0000111\ttotal: 4.4s\tremaining: 5.91s\n",
            "427:\tlearn: 0.0000109\ttotal: 4.41s\tremaining: 5.89s\n",
            "428:\tlearn: 0.0000106\ttotal: 4.42s\tremaining: 5.88s\n",
            "429:\tlearn: 0.0000103\ttotal: 4.42s\tremaining: 5.86s\n",
            "430:\tlearn: 0.0000101\ttotal: 4.43s\tremaining: 5.85s\n",
            "431:\tlearn: 0.0000098\ttotal: 4.44s\tremaining: 5.84s\n",
            "432:\tlearn: 0.0000096\ttotal: 4.45s\tremaining: 5.82s\n",
            "433:\tlearn: 0.0000093\ttotal: 4.45s\tremaining: 5.81s\n",
            "434:\tlearn: 0.0000091\ttotal: 4.46s\tremaining: 5.79s\n",
            "435:\tlearn: 0.0000089\ttotal: 4.47s\tremaining: 5.78s\n",
            "436:\tlearn: 0.0000086\ttotal: 4.48s\tremaining: 5.77s\n",
            "437:\tlearn: 0.0000084\ttotal: 4.48s\tremaining: 5.75s\n",
            "438:\tlearn: 0.0000082\ttotal: 4.49s\tremaining: 5.74s\n",
            "439:\tlearn: 0.0000080\ttotal: 4.5s\tremaining: 5.73s\n",
            "440:\tlearn: 0.0000078\ttotal: 4.51s\tremaining: 5.71s\n",
            "441:\tlearn: 0.0000076\ttotal: 4.52s\tremaining: 5.71s\n",
            "442:\tlearn: 0.0000074\ttotal: 4.53s\tremaining: 5.69s\n",
            "443:\tlearn: 0.0000072\ttotal: 4.53s\tremaining: 5.68s\n",
            "444:\tlearn: 0.0000071\ttotal: 4.54s\tremaining: 5.66s\n",
            "445:\tlearn: 0.0000069\ttotal: 4.55s\tremaining: 5.65s\n",
            "446:\tlearn: 0.0000067\ttotal: 4.56s\tremaining: 5.64s\n",
            "447:\tlearn: 0.0000065\ttotal: 4.56s\tremaining: 5.62s\n",
            "448:\tlearn: 0.0000064\ttotal: 4.57s\tremaining: 5.61s\n",
            "449:\tlearn: 0.0000062\ttotal: 4.58s\tremaining: 5.6s\n",
            "450:\tlearn: 0.0000061\ttotal: 4.59s\tremaining: 5.58s\n",
            "451:\tlearn: 0.0000059\ttotal: 4.6s\tremaining: 5.57s\n",
            "452:\tlearn: 0.0000058\ttotal: 4.61s\tremaining: 5.56s\n",
            "453:\tlearn: 0.0000056\ttotal: 4.61s\tremaining: 5.55s\n",
            "454:\tlearn: 0.0000055\ttotal: 4.62s\tremaining: 5.53s\n",
            "455:\tlearn: 0.0000053\ttotal: 4.63s\tremaining: 5.52s\n",
            "456:\tlearn: 0.0000052\ttotal: 4.63s\tremaining: 5.51s\n",
            "457:\tlearn: 0.0000051\ttotal: 4.64s\tremaining: 5.49s\n",
            "458:\tlearn: 0.0000049\ttotal: 4.65s\tremaining: 5.48s\n",
            "459:\tlearn: 0.0000048\ttotal: 4.66s\tremaining: 5.47s\n",
            "460:\tlearn: 0.0000047\ttotal: 4.66s\tremaining: 5.45s\n",
            "461:\tlearn: 0.0000046\ttotal: 4.67s\tremaining: 5.44s\n",
            "462:\tlearn: 0.0000045\ttotal: 4.68s\tremaining: 5.43s\n",
            "463:\tlearn: 0.0000044\ttotal: 4.69s\tremaining: 5.42s\n",
            "464:\tlearn: 0.0000042\ttotal: 4.7s\tremaining: 5.4s\n",
            "465:\tlearn: 0.0000041\ttotal: 4.7s\tremaining: 5.39s\n",
            "466:\tlearn: 0.0000040\ttotal: 4.71s\tremaining: 5.38s\n",
            "467:\tlearn: 0.0000039\ttotal: 4.72s\tremaining: 5.37s\n",
            "468:\tlearn: 0.0000038\ttotal: 4.73s\tremaining: 5.35s\n",
            "469:\tlearn: 0.0000037\ttotal: 4.74s\tremaining: 5.34s\n",
            "470:\tlearn: 0.0000036\ttotal: 4.74s\tremaining: 5.33s\n",
            "471:\tlearn: 0.0000036\ttotal: 4.75s\tremaining: 5.31s\n",
            "472:\tlearn: 0.0000035\ttotal: 4.76s\tremaining: 5.3s\n",
            "473:\tlearn: 0.0000034\ttotal: 4.76s\tremaining: 5.29s\n",
            "474:\tlearn: 0.0000033\ttotal: 4.77s\tremaining: 5.27s\n",
            "475:\tlearn: 0.0000032\ttotal: 4.78s\tremaining: 5.26s\n",
            "476:\tlearn: 0.0000031\ttotal: 4.79s\tremaining: 5.25s\n",
            "477:\tlearn: 0.0000031\ttotal: 4.79s\tremaining: 5.23s\n",
            "478:\tlearn: 0.0000030\ttotal: 4.8s\tremaining: 5.22s\n",
            "479:\tlearn: 0.0000029\ttotal: 4.81s\tremaining: 5.21s\n",
            "480:\tlearn: 0.0000028\ttotal: 4.82s\tremaining: 5.2s\n",
            "481:\tlearn: 0.0000028\ttotal: 4.82s\tremaining: 5.18s\n",
            "482:\tlearn: 0.0000027\ttotal: 4.83s\tremaining: 5.17s\n",
            "483:\tlearn: 0.0000026\ttotal: 4.84s\tremaining: 5.16s\n",
            "484:\tlearn: 0.0000026\ttotal: 4.85s\tremaining: 5.15s\n",
            "485:\tlearn: 0.0000025\ttotal: 4.85s\tremaining: 5.13s\n",
            "486:\tlearn: 0.0000024\ttotal: 4.86s\tremaining: 5.12s\n",
            "487:\tlearn: 0.0000024\ttotal: 4.87s\tremaining: 5.11s\n",
            "488:\tlearn: 0.0000023\ttotal: 4.88s\tremaining: 5.1s\n",
            "489:\tlearn: 0.0000023\ttotal: 4.89s\tremaining: 5.09s\n",
            "490:\tlearn: 0.0000022\ttotal: 4.89s\tremaining: 5.07s\n",
            "491:\tlearn: 0.0000021\ttotal: 4.9s\tremaining: 5.06s\n",
            "492:\tlearn: 0.0000021\ttotal: 4.91s\tremaining: 5.05s\n",
            "493:\tlearn: 0.0000020\ttotal: 4.92s\tremaining: 5.04s\n",
            "494:\tlearn: 0.0000020\ttotal: 4.93s\tremaining: 5.03s\n",
            "495:\tlearn: 0.0000019\ttotal: 4.93s\tremaining: 5.01s\n",
            "496:\tlearn: 0.0000019\ttotal: 4.94s\tremaining: 5s\n",
            "497:\tlearn: 0.0000018\ttotal: 4.95s\tremaining: 4.99s\n",
            "498:\tlearn: 0.0000018\ttotal: 4.96s\tremaining: 4.97s\n",
            "499:\tlearn: 0.0000018\ttotal: 4.96s\tremaining: 4.96s\n",
            "500:\tlearn: 0.0000017\ttotal: 4.97s\tremaining: 4.95s\n",
            "501:\tlearn: 0.0000017\ttotal: 4.98s\tremaining: 4.94s\n",
            "502:\tlearn: 0.0000016\ttotal: 4.98s\tremaining: 4.92s\n",
            "503:\tlearn: 0.0000016\ttotal: 4.99s\tremaining: 4.91s\n",
            "504:\tlearn: 0.0000015\ttotal: 5s\tremaining: 4.9s\n",
            "505:\tlearn: 0.0000015\ttotal: 5.01s\tremaining: 4.89s\n",
            "506:\tlearn: 0.0000015\ttotal: 5.01s\tremaining: 4.88s\n",
            "507:\tlearn: 0.0000014\ttotal: 5.02s\tremaining: 4.86s\n",
            "508:\tlearn: 0.0000014\ttotal: 5.03s\tremaining: 4.85s\n",
            "509:\tlearn: 0.0000014\ttotal: 5.04s\tremaining: 4.84s\n",
            "510:\tlearn: 0.0000013\ttotal: 5.04s\tremaining: 4.83s\n",
            "511:\tlearn: 0.0000013\ttotal: 5.05s\tremaining: 4.81s\n",
            "512:\tlearn: 0.0000013\ttotal: 5.06s\tremaining: 4.8s\n",
            "513:\tlearn: 0.0000012\ttotal: 5.07s\tremaining: 4.79s\n",
            "514:\tlearn: 0.0000012\ttotal: 5.07s\tremaining: 4.78s\n",
            "515:\tlearn: 0.0000012\ttotal: 5.08s\tremaining: 4.76s\n",
            "516:\tlearn: 0.0000011\ttotal: 5.09s\tremaining: 4.75s\n",
            "517:\tlearn: 0.0000011\ttotal: 5.09s\tremaining: 4.74s\n",
            "518:\tlearn: 0.0000011\ttotal: 5.1s\tremaining: 4.73s\n",
            "519:\tlearn: 0.0000011\ttotal: 5.11s\tremaining: 4.72s\n",
            "520:\tlearn: 0.0000010\ttotal: 5.12s\tremaining: 4.71s\n",
            "521:\tlearn: 0.0000010\ttotal: 5.14s\tremaining: 4.71s\n",
            "522:\tlearn: 0.0000010\ttotal: 5.15s\tremaining: 4.69s\n",
            "523:\tlearn: 0.0000010\ttotal: 5.15s\tremaining: 4.68s\n",
            "524:\tlearn: 0.0000009\ttotal: 5.16s\tremaining: 4.67s\n",
            "525:\tlearn: 0.0000009\ttotal: 5.17s\tremaining: 4.66s\n",
            "526:\tlearn: 0.0000009\ttotal: 5.18s\tremaining: 4.65s\n",
            "527:\tlearn: 0.0000009\ttotal: 5.19s\tremaining: 4.64s\n",
            "528:\tlearn: 0.0000008\ttotal: 5.2s\tremaining: 4.63s\n",
            "529:\tlearn: 0.0000008\ttotal: 5.21s\tremaining: 4.62s\n",
            "530:\tlearn: 0.0000008\ttotal: 5.21s\tremaining: 4.6s\n",
            "531:\tlearn: 0.0000008\ttotal: 5.22s\tremaining: 4.59s\n",
            "532:\tlearn: 0.0000008\ttotal: 5.23s\tremaining: 4.58s\n",
            "533:\tlearn: 0.0000007\ttotal: 5.23s\tremaining: 4.57s\n",
            "534:\tlearn: 0.0000007\ttotal: 5.24s\tremaining: 4.55s\n",
            "535:\tlearn: 0.0000007\ttotal: 5.25s\tremaining: 4.54s\n",
            "536:\tlearn: 0.0000007\ttotal: 5.25s\tremaining: 4.53s\n",
            "537:\tlearn: 0.0000007\ttotal: 5.26s\tremaining: 4.52s\n",
            "538:\tlearn: 0.0000007\ttotal: 5.27s\tremaining: 4.51s\n",
            "539:\tlearn: 0.0000006\ttotal: 5.28s\tremaining: 4.5s\n",
            "540:\tlearn: 0.0000006\ttotal: 5.29s\tremaining: 4.48s\n",
            "541:\tlearn: 0.0000006\ttotal: 5.29s\tremaining: 4.47s\n",
            "542:\tlearn: 0.0000006\ttotal: 5.3s\tremaining: 4.46s\n",
            "543:\tlearn: 0.0000006\ttotal: 5.31s\tremaining: 4.45s\n",
            "544:\tlearn: 0.0000006\ttotal: 5.32s\tremaining: 4.44s\n",
            "545:\tlearn: 0.0000005\ttotal: 5.32s\tremaining: 4.43s\n",
            "546:\tlearn: 0.0000005\ttotal: 5.33s\tremaining: 4.41s\n",
            "547:\tlearn: 0.0000005\ttotal: 5.34s\tremaining: 4.41s\n",
            "548:\tlearn: 0.0000005\ttotal: 5.35s\tremaining: 4.39s\n",
            "549:\tlearn: 0.0000005\ttotal: 5.36s\tremaining: 4.38s\n",
            "550:\tlearn: 0.0000005\ttotal: 5.36s\tremaining: 4.37s\n",
            "551:\tlearn: 0.0000005\ttotal: 5.37s\tremaining: 4.36s\n",
            "552:\tlearn: 0.0000005\ttotal: 5.38s\tremaining: 4.35s\n",
            "553:\tlearn: 0.0000004\ttotal: 5.39s\tremaining: 4.34s\n",
            "554:\tlearn: 0.0000004\ttotal: 5.39s\tremaining: 4.33s\n",
            "555:\tlearn: 0.0000004\ttotal: 5.4s\tremaining: 4.31s\n",
            "556:\tlearn: 0.0000004\ttotal: 5.41s\tremaining: 4.3s\n",
            "557:\tlearn: 0.0000004\ttotal: 5.42s\tremaining: 4.29s\n",
            "558:\tlearn: 0.0000004\ttotal: 5.42s\tremaining: 4.28s\n",
            "559:\tlearn: 0.0000004\ttotal: 5.43s\tremaining: 4.27s\n",
            "560:\tlearn: 0.0000004\ttotal: 5.44s\tremaining: 4.26s\n",
            "561:\tlearn: 0.0000004\ttotal: 5.45s\tremaining: 4.25s\n",
            "562:\tlearn: 0.0000004\ttotal: 5.45s\tremaining: 4.23s\n",
            "563:\tlearn: 0.0000003\ttotal: 5.46s\tremaining: 4.22s\n",
            "564:\tlearn: 0.0000003\ttotal: 5.47s\tremaining: 4.21s\n",
            "565:\tlearn: 0.0000003\ttotal: 5.48s\tremaining: 4.2s\n",
            "566:\tlearn: 0.0000003\ttotal: 5.48s\tremaining: 4.19s\n",
            "567:\tlearn: 0.0000003\ttotal: 5.49s\tremaining: 4.18s\n",
            "568:\tlearn: 0.0000003\ttotal: 5.5s\tremaining: 4.17s\n",
            "569:\tlearn: 0.0000003\ttotal: 5.51s\tremaining: 4.15s\n",
            "570:\tlearn: 0.0000003\ttotal: 5.51s\tremaining: 4.14s\n",
            "571:\tlearn: 0.0000003\ttotal: 5.52s\tremaining: 4.13s\n",
            "572:\tlearn: 0.0000003\ttotal: 5.53s\tremaining: 4.12s\n",
            "573:\tlearn: 0.0000003\ttotal: 5.54s\tremaining: 4.11s\n",
            "574:\tlearn: 0.0000003\ttotal: 5.55s\tremaining: 4.1s\n",
            "575:\tlearn: 0.0000003\ttotal: 5.55s\tremaining: 4.09s\n",
            "576:\tlearn: 0.0000003\ttotal: 5.56s\tremaining: 4.08s\n",
            "577:\tlearn: 0.0000002\ttotal: 5.57s\tremaining: 4.07s\n",
            "578:\tlearn: 0.0000002\ttotal: 5.58s\tremaining: 4.05s\n",
            "579:\tlearn: 0.0000002\ttotal: 5.58s\tremaining: 4.04s\n",
            "580:\tlearn: 0.0000002\ttotal: 5.59s\tremaining: 4.03s\n",
            "581:\tlearn: 0.0000002\ttotal: 5.6s\tremaining: 4.02s\n",
            "582:\tlearn: 0.0000002\ttotal: 5.61s\tremaining: 4.01s\n",
            "583:\tlearn: 0.0000002\ttotal: 5.61s\tremaining: 4s\n",
            "584:\tlearn: 0.0000002\ttotal: 5.62s\tremaining: 3.99s\n",
            "585:\tlearn: 0.0000002\ttotal: 5.63s\tremaining: 3.98s\n",
            "586:\tlearn: 0.0000002\ttotal: 5.64s\tremaining: 3.96s\n",
            "587:\tlearn: 0.0000002\ttotal: 5.64s\tremaining: 3.95s\n",
            "588:\tlearn: 0.0000002\ttotal: 5.65s\tremaining: 3.94s\n",
            "589:\tlearn: 0.0000002\ttotal: 5.66s\tremaining: 3.93s\n",
            "590:\tlearn: 0.0000002\ttotal: 5.67s\tremaining: 3.92s\n",
            "591:\tlearn: 0.0000002\ttotal: 5.68s\tremaining: 3.91s\n",
            "592:\tlearn: 0.0000002\ttotal: 5.68s\tremaining: 3.9s\n",
            "593:\tlearn: 0.0000002\ttotal: 5.69s\tremaining: 3.89s\n",
            "594:\tlearn: 0.0000002\ttotal: 5.7s\tremaining: 3.88s\n",
            "595:\tlearn: 0.0000002\ttotal: 5.7s\tremaining: 3.87s\n",
            "596:\tlearn: 0.0000002\ttotal: 5.71s\tremaining: 3.85s\n",
            "597:\tlearn: 0.0000001\ttotal: 5.72s\tremaining: 3.84s\n",
            "598:\tlearn: 0.0000001\ttotal: 5.73s\tremaining: 3.83s\n",
            "599:\tlearn: 0.0000001\ttotal: 5.73s\tremaining: 3.82s\n",
            "600:\tlearn: 0.0000001\ttotal: 5.74s\tremaining: 3.81s\n",
            "601:\tlearn: 0.0000001\ttotal: 5.75s\tremaining: 3.8s\n",
            "602:\tlearn: 0.0000001\ttotal: 5.76s\tremaining: 3.79s\n",
            "603:\tlearn: 0.0000001\ttotal: 5.77s\tremaining: 3.78s\n",
            "604:\tlearn: 0.0000001\ttotal: 5.77s\tremaining: 3.77s\n",
            "605:\tlearn: 0.0000001\ttotal: 5.78s\tremaining: 3.76s\n",
            "606:\tlearn: 0.0000001\ttotal: 5.79s\tremaining: 3.75s\n",
            "607:\tlearn: 0.0000001\ttotal: 5.8s\tremaining: 3.74s\n",
            "608:\tlearn: 0.0000001\ttotal: 5.8s\tremaining: 3.73s\n",
            "609:\tlearn: 0.0000001\ttotal: 5.81s\tremaining: 3.71s\n",
            "610:\tlearn: 0.0000001\ttotal: 5.82s\tremaining: 3.7s\n",
            "611:\tlearn: 0.0000001\ttotal: 5.82s\tremaining: 3.69s\n",
            "612:\tlearn: 0.0000001\ttotal: 5.83s\tremaining: 3.68s\n",
            "613:\tlearn: 0.0000001\ttotal: 5.84s\tremaining: 3.67s\n",
            "614:\tlearn: 0.0000001\ttotal: 5.84s\tremaining: 3.66s\n",
            "615:\tlearn: 0.0000001\ttotal: 5.85s\tremaining: 3.65s\n",
            "616:\tlearn: 0.0000001\ttotal: 5.86s\tremaining: 3.64s\n",
            "617:\tlearn: 0.0000001\ttotal: 5.87s\tremaining: 3.63s\n",
            "618:\tlearn: 0.0000001\ttotal: 5.87s\tremaining: 3.61s\n",
            "619:\tlearn: 0.0000001\ttotal: 5.88s\tremaining: 3.6s\n",
            "620:\tlearn: 0.0000001\ttotal: 5.88s\tremaining: 3.59s\n",
            "621:\tlearn: 0.0000001\ttotal: 5.89s\tremaining: 3.58s\n",
            "622:\tlearn: 0.0000001\ttotal: 5.9s\tremaining: 3.57s\n",
            "623:\tlearn: 0.0000001\ttotal: 5.91s\tremaining: 3.56s\n",
            "624:\tlearn: 0.0000001\ttotal: 5.92s\tremaining: 3.55s\n",
            "625:\tlearn: 0.0000001\ttotal: 5.92s\tremaining: 3.54s\n",
            "626:\tlearn: 0.0000001\ttotal: 5.93s\tremaining: 3.53s\n",
            "627:\tlearn: 0.0000001\ttotal: 5.93s\tremaining: 3.52s\n",
            "628:\tlearn: 0.0000001\ttotal: 5.94s\tremaining: 3.5s\n",
            "629:\tlearn: 0.0000001\ttotal: 5.95s\tremaining: 3.5s\n",
            "630:\tlearn: 0.0000001\ttotal: 5.96s\tremaining: 3.49s\n",
            "631:\tlearn: 0.0000001\ttotal: 5.97s\tremaining: 3.48s\n",
            "632:\tlearn: 0.0000001\ttotal: 5.97s\tremaining: 3.46s\n",
            "633:\tlearn: 0.0000001\ttotal: 5.98s\tremaining: 3.45s\n",
            "634:\tlearn: 0.0000001\ttotal: 5.99s\tremaining: 3.44s\n",
            "635:\tlearn: 0.0000001\ttotal: 6s\tremaining: 3.43s\n",
            "636:\tlearn: 0.0000001\ttotal: 6s\tremaining: 3.42s\n",
            "637:\tlearn: 0.0000001\ttotal: 6.01s\tremaining: 3.41s\n",
            "638:\tlearn: 0.0000001\ttotal: 6.02s\tremaining: 3.4s\n",
            "639:\tlearn: 0.0000001\ttotal: 6.02s\tremaining: 3.39s\n",
            "640:\tlearn: 0.0000000\ttotal: 6.03s\tremaining: 3.38s\n",
            "641:\tlearn: 0.0000000\ttotal: 6.04s\tremaining: 3.37s\n",
            "642:\tlearn: 0.0000000\ttotal: 6.04s\tremaining: 3.36s\n",
            "643:\tlearn: 0.0000000\ttotal: 6.05s\tremaining: 3.35s\n",
            "644:\tlearn: 0.0000000\ttotal: 6.06s\tremaining: 3.34s\n",
            "645:\tlearn: 0.0000000\ttotal: 6.07s\tremaining: 3.33s\n",
            "646:\tlearn: 0.0000000\ttotal: 6.08s\tremaining: 3.31s\n",
            "647:\tlearn: 0.0000000\ttotal: 6.08s\tremaining: 3.31s\n",
            "648:\tlearn: 0.0000000\ttotal: 6.09s\tremaining: 3.29s\n",
            "649:\tlearn: 0.0000000\ttotal: 6.1s\tremaining: 3.28s\n",
            "650:\tlearn: 0.0000000\ttotal: 6.11s\tremaining: 3.27s\n",
            "651:\tlearn: 0.0000000\ttotal: 6.11s\tremaining: 3.26s\n",
            "652:\tlearn: 0.0000000\ttotal: 6.12s\tremaining: 3.25s\n",
            "653:\tlearn: 0.0000000\ttotal: 6.13s\tremaining: 3.24s\n",
            "654:\tlearn: 0.0000000\ttotal: 6.13s\tremaining: 3.23s\n",
            "655:\tlearn: 0.0000000\ttotal: 6.14s\tremaining: 3.22s\n",
            "656:\tlearn: 0.0000000\ttotal: 6.15s\tremaining: 3.21s\n",
            "657:\tlearn: 0.0000000\ttotal: 6.16s\tremaining: 3.2s\n",
            "658:\tlearn: 0.0000000\ttotal: 6.17s\tremaining: 3.19s\n",
            "659:\tlearn: 0.0000000\ttotal: 6.18s\tremaining: 3.19s\n",
            "660:\tlearn: 0.0000000\ttotal: 6.2s\tremaining: 3.18s\n",
            "661:\tlearn: 0.0000000\ttotal: 6.21s\tremaining: 3.17s\n",
            "662:\tlearn: 0.0000000\ttotal: 6.21s\tremaining: 3.16s\n",
            "663:\tlearn: 0.0000000\ttotal: 6.22s\tremaining: 3.15s\n",
            "664:\tlearn: 0.0000000\ttotal: 6.23s\tremaining: 3.14s\n",
            "665:\tlearn: 0.0000000\ttotal: 6.23s\tremaining: 3.13s\n",
            "666:\tlearn: 0.0000000\ttotal: 6.24s\tremaining: 3.12s\n",
            "667:\tlearn: 0.0000000\ttotal: 6.25s\tremaining: 3.1s\n",
            "668:\tlearn: 0.0000000\ttotal: 6.25s\tremaining: 3.09s\n",
            "669:\tlearn: 0.0000000\ttotal: 6.26s\tremaining: 3.08s\n",
            "670:\tlearn: 0.0000000\ttotal: 6.27s\tremaining: 3.07s\n",
            "671:\tlearn: 0.0000000\ttotal: 6.28s\tremaining: 3.06s\n",
            "672:\tlearn: 0.0000000\ttotal: 6.28s\tremaining: 3.05s\n",
            "673:\tlearn: 0.0000000\ttotal: 6.29s\tremaining: 3.04s\n",
            "674:\tlearn: 0.0000000\ttotal: 6.3s\tremaining: 3.03s\n",
            "675:\tlearn: 0.0000000\ttotal: 6.3s\tremaining: 3.02s\n",
            "676:\tlearn: 0.0000000\ttotal: 6.31s\tremaining: 3.01s\n",
            "677:\tlearn: 0.0000000\ttotal: 6.32s\tremaining: 3s\n",
            "678:\tlearn: 0.0000000\ttotal: 6.33s\tremaining: 2.99s\n",
            "679:\tlearn: 0.0000000\ttotal: 6.33s\tremaining: 2.98s\n",
            "680:\tlearn: 0.0000000\ttotal: 6.34s\tremaining: 2.97s\n",
            "681:\tlearn: 0.0000000\ttotal: 6.35s\tremaining: 2.96s\n",
            "682:\tlearn: 0.0000000\ttotal: 6.35s\tremaining: 2.95s\n",
            "683:\tlearn: 0.0000000\ttotal: 6.36s\tremaining: 2.94s\n",
            "684:\tlearn: 0.0000000\ttotal: 6.37s\tremaining: 2.93s\n",
            "685:\tlearn: 0.0000000\ttotal: 6.38s\tremaining: 2.92s\n",
            "686:\tlearn: 0.0000000\ttotal: 6.38s\tremaining: 2.91s\n",
            "687:\tlearn: 0.0000000\ttotal: 6.39s\tremaining: 2.9s\n",
            "688:\tlearn: 0.0000000\ttotal: 6.4s\tremaining: 2.89s\n",
            "689:\tlearn: 0.0000000\ttotal: 6.41s\tremaining: 2.88s\n",
            "690:\tlearn: 0.0000000\ttotal: 6.41s\tremaining: 2.87s\n",
            "691:\tlearn: 0.0000000\ttotal: 6.42s\tremaining: 2.86s\n",
            "692:\tlearn: 0.0000000\ttotal: 6.43s\tremaining: 2.85s\n",
            "693:\tlearn: 0.0000000\ttotal: 6.43s\tremaining: 2.84s\n",
            "694:\tlearn: 0.0000000\ttotal: 6.44s\tremaining: 2.83s\n",
            "695:\tlearn: 0.0000000\ttotal: 6.45s\tremaining: 2.82s\n",
            "696:\tlearn: 0.0000000\ttotal: 6.46s\tremaining: 2.81s\n",
            "697:\tlearn: 0.0000000\ttotal: 6.46s\tremaining: 2.8s\n",
            "698:\tlearn: 0.0000000\ttotal: 6.47s\tremaining: 2.79s\n",
            "699:\tlearn: 0.0000000\ttotal: 6.48s\tremaining: 2.78s\n",
            "700:\tlearn: 0.0000000\ttotal: 6.49s\tremaining: 2.77s\n",
            "701:\tlearn: 0.0000000\ttotal: 6.49s\tremaining: 2.76s\n",
            "702:\tlearn: 0.0000000\ttotal: 6.5s\tremaining: 2.75s\n",
            "703:\tlearn: 0.0000000\ttotal: 6.51s\tremaining: 2.74s\n",
            "704:\tlearn: 0.0000000\ttotal: 6.51s\tremaining: 2.73s\n",
            "705:\tlearn: 0.0000000\ttotal: 6.52s\tremaining: 2.71s\n",
            "706:\tlearn: 0.0000000\ttotal: 6.53s\tremaining: 2.71s\n",
            "707:\tlearn: 0.0000000\ttotal: 6.54s\tremaining: 2.69s\n",
            "708:\tlearn: 0.0000000\ttotal: 6.54s\tremaining: 2.69s\n",
            "709:\tlearn: 0.0000000\ttotal: 6.55s\tremaining: 2.67s\n",
            "710:\tlearn: 0.0000000\ttotal: 6.56s\tremaining: 2.67s\n",
            "711:\tlearn: 0.0000000\ttotal: 6.56s\tremaining: 2.65s\n",
            "712:\tlearn: 0.0000000\ttotal: 6.58s\tremaining: 2.65s\n",
            "713:\tlearn: 0.0000000\ttotal: 6.58s\tremaining: 2.64s\n",
            "714:\tlearn: 0.0000000\ttotal: 6.59s\tremaining: 2.63s\n",
            "715:\tlearn: 0.0000000\ttotal: 6.6s\tremaining: 2.62s\n",
            "716:\tlearn: 0.0000000\ttotal: 6.61s\tremaining: 2.61s\n",
            "717:\tlearn: 0.0000000\ttotal: 6.61s\tremaining: 2.6s\n",
            "718:\tlearn: 0.0000000\ttotal: 6.62s\tremaining: 2.59s\n",
            "719:\tlearn: 0.0000000\ttotal: 6.63s\tremaining: 2.58s\n",
            "720:\tlearn: 0.0000000\ttotal: 6.64s\tremaining: 2.57s\n",
            "721:\tlearn: 0.0000000\ttotal: 6.64s\tremaining: 2.56s\n",
            "722:\tlearn: 0.0000000\ttotal: 6.65s\tremaining: 2.55s\n",
            "723:\tlearn: 0.0000000\ttotal: 6.66s\tremaining: 2.54s\n",
            "724:\tlearn: 0.0000000\ttotal: 6.67s\tremaining: 2.53s\n",
            "725:\tlearn: 0.0000000\ttotal: 6.67s\tremaining: 2.52s\n",
            "726:\tlearn: 0.0000000\ttotal: 6.68s\tremaining: 2.51s\n",
            "727:\tlearn: 0.0000000\ttotal: 6.69s\tremaining: 2.5s\n",
            "728:\tlearn: 0.0000000\ttotal: 6.7s\tremaining: 2.49s\n",
            "729:\tlearn: 0.0000000\ttotal: 6.7s\tremaining: 2.48s\n",
            "730:\tlearn: 0.0000000\ttotal: 6.71s\tremaining: 2.47s\n",
            "731:\tlearn: 0.0000000\ttotal: 6.72s\tremaining: 2.46s\n",
            "732:\tlearn: 0.0000000\ttotal: 6.73s\tremaining: 2.45s\n",
            "733:\tlearn: 0.0000000\ttotal: 6.73s\tremaining: 2.44s\n",
            "734:\tlearn: 0.0000000\ttotal: 6.74s\tremaining: 2.43s\n",
            "735:\tlearn: 0.0000000\ttotal: 6.75s\tremaining: 2.42s\n",
            "736:\tlearn: 0.0000000\ttotal: 6.75s\tremaining: 2.41s\n",
            "737:\tlearn: 0.0000000\ttotal: 6.76s\tremaining: 2.4s\n",
            "738:\tlearn: 0.0000000\ttotal: 6.77s\tremaining: 2.39s\n",
            "739:\tlearn: 0.0000000\ttotal: 6.78s\tremaining: 2.38s\n",
            "740:\tlearn: 0.0000000\ttotal: 6.79s\tremaining: 2.37s\n",
            "741:\tlearn: 0.0000000\ttotal: 6.79s\tremaining: 2.36s\n",
            "742:\tlearn: 0.0000000\ttotal: 6.8s\tremaining: 2.35s\n",
            "743:\tlearn: 0.0000000\ttotal: 6.81s\tremaining: 2.34s\n",
            "744:\tlearn: 0.0000000\ttotal: 6.81s\tremaining: 2.33s\n",
            "745:\tlearn: 0.0000000\ttotal: 6.82s\tremaining: 2.32s\n",
            "746:\tlearn: 0.0000000\ttotal: 6.83s\tremaining: 2.31s\n",
            "747:\tlearn: 0.0000000\ttotal: 6.83s\tremaining: 2.3s\n",
            "748:\tlearn: 0.0000000\ttotal: 6.84s\tremaining: 2.29s\n",
            "749:\tlearn: 0.0000000\ttotal: 6.85s\tremaining: 2.28s\n",
            "750:\tlearn: 0.0000000\ttotal: 6.85s\tremaining: 2.27s\n",
            "751:\tlearn: 0.0000000\ttotal: 6.86s\tremaining: 2.26s\n",
            "752:\tlearn: 0.0000000\ttotal: 6.87s\tremaining: 2.25s\n",
            "753:\tlearn: 0.0000000\ttotal: 6.88s\tremaining: 2.24s\n",
            "754:\tlearn: 0.0000000\ttotal: 6.88s\tremaining: 2.23s\n",
            "755:\tlearn: 0.0000000\ttotal: 6.89s\tremaining: 2.22s\n",
            "756:\tlearn: 0.0000000\ttotal: 6.9s\tremaining: 2.21s\n",
            "757:\tlearn: 0.0000000\ttotal: 6.9s\tremaining: 2.2s\n",
            "758:\tlearn: 0.0000000\ttotal: 6.91s\tremaining: 2.19s\n",
            "759:\tlearn: 0.0000000\ttotal: 6.92s\tremaining: 2.18s\n",
            "760:\tlearn: 0.0000000\ttotal: 6.93s\tremaining: 2.17s\n",
            "761:\tlearn: 0.0000000\ttotal: 6.93s\tremaining: 2.17s\n",
            "762:\tlearn: 0.0000000\ttotal: 6.94s\tremaining: 2.16s\n",
            "763:\tlearn: 0.0000000\ttotal: 6.95s\tremaining: 2.15s\n",
            "764:\tlearn: 0.0000000\ttotal: 6.96s\tremaining: 2.14s\n",
            "765:\tlearn: 0.0000000\ttotal: 6.96s\tremaining: 2.13s\n",
            "766:\tlearn: 0.0000000\ttotal: 6.97s\tremaining: 2.12s\n",
            "767:\tlearn: 0.0000000\ttotal: 6.98s\tremaining: 2.11s\n",
            "768:\tlearn: 0.0000000\ttotal: 6.99s\tremaining: 2.1s\n",
            "769:\tlearn: 0.0000000\ttotal: 7s\tremaining: 2.09s\n",
            "770:\tlearn: 0.0000000\ttotal: 7s\tremaining: 2.08s\n",
            "771:\tlearn: 0.0000000\ttotal: 7.01s\tremaining: 2.07s\n",
            "772:\tlearn: 0.0000000\ttotal: 7.02s\tremaining: 2.06s\n",
            "773:\tlearn: 0.0000000\ttotal: 7.03s\tremaining: 2.05s\n",
            "774:\tlearn: 0.0000000\ttotal: 7.03s\tremaining: 2.04s\n",
            "775:\tlearn: 0.0000000\ttotal: 7.04s\tremaining: 2.03s\n",
            "776:\tlearn: 0.0000000\ttotal: 7.05s\tremaining: 2.02s\n",
            "777:\tlearn: 0.0000000\ttotal: 7.05s\tremaining: 2.01s\n",
            "778:\tlearn: 0.0000000\ttotal: 7.06s\tremaining: 2s\n",
            "779:\tlearn: 0.0000000\ttotal: 7.07s\tremaining: 1.99s\n",
            "780:\tlearn: 0.0000000\ttotal: 7.07s\tremaining: 1.98s\n",
            "781:\tlearn: 0.0000000\ttotal: 7.08s\tremaining: 1.97s\n",
            "782:\tlearn: 0.0000000\ttotal: 7.09s\tremaining: 1.96s\n",
            "783:\tlearn: 0.0000000\ttotal: 7.09s\tremaining: 1.95s\n",
            "784:\tlearn: 0.0000000\ttotal: 7.1s\tremaining: 1.95s\n",
            "785:\tlearn: 0.0000000\ttotal: 7.11s\tremaining: 1.94s\n",
            "786:\tlearn: 0.0000000\ttotal: 7.12s\tremaining: 1.93s\n",
            "787:\tlearn: 0.0000000\ttotal: 7.12s\tremaining: 1.92s\n",
            "788:\tlearn: 0.0000000\ttotal: 7.13s\tremaining: 1.91s\n",
            "789:\tlearn: 0.0000000\ttotal: 7.14s\tremaining: 1.9s\n",
            "790:\tlearn: 0.0000000\ttotal: 7.15s\tremaining: 1.89s\n",
            "791:\tlearn: 0.0000000\ttotal: 7.16s\tremaining: 1.88s\n",
            "792:\tlearn: 0.0000000\ttotal: 7.17s\tremaining: 1.87s\n",
            "793:\tlearn: 0.0000000\ttotal: 7.17s\tremaining: 1.86s\n",
            "794:\tlearn: 0.0000000\ttotal: 7.19s\tremaining: 1.85s\n",
            "795:\tlearn: 0.0000000\ttotal: 7.21s\tremaining: 1.85s\n",
            "796:\tlearn: 0.0000000\ttotal: 7.21s\tremaining: 1.84s\n",
            "797:\tlearn: 0.0000000\ttotal: 7.22s\tremaining: 1.83s\n",
            "798:\tlearn: 0.0000000\ttotal: 7.23s\tremaining: 1.82s\n",
            "799:\tlearn: 0.0000000\ttotal: 7.23s\tremaining: 1.81s\n",
            "800:\tlearn: 0.0000000\ttotal: 7.24s\tremaining: 1.8s\n",
            "801:\tlearn: 0.0000000\ttotal: 7.25s\tremaining: 1.79s\n",
            "802:\tlearn: 0.0000000\ttotal: 7.25s\tremaining: 1.78s\n",
            "803:\tlearn: 0.0000000\ttotal: 7.26s\tremaining: 1.77s\n",
            "804:\tlearn: 0.0000000\ttotal: 7.27s\tremaining: 1.76s\n",
            "805:\tlearn: 0.0000000\ttotal: 7.28s\tremaining: 1.75s\n",
            "806:\tlearn: 0.0000000\ttotal: 7.28s\tremaining: 1.74s\n",
            "807:\tlearn: 0.0000000\ttotal: 7.29s\tremaining: 1.73s\n",
            "808:\tlearn: 0.0000000\ttotal: 7.3s\tremaining: 1.72s\n",
            "809:\tlearn: 0.0000000\ttotal: 7.3s\tremaining: 1.71s\n",
            "810:\tlearn: 0.0000000\ttotal: 7.31s\tremaining: 1.7s\n",
            "811:\tlearn: 0.0000000\ttotal: 7.32s\tremaining: 1.69s\n",
            "812:\tlearn: 0.0000000\ttotal: 7.33s\tremaining: 1.69s\n",
            "813:\tlearn: 0.0000000\ttotal: 7.33s\tremaining: 1.68s\n",
            "814:\tlearn: 0.0000000\ttotal: 7.34s\tremaining: 1.67s\n",
            "815:\tlearn: 0.0000000\ttotal: 7.35s\tremaining: 1.66s\n",
            "816:\tlearn: 0.0000000\ttotal: 7.36s\tremaining: 1.65s\n",
            "817:\tlearn: 0.0000000\ttotal: 7.36s\tremaining: 1.64s\n",
            "818:\tlearn: 0.0000000\ttotal: 7.37s\tremaining: 1.63s\n",
            "819:\tlearn: 0.0000000\ttotal: 7.38s\tremaining: 1.62s\n",
            "820:\tlearn: 0.0000000\ttotal: 7.39s\tremaining: 1.61s\n",
            "821:\tlearn: 0.0000000\ttotal: 7.4s\tremaining: 1.6s\n",
            "822:\tlearn: 0.0000000\ttotal: 7.41s\tremaining: 1.59s\n",
            "823:\tlearn: 0.0000000\ttotal: 7.42s\tremaining: 1.58s\n",
            "824:\tlearn: 0.0000000\ttotal: 7.42s\tremaining: 1.57s\n",
            "825:\tlearn: 0.0000000\ttotal: 7.43s\tremaining: 1.56s\n",
            "826:\tlearn: 0.0000000\ttotal: 7.44s\tremaining: 1.55s\n",
            "827:\tlearn: 0.0000000\ttotal: 7.44s\tremaining: 1.55s\n",
            "828:\tlearn: 0.0000000\ttotal: 7.45s\tremaining: 1.54s\n",
            "829:\tlearn: 0.0000000\ttotal: 7.46s\tremaining: 1.53s\n",
            "830:\tlearn: 0.0000000\ttotal: 7.46s\tremaining: 1.52s\n",
            "831:\tlearn: 0.0000000\ttotal: 7.47s\tremaining: 1.51s\n",
            "832:\tlearn: 0.0000000\ttotal: 7.48s\tremaining: 1.5s\n",
            "833:\tlearn: 0.0000000\ttotal: 7.49s\tremaining: 1.49s\n",
            "834:\tlearn: 0.0000000\ttotal: 7.49s\tremaining: 1.48s\n",
            "835:\tlearn: 0.0000000\ttotal: 7.5s\tremaining: 1.47s\n",
            "836:\tlearn: 0.0000000\ttotal: 7.51s\tremaining: 1.46s\n",
            "837:\tlearn: 0.0000000\ttotal: 7.51s\tremaining: 1.45s\n",
            "838:\tlearn: 0.0000000\ttotal: 7.52s\tremaining: 1.44s\n",
            "839:\tlearn: 0.0000000\ttotal: 7.53s\tremaining: 1.43s\n",
            "840:\tlearn: 0.0000000\ttotal: 7.53s\tremaining: 1.42s\n",
            "841:\tlearn: 0.0000000\ttotal: 7.54s\tremaining: 1.42s\n",
            "842:\tlearn: 0.0000000\ttotal: 7.55s\tremaining: 1.41s\n",
            "843:\tlearn: 0.0000000\ttotal: 7.56s\tremaining: 1.4s\n",
            "844:\tlearn: 0.0000000\ttotal: 7.56s\tremaining: 1.39s\n",
            "845:\tlearn: 0.0000000\ttotal: 7.57s\tremaining: 1.38s\n",
            "846:\tlearn: 0.0000000\ttotal: 7.58s\tremaining: 1.37s\n",
            "847:\tlearn: 0.0000000\ttotal: 7.59s\tremaining: 1.36s\n",
            "848:\tlearn: 0.0000000\ttotal: 7.59s\tremaining: 1.35s\n",
            "849:\tlearn: 0.0000000\ttotal: 7.6s\tremaining: 1.34s\n",
            "850:\tlearn: 0.0000000\ttotal: 7.61s\tremaining: 1.33s\n",
            "851:\tlearn: 0.0000000\ttotal: 7.62s\tremaining: 1.32s\n",
            "852:\tlearn: 0.0000000\ttotal: 7.63s\tremaining: 1.31s\n",
            "853:\tlearn: 0.0000000\ttotal: 7.63s\tremaining: 1.3s\n",
            "854:\tlearn: 0.0000000\ttotal: 7.64s\tremaining: 1.29s\n",
            "855:\tlearn: 0.0000000\ttotal: 7.65s\tremaining: 1.29s\n",
            "856:\tlearn: 0.0000000\ttotal: 7.65s\tremaining: 1.28s\n",
            "857:\tlearn: 0.0000000\ttotal: 7.67s\tremaining: 1.27s\n",
            "858:\tlearn: 0.0000000\ttotal: 7.67s\tremaining: 1.26s\n",
            "859:\tlearn: 0.0000000\ttotal: 7.68s\tremaining: 1.25s\n",
            "860:\tlearn: 0.0000000\ttotal: 7.69s\tremaining: 1.24s\n",
            "861:\tlearn: 0.0000000\ttotal: 7.69s\tremaining: 1.23s\n",
            "862:\tlearn: 0.0000000\ttotal: 7.7s\tremaining: 1.22s\n",
            "863:\tlearn: 0.0000000\ttotal: 7.71s\tremaining: 1.21s\n",
            "864:\tlearn: 0.0000000\ttotal: 7.72s\tremaining: 1.2s\n",
            "865:\tlearn: 0.0000000\ttotal: 7.72s\tremaining: 1.2s\n",
            "866:\tlearn: 0.0000000\ttotal: 7.73s\tremaining: 1.19s\n",
            "867:\tlearn: 0.0000000\ttotal: 7.74s\tremaining: 1.18s\n",
            "868:\tlearn: 0.0000000\ttotal: 7.74s\tremaining: 1.17s\n",
            "869:\tlearn: 0.0000000\ttotal: 7.75s\tremaining: 1.16s\n",
            "870:\tlearn: 0.0000000\ttotal: 7.76s\tremaining: 1.15s\n",
            "871:\tlearn: 0.0000000\ttotal: 7.76s\tremaining: 1.14s\n",
            "872:\tlearn: 0.0000000\ttotal: 7.77s\tremaining: 1.13s\n",
            "873:\tlearn: 0.0000000\ttotal: 7.78s\tremaining: 1.12s\n",
            "874:\tlearn: 0.0000000\ttotal: 7.79s\tremaining: 1.11s\n",
            "875:\tlearn: 0.0000000\ttotal: 7.79s\tremaining: 1.1s\n",
            "876:\tlearn: 0.0000000\ttotal: 7.8s\tremaining: 1.09s\n",
            "877:\tlearn: 0.0000000\ttotal: 7.81s\tremaining: 1.08s\n",
            "878:\tlearn: 0.0000000\ttotal: 7.82s\tremaining: 1.08s\n",
            "879:\tlearn: 0.0000000\ttotal: 7.83s\tremaining: 1.07s\n",
            "880:\tlearn: 0.0000000\ttotal: 7.83s\tremaining: 1.06s\n",
            "881:\tlearn: 0.0000000\ttotal: 7.84s\tremaining: 1.05s\n",
            "882:\tlearn: 0.0000000\ttotal: 7.85s\tremaining: 1.04s\n",
            "883:\tlearn: 0.0000000\ttotal: 7.86s\tremaining: 1.03s\n",
            "884:\tlearn: 0.0000000\ttotal: 7.86s\tremaining: 1.02s\n",
            "885:\tlearn: 0.0000000\ttotal: 7.87s\tremaining: 1.01s\n",
            "886:\tlearn: 0.0000000\ttotal: 7.88s\tremaining: 1s\n",
            "887:\tlearn: 0.0000000\ttotal: 7.88s\tremaining: 994ms\n",
            "888:\tlearn: 0.0000000\ttotal: 7.89s\tremaining: 985ms\n",
            "889:\tlearn: 0.0000000\ttotal: 7.9s\tremaining: 976ms\n",
            "890:\tlearn: 0.0000000\ttotal: 7.91s\tremaining: 967ms\n",
            "891:\tlearn: 0.0000000\ttotal: 7.92s\tremaining: 958ms\n",
            "892:\tlearn: 0.0000000\ttotal: 7.92s\tremaining: 949ms\n",
            "893:\tlearn: 0.0000000\ttotal: 7.93s\tremaining: 940ms\n",
            "894:\tlearn: 0.0000000\ttotal: 7.93s\tremaining: 931ms\n",
            "895:\tlearn: 0.0000000\ttotal: 7.94s\tremaining: 922ms\n",
            "896:\tlearn: 0.0000000\ttotal: 7.95s\tremaining: 913ms\n",
            "897:\tlearn: 0.0000000\ttotal: 7.96s\tremaining: 904ms\n",
            "898:\tlearn: 0.0000000\ttotal: 7.96s\tremaining: 894ms\n",
            "899:\tlearn: 0.0000000\ttotal: 7.97s\tremaining: 885ms\n",
            "900:\tlearn: 0.0000000\ttotal: 7.97s\tremaining: 876ms\n",
            "901:\tlearn: 0.0000000\ttotal: 7.98s\tremaining: 867ms\n",
            "902:\tlearn: 0.0000000\ttotal: 7.99s\tremaining: 858ms\n",
            "903:\tlearn: 0.0000000\ttotal: 8s\tremaining: 849ms\n",
            "904:\tlearn: 0.0000000\ttotal: 8s\tremaining: 840ms\n",
            "905:\tlearn: 0.0000000\ttotal: 8.01s\tremaining: 831ms\n",
            "906:\tlearn: 0.0000000\ttotal: 8.02s\tremaining: 822ms\n",
            "907:\tlearn: 0.0000000\ttotal: 8.03s\tremaining: 813ms\n",
            "908:\tlearn: 0.0000000\ttotal: 8.04s\tremaining: 804ms\n",
            "909:\tlearn: 0.0000000\ttotal: 8.04s\tremaining: 795ms\n",
            "910:\tlearn: 0.0000000\ttotal: 8.05s\tremaining: 786ms\n",
            "911:\tlearn: 0.0000000\ttotal: 8.06s\tremaining: 777ms\n",
            "912:\tlearn: 0.0000000\ttotal: 8.06s\tremaining: 768ms\n",
            "913:\tlearn: 0.0000000\ttotal: 8.07s\tremaining: 759ms\n",
            "914:\tlearn: 0.0000000\ttotal: 8.08s\tremaining: 750ms\n",
            "915:\tlearn: 0.0000000\ttotal: 8.08s\tremaining: 741ms\n",
            "916:\tlearn: 0.0000000\ttotal: 8.09s\tremaining: 732ms\n",
            "917:\tlearn: 0.0000000\ttotal: 8.1s\tremaining: 723ms\n",
            "918:\tlearn: 0.0000000\ttotal: 8.11s\tremaining: 714ms\n",
            "919:\tlearn: 0.0000000\ttotal: 8.11s\tremaining: 705ms\n",
            "920:\tlearn: 0.0000000\ttotal: 8.12s\tremaining: 697ms\n",
            "921:\tlearn: 0.0000000\ttotal: 8.13s\tremaining: 688ms\n",
            "922:\tlearn: 0.0000000\ttotal: 8.13s\tremaining: 679ms\n",
            "923:\tlearn: 0.0000000\ttotal: 8.14s\tremaining: 670ms\n",
            "924:\tlearn: 0.0000000\ttotal: 8.15s\tremaining: 661ms\n",
            "925:\tlearn: 0.0000000\ttotal: 8.16s\tremaining: 652ms\n",
            "926:\tlearn: 0.0000000\ttotal: 8.16s\tremaining: 643ms\n",
            "927:\tlearn: 0.0000000\ttotal: 8.17s\tremaining: 634ms\n",
            "928:\tlearn: 0.0000000\ttotal: 8.18s\tremaining: 625ms\n",
            "929:\tlearn: 0.0000000\ttotal: 8.19s\tremaining: 616ms\n",
            "930:\tlearn: 0.0000000\ttotal: 8.2s\tremaining: 608ms\n",
            "931:\tlearn: 0.0000000\ttotal: 8.21s\tremaining: 599ms\n",
            "932:\tlearn: 0.0000000\ttotal: 8.22s\tremaining: 590ms\n",
            "933:\tlearn: 0.0000000\ttotal: 8.23s\tremaining: 582ms\n",
            "934:\tlearn: 0.0000000\ttotal: 8.24s\tremaining: 573ms\n",
            "935:\tlearn: 0.0000000\ttotal: 8.24s\tremaining: 564ms\n",
            "936:\tlearn: 0.0000000\ttotal: 8.25s\tremaining: 555ms\n",
            "937:\tlearn: 0.0000000\ttotal: 8.26s\tremaining: 546ms\n",
            "938:\tlearn: 0.0000000\ttotal: 8.27s\tremaining: 537ms\n",
            "939:\tlearn: 0.0000000\ttotal: 8.27s\tremaining: 528ms\n",
            "940:\tlearn: 0.0000000\ttotal: 8.28s\tremaining: 519ms\n",
            "941:\tlearn: 0.0000000\ttotal: 8.29s\tremaining: 510ms\n",
            "942:\tlearn: 0.0000000\ttotal: 8.29s\tremaining: 501ms\n",
            "943:\tlearn: 0.0000000\ttotal: 8.3s\tremaining: 493ms\n",
            "944:\tlearn: 0.0000000\ttotal: 8.31s\tremaining: 484ms\n",
            "945:\tlearn: 0.0000000\ttotal: 8.31s\tremaining: 475ms\n",
            "946:\tlearn: 0.0000000\ttotal: 8.32s\tremaining: 466ms\n",
            "947:\tlearn: 0.0000000\ttotal: 8.33s\tremaining: 457ms\n",
            "948:\tlearn: 0.0000000\ttotal: 8.34s\tremaining: 448ms\n",
            "949:\tlearn: 0.0000000\ttotal: 8.34s\tremaining: 439ms\n",
            "950:\tlearn: 0.0000000\ttotal: 8.35s\tremaining: 430ms\n",
            "951:\tlearn: 0.0000000\ttotal: 8.36s\tremaining: 421ms\n",
            "952:\tlearn: 0.0000000\ttotal: 8.36s\tremaining: 412ms\n",
            "953:\tlearn: 0.0000000\ttotal: 8.37s\tremaining: 404ms\n",
            "954:\tlearn: 0.0000000\ttotal: 8.38s\tremaining: 395ms\n",
            "955:\tlearn: 0.0000000\ttotal: 8.38s\tremaining: 386ms\n",
            "956:\tlearn: 0.0000000\ttotal: 8.39s\tremaining: 377ms\n",
            "957:\tlearn: 0.0000000\ttotal: 8.4s\tremaining: 368ms\n",
            "958:\tlearn: 0.0000000\ttotal: 8.4s\tremaining: 359ms\n",
            "959:\tlearn: 0.0000000\ttotal: 8.41s\tremaining: 350ms\n",
            "960:\tlearn: 0.0000000\ttotal: 8.42s\tremaining: 342ms\n",
            "961:\tlearn: 0.0000000\ttotal: 8.43s\tremaining: 333ms\n",
            "962:\tlearn: 0.0000000\ttotal: 8.44s\tremaining: 324ms\n",
            "963:\tlearn: 0.0000000\ttotal: 8.45s\tremaining: 315ms\n",
            "964:\tlearn: 0.0000000\ttotal: 8.46s\tremaining: 307ms\n",
            "965:\tlearn: 0.0000000\ttotal: 8.46s\tremaining: 298ms\n",
            "966:\tlearn: 0.0000000\ttotal: 8.47s\tremaining: 289ms\n",
            "967:\tlearn: 0.0000000\ttotal: 8.47s\tremaining: 280ms\n",
            "968:\tlearn: 0.0000000\ttotal: 8.48s\tremaining: 271ms\n",
            "969:\tlearn: 0.0000000\ttotal: 8.49s\tremaining: 263ms\n",
            "970:\tlearn: 0.0000000\ttotal: 8.49s\tremaining: 254ms\n",
            "971:\tlearn: 0.0000000\ttotal: 8.5s\tremaining: 245ms\n",
            "972:\tlearn: 0.0000000\ttotal: 8.51s\tremaining: 236ms\n",
            "973:\tlearn: 0.0000000\ttotal: 8.52s\tremaining: 227ms\n",
            "974:\tlearn: 0.0000000\ttotal: 8.52s\tremaining: 219ms\n",
            "975:\tlearn: 0.0000000\ttotal: 8.53s\tremaining: 210ms\n",
            "976:\tlearn: 0.0000000\ttotal: 8.54s\tremaining: 201ms\n",
            "977:\tlearn: 0.0000000\ttotal: 8.55s\tremaining: 192ms\n",
            "978:\tlearn: 0.0000000\ttotal: 8.55s\tremaining: 183ms\n",
            "979:\tlearn: 0.0000000\ttotal: 8.56s\tremaining: 175ms\n",
            "980:\tlearn: 0.0000000\ttotal: 8.57s\tremaining: 166ms\n",
            "981:\tlearn: 0.0000000\ttotal: 8.57s\tremaining: 157ms\n",
            "982:\tlearn: 0.0000000\ttotal: 8.58s\tremaining: 148ms\n",
            "983:\tlearn: 0.0000000\ttotal: 8.59s\tremaining: 140ms\n",
            "984:\tlearn: 0.0000000\ttotal: 8.6s\tremaining: 131ms\n",
            "985:\tlearn: 0.0000000\ttotal: 8.6s\tremaining: 122ms\n",
            "986:\tlearn: 0.0000000\ttotal: 8.61s\tremaining: 113ms\n",
            "987:\tlearn: 0.0000000\ttotal: 8.62s\tremaining: 105ms\n",
            "988:\tlearn: 0.0000000\ttotal: 8.62s\tremaining: 95.9ms\n",
            "989:\tlearn: 0.0000000\ttotal: 8.63s\tremaining: 87.2ms\n",
            "990:\tlearn: 0.0000000\ttotal: 8.64s\tremaining: 78.5ms\n",
            "991:\tlearn: 0.0000000\ttotal: 8.65s\tremaining: 69.7ms\n",
            "992:\tlearn: 0.0000000\ttotal: 8.65s\tremaining: 61ms\n",
            "993:\tlearn: 0.0000000\ttotal: 8.66s\tremaining: 52.3ms\n",
            "994:\tlearn: 0.0000000\ttotal: 8.67s\tremaining: 43.6ms\n",
            "995:\tlearn: 0.0000000\ttotal: 8.68s\tremaining: 34.8ms\n",
            "996:\tlearn: 0.0000000\ttotal: 8.68s\tremaining: 26.1ms\n",
            "997:\tlearn: 0.0000000\ttotal: 8.69s\tremaining: 17.4ms\n",
            "998:\tlearn: 0.0000000\ttotal: 8.7s\tremaining: 8.71ms\n",
            "999:\tlearn: 0.0000000\ttotal: 8.7s\tremaining: 0us\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_899713c9-569a-419f-acbd-34367804cdb3\", \"preds_full_catrERI.csv\", 1325)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_c5c11c4c-980e-44c7-9d53-23247492bdd5\", \"absoluteerrors_full_catrERI.csv\", 1325)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_df5afb26-8586-4007-92ae-d1222a4f1927\", \"squarederrors_full_catrERI.csv\", 1325)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in targets:\n",
        "\n",
        "  name = 'catr'\n",
        "  name=name+i[:3]\n",
        "  dfextract2, y = get_targets(i)\n",
        "\n",
        "  predictions = run_exp(model,grid,i)\n",
        "\n",
        "  ae = np.abs(np.tile(y,(1)).T-predictions)\n",
        "  se = np.square(np.tile(y,(1)).T-predictions)\n",
        "\n",
        "  np.savetxt('preds_full_{}.csv'.format(name), predictions, delimiter = ',')\n",
        "  np.savetxt('absoluteerrors_full_{}.csv'.format(name), ae, delimiter = ',')\n",
        "  np.savetxt('squarederrors_full_{}.csv'.format(name), se, delimiter = ',')\n",
        "\n",
        "  files.download('preds_full_{}.csv'.format(name))\n",
        "  files.download('absoluteerrors_full_{}.csv'.format(name))\n",
        "  files.download('squarederrors_full_{}.csv'.format(name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duveYjp0GKzK"
      },
      "source": [
        "## XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ82EEUTGKzK"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6WMxHU5Pnv-"
      },
      "outputs": [],
      "source": [
        "model = XGBRegressor()\n",
        "grid = {'max_depth': range(2, 10, 1),\n",
        "    'n_estimators': range(60, 220, 40),\n",
        "    'learning_rate': [0.1, 0.01, 0.05]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "StIqhL2WGKzL",
        "outputId": "f70a6158-aee0-4435-c7f8-53ebb142b14b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration 0\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 1\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 2\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 3\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 4\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 5\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 6\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 7\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 8\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 9\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_ba7ce8de-567f-440a-9338-2a5be173deb5\", \"preds_full_xgbERI.csv\", 1325)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_43368542-4707-4713-98d8-019cf936a738\", \"absoluteerrors_full_xgbERI.csv\", 70225)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_64cf5ce9-84a1-401a-ac60-9d8820ddd6a5\", \"squarederrors_full_xgbERI.csv\", 70225)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration 0\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 1\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 2\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 3\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 4\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 5\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 6\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 7\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 8\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 9\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_5b41348f-3624-4805-b535-c090b6fbada6\", \"preds_full_xgbPLA.csv\", 1325)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_0ba4d6ba-077a-4b6a-9494-3cf809178593\", \"absoluteerrors_full_xgbPLA.csv\", 70225)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_2a680f9e-c77c-4d5e-9a91-1fae2d026f48\", \"squarederrors_full_xgbPLA.csv\", 70225)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration 0\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 1\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 2\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 3\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 4\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 5\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 6\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 7\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 8\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 9\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_531e7990-3a01-4a74-8580-a37255026c41\", \"preds_full_xgbLEU.csv\", 1325)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_36d1b48d-6dc7-4cf7-8f66-8a8fc713fb0f\", \"absoluteerrors_full_xgbLEU.csv\", 70225)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_d72e92fd-5c80-4adb-a70c-2e02e9f47adc\", \"squarederrors_full_xgbLEU.csv\", 70225)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration 0\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 1\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 2\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 3\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 4\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 5\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 6\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 7\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 8\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "iteration 9\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_843e8aa1-ea91-45a2-be94-b6298560cb35\", \"preds_full_xgbHEM.csv\", 1325)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_f80da65b-4e31-4758-b1d9-310eb9565922\", \"absoluteerrors_full_xgbHEM.csv\", 70225)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_bb590cdb-0bed-4ebf-8480-f83317ca9fbb\", \"squarederrors_full_xgbHEM.csv\", 70225)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in targets:\n",
        "  name = 'xgb'\n",
        "  name=name+i[:3]\n",
        "\n",
        "  dfextract2, y = get_targets(i)\n",
        "\n",
        "  predictions = run_exp(model,grid,i)\n",
        "\n",
        "  ae = np.abs(np.tile(y,(1)).T-predictions)\n",
        "  se = np.square(np.tile(y,(1)).T-predictions)\n",
        "\n",
        "  np.savetxt('preds_full_{}.csv'.format(name), predictions, delimiter = ',')\n",
        "  np.savetxt('absoluteerrors_full_{}.csv'.format(name), ae, delimiter = ',')\n",
        "  np.savetxt('squarederrors_full_{}.csv'.format(name), se, delimiter = ',')\n",
        "\n",
        "  files.download('preds_full_{}.csv'.format(name))\n",
        "  files.download('absoluteerrors_full_{}.csv'.format(name))\n",
        "  files.download('squarederrors_full_{}.csv'.format(name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF9ywaHj20I-"
      },
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CatwDOw4PuEa"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "model = KNeighborsRegressor()\n",
        "grid = {\n",
        "    'n_neighbors': range(1, 21),\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'p': [1, 2]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "0xsfQLRTQpr8",
        "outputId": "0a6c10fa-ed90-4d55-a5a0-4030d9a0e02a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration 0\n",
            "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_fdb9d0a0-1007-4814-b118-2a13d61cb004\", \"preds_full_knnERI.csv\", 1325)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_73a135d0-ed54-4670-9792-2fd6fd9a865e\", \"absoluteerrors_full_knnERI.csv\", 1325)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e6f09dac-ea0f-4276-a29d-79b5561e4fe2\", \"squarederrors_full_knnERI.csv\", 1325)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in targets:\n",
        "  name = 'knn'\n",
        "  name=name+i[:3]\n",
        "\n",
        "  dfextract2, y = get_targets(i)\n",
        "\n",
        "  predictions = run_exp(model,grid,i)\n",
        "\n",
        "  ae = np.abs(np.tile(y,(1)).T-predictions)\n",
        "  se = np.square(np.tile(y,(1)).T-predictions)\n",
        "\n",
        "  np.savetxt('preds_full_{}.csv'.format(name), predictions, delimiter = ',')\n",
        "  np.savetxt('absoluteerrors_full_{}.csv'.format(name), ae, delimiter = ',')\n",
        "  np.savetxt('squarederrors_full_{}.csv'.format(name), se, delimiter = ',')\n",
        "\n",
        "  files.download('preds_full_{}.csv'.format(name))\n",
        "  files.download('absoluteerrors_full_{}.csv'.format(name))\n",
        "  files.download('squarederrors_full_{}.csv'.format(name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4-6wevqSQOW"
      },
      "source": [
        "## RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu01GWD-SPwy"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor()\n",
        "grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "NErYQL-hSlGM",
        "outputId": "fea52b6f-da12-440d-cf8b-1a4c733e99f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration 0\n",
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e99f7915-0beb-4ba1-b451-5308535e7348\", \"preds_full_randforestERI.csv\", 1325)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_08b99803-617a-4b80-80eb-b3b202105f40\", \"absoluteerrors_full_randforestERI.csv\", 1325)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_2aace77c-b4d4-4e4a-8149-9376f76ae16b\", \"squarederrors_full_randforestERI.csv\", 1325)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for i in targets:\n",
        "  name = 'randforest'\n",
        "  name=name+i[:3]\n",
        "\n",
        "  dfextract2, y = get_targets(i)\n",
        "\n",
        "  predictions = run_exp(model,grid,i)\n",
        "\n",
        "  ae = np.abs(np.tile(y,(1)).T-predictions)\n",
        "  se = np.square(np.tile(y,(1)).T-predictions)\n",
        "\n",
        "  np.savetxt('preds_full_{}.csv'.format(name), predictions, delimiter = ',')\n",
        "  np.savetxt('absoluteerrors_full_{}.csv'.format(name), ae, delimiter = ',')\n",
        "  np.savetxt('squarederrors_full_{}.csv'.format(name), se, delimiter = ',')\n",
        "\n",
        "  files.download('preds_full_{}.csv'.format(name))\n",
        "  files.download('absoluteerrors_full_{}.csv'.format(name))\n",
        "  files.download('squarederrors_full_{}.csv'.format(name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDTVaKb89xSU"
      },
      "source": [
        "# Modelos Rede Neural\n",
        "\n",
        "Os testes abaixo foram todos executados, mas tivemos que apagar o output gerado porque ele era muito extenso e o GitHub não permitia salvá-lo assim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxT5xmnFZIKD"
      },
      "source": [
        "## Funções utilizadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbkQIjl4aire"
      },
      "outputs": [],
      "source": [
        "def get_ts_target(nameTarget):\n",
        "  data = dataframe[nameTarget].to_numpy()\n",
        "\n",
        "  timeSeries = []\n",
        "  for j in range(len(data)):\n",
        "      if not math.isnan(data[j]):\n",
        "          timeSeries.append(timeSeriesAux[j])\n",
        "  timeSeries = np.array(timeSeries).astype(float)\n",
        "\n",
        "  data = dataframe[nameTarget].dropna().to_numpy()\n",
        "\n",
        "  return timeSeries, data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAvx5Ly6C2bl"
      },
      "outputs": [],
      "source": [
        "def normalize_parameters(parameters):\n",
        "    norm = MinMaxScaler(feature_range = (0,1))\n",
        "    normalized_param = np.reshape(parameters,(parameters.shape[0],1))\n",
        "    normalized_param = norm.fit_transform(normalized_param)\n",
        "\n",
        "    return normalized_param, norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtZ_ogfRKMQy"
      },
      "outputs": [],
      "source": [
        "def windowing_func(time_series,parameters,number_of_parts):\n",
        "\n",
        "    if number_of_parts == 1:\n",
        "        return time_series, parameters\n",
        "\n",
        "    time_series_with_windowing = np.zeros(shape = (number_of_parts*time_series.shape[0],\n",
        "                                                  time_series.shape[1], 300))\n",
        "\n",
        "    parameters_with_windowing = []\n",
        "    for i in range(time_series.shape[0]):\n",
        "        for j in range(number_of_parts):\n",
        "            start = random.randint(0, time_series.shape[2] - 300)\n",
        "            time_series_with_windowing[i * number_of_parts + j][0] = time_series[i][0][start:start+300]\n",
        "            time_series_with_windowing[i * number_of_parts + j][1] = time_series[i][1][start:start+300]\n",
        "            time_series_with_windowing[i * number_of_parts + j][2] = time_series[i][2][start:start+300]\n",
        "            parameters_with_windowing.append(parameters[i])\n",
        "\n",
        "    return time_series_with_windowing, np.array(parameters_with_windowing)\n",
        "\n",
        "\n",
        "def time_series_augmentations(time_series,parameters, multiple, augmenters):\n",
        "    if(multiple == 0):\n",
        "        return time_series,parameters\n",
        "\n",
        "    sum_augmenters = augmenters[0]*multiple\n",
        "\n",
        "    for i in range(1,len(augmenters)):\n",
        "        sum_augmenters += augmenters[i]\n",
        "\n",
        "    augmenter = (\n",
        "        sum_augmenters\n",
        "    )\n",
        "    augmented_time_series = augmenter.augment(time_series)\n",
        "    augmented_time_series = np.concatenate((time_series,augmented_time_series))\n",
        "    augmented_parameters = np.repeat(parameters, multiple)\n",
        "    augmented_parameters = np.concatenate((parameters,augmented_parameters))\n",
        "\n",
        "    return augmented_time_series, augmented_parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S0DsE9wKLAS"
      },
      "outputs": [],
      "source": [
        "def split_train_valid(train_index, lenValSet):\n",
        "  np.random.shuffle(train_index)\n",
        "\n",
        "  val_index = []\n",
        "  for i in train_index:\n",
        "    if not i in val_index:\n",
        "      val_index.append(i)\n",
        "    if len(val_index) == lenValSet:\n",
        "      break\n",
        "  val_index = sorted(val_index)\n",
        "\n",
        "  train_index = sorted(train_index[lenValSet:])\n",
        "\n",
        "  return train_index, val_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lxsnfl2X2Us1"
      },
      "outputs": [],
      "source": [
        "def run_exp(windowing = False, augment = False, arch='ResNet'):\n",
        "  preds = np.zeros([timeSeries.shape[0],5], dtype=float)\n",
        "\n",
        "  for i in range(5):\n",
        "        print('\\n\\n\\nExecution #'+str(i))\n",
        "        kf = KFold(n_splits=10)\n",
        "\n",
        "        for train_index, test_index in kf.split(timeSeries):\n",
        "\n",
        "          lenValSet = len(test_index)\n",
        "          train_index, val_index = split_train_valid(train_index, lenValSet)\n",
        "\n",
        "          X_train, X_val, X_test, y_train, y_val, y_test = (timeSeries[train_index],\n",
        "                                                            timeSeries[val_index],\n",
        "                                                            timeSeries[test_index],\n",
        "                                                            data[train_index],\n",
        "                                                            data[val_index],\n",
        "                                                            data[test_index])\n",
        "\n",
        "          print(X_train.shape)\n",
        "\n",
        "          if (augment):\n",
        "              X_train, y_train = time_series_augmentations(X_train, y_train, 19, [tsaug.TimeWarp(), tsaug.AddNoise(), tsaug.Drift()])\n",
        "\n",
        "          print(X_train.shape)\n",
        "\n",
        "          X_train = np.concatenate((X_train, X_val), axis=0)\n",
        "          y_train = np.concatenate((y_train, y_val), axis=0)\n",
        "\n",
        "          train_idx = np.arange(len(X_train) - lenValSet)\n",
        "          val_idx = np.arange(len(X_train) - lenValSet, len(X_train))\n",
        "          splits = (train_idx, val_idx)\n",
        "\n",
        "          y_train_normalized, norm = normalize_parameters(y_train)\n",
        "\n",
        "          batch_tfms = TSStandardize(by_sample=True)\n",
        "          reg = TSRegressor(X_train, y_train_normalized.T[0],\n",
        "                            path='models',\n",
        "                            splits=splits,\n",
        "                            arch=arch,\n",
        "                            batch_tfms=batch_tfms,\n",
        "                            metrics=rmse,\n",
        "                            train_metrics=True,\n",
        "                            verbose=True,\n",
        "                            )\n",
        "\n",
        "          reg.fit_one_cycle(200, 5e-5)\n",
        "\n",
        "          reg.recorder.plot_metrics()\n",
        "\n",
        "          raw_preds, target, y_pred = reg.get_X_preds(X_test, y_test)\n",
        "\n",
        "          y_pred = norm.inverse_transform(y_pred)\n",
        "\n",
        "          if (windowing or augment):\n",
        "            if (windowing ^ augment):\n",
        "                for k in range(y_test.shape[0] // 5):\n",
        "                    preds[test_index[k], i] = np.median(y_pred[k*5:k*5+5])\n",
        "            else:\n",
        "                for k in range(y_test.shape[0] // 5):\n",
        "                    preds[test_index[k], i] = np.median(y_pred[k*5:k*5+5])\n",
        "          else:\n",
        "              preds[test_index,i] = y_pred.reshape(preds[test_index,i].shape)\n",
        "\n",
        "  return preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzHIZVRAz1Jo"
      },
      "source": [
        "## Hemoglobina"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK-WFRM9baut"
      },
      "outputs": [],
      "source": [
        "timeSeries, data = get_ts_target('HEMOGLOBINA [g/dL]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F24dSnMp2B53"
      },
      "outputs": [],
      "source": [
        "model = \"ResNet\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLeh_YQb2Blf"
      },
      "outputs": [],
      "source": [
        "model = \"FCN\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ffeAPXUxyRW"
      },
      "outputs": [],
      "source": [
        "model = \"InceptionTime\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijm4KNWrOGxE"
      },
      "outputs": [],
      "source": [
        "model = \"MiniRocket\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbYWIvGxz3yH"
      },
      "source": [
        "## Leucócitos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I63k3B4QokMA"
      },
      "outputs": [],
      "source": [
        "timeSeries, data = get_ts_target('LEUCÓCITOS [n°/mm³]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqror3gtotp7"
      },
      "outputs": [],
      "source": [
        "model = \"ResNet\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFiC2Tdbowq8"
      },
      "outputs": [],
      "source": [
        "model = \"FCN\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybbpUC3voxqd"
      },
      "outputs": [],
      "source": [
        "model = \"InceptionTime\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XM1nVlgHCWZR"
      },
      "outputs": [],
      "source": [
        "model = \"MiniRocket\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbJSod3dZwUy"
      },
      "source": [
        "## Plaquetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZci_jHoWu-Y"
      },
      "outputs": [],
      "source": [
        "timeSeries, data = get_ts_target('PLAQUETAS [n°/mm³]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo0KZwAhW-Z1"
      },
      "outputs": [],
      "source": [
        "model = \"ResNet\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHKfMZ9uXcvy"
      },
      "outputs": [],
      "source": [
        "model = \"FCN\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip5nFctPm4-X"
      },
      "outputs": [],
      "source": [
        "model = \"InceptionTime\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3R6MDRRd6JWN"
      },
      "outputs": [],
      "source": [
        "model = \"MiniRocket\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZppAd2KiZ6Q2"
      },
      "source": [
        "## Eritrócitos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZtWxL2-ZiF9"
      },
      "outputs": [],
      "source": [
        "timeSeries, data = get_ts_target('ERITRÓCITOS [x10⁶/μL]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6CxALxxZkau"
      },
      "outputs": [],
      "source": [
        "model = \"ResNet\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gaNMdVhZkqG"
      },
      "outputs": [],
      "source": [
        "model = \"FCN\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_fT5lMfZk5v"
      },
      "outputs": [],
      "source": [
        "model = \"InceptionTime\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiyQXtCZzyB7"
      },
      "outputs": [],
      "source": [
        "model = \"MiniRocket\"\n",
        "\n",
        "predictions = run_exp(arch=model)\n",
        "\n",
        "np.savetxt('preds_full_{}.csv'.format(model), predictions, delimiter = ',')\n",
        "\n",
        "ae = np.abs(np.tile(data,(5,1)).T-predictions)\n",
        "se = np.square(np.tile(data,(5,1)).T-predictions)\n",
        "\n",
        "np.savetxt('absoluteerrors_full_{}.csv'.format(model), ae, delimiter = ',')\n",
        "np.savetxt('squarederrors_full_{}.csv'.format(model), se, delimiter = ',')\n",
        "\n",
        "files.download('preds_full_{}.csv'.format(model))\n",
        "files.download('absoluteerrors_full_{}.csv'.format(model))\n",
        "files.download('squarederrors_full_{}.csv'.format(model))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-gP-x0H9Y7A5",
        "SphOYdDnZVeQ",
        "4jSNYcOzFFV2",
        "edHSfMqwyEnv",
        "c3WW7o_BFzML",
        "fL-7T_VaFxAb",
        "duveYjp0GKzK",
        "bF9ywaHj20I-",
        "T4-6wevqSQOW",
        "rDTVaKb89xSU",
        "wxT5xmnFZIKD",
        "HzHIZVRAz1Jo",
        "vbYWIvGxz3yH",
        "AbJSod3dZwUy",
        "ZppAd2KiZ6Q2"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
